{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nfQAEJhqchZb"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHxbQvguZjUKKwFemWjHPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PietroSpalluto/word-2-vec/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSj5mpo3a86B",
        "outputId": "d8892209-2533-43ea-d3ab-8e7d4498e06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import itertools\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/datasets/Brown_Corpus/brown.csv')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "4hSO9SYHbATB",
        "outputId": "96780658-5f3a-462a-e61f-25e8cf081a5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      filename  para_id  sent_id  \\\n",
              "0         cd05        0        0   \n",
              "1         cd05        0        1   \n",
              "2         cd05        0        2   \n",
              "3         cd05        0        3   \n",
              "4         cd05        0        4   \n",
              "...        ...      ...      ...   \n",
              "57335     cj14        6        3   \n",
              "57336     cj14        6        4   \n",
              "57337     cj14        6        5   \n",
              "57338     cj14        6        6   \n",
              "57339     cj14        6        7   \n",
              "\n",
              "                                                raw_text  \\\n",
              "0      Furthermore/rb ,/, as/cs an/at encouragement/n...   \n",
              "1      The/at Unitarian/jj clergy/nns were/bed an/at ...   \n",
              "2      Ezra/np Stiles/np Gannett/np ,/, an/at honorab...   \n",
              "3      Even/rb so/rb ,/, Gannett/np judiciously/rb ar...   \n",
              "4      We/ppss today/nr are/ber not/* entitled/vbn to...   \n",
              "...                                                  ...   \n",
              "57335  For/in the/at most/ap part/nn ,/, this/dt disc...   \n",
              "57336                                     A/np-hl ./.-hl   \n",
              "57337  Standard/jj-hl preparations/nns-hl and/cc-hl u...   \n",
              "57338  The/at international/jj unit/nn (/( u./nn )/) ...   \n",
              "57339  The/at international/jj unit/nn is/bez equipot...   \n",
              "\n",
              "                                          tokenized_text  \\\n",
              "0      Furthermore , as an encouragement to revisioni...   \n",
              "1      The Unitarian clergy were an exclusive club of...   \n",
              "2      Ezra Stiles Gannett , an honorable representat...   \n",
              "3      Even so , Gannett judiciously argued , the Ass...   \n",
              "4      We today are not entitled to excoriate honest ...   \n",
              "...                                                  ...   \n",
              "57335  For the most part , this discussion will be co...   \n",
              "57336                                                A .   \n",
              "57337  Standard preparations and units of thyroid-sti...   \n",
              "57338  The international unit ( u. ) , adopted to mak...   \n",
              "57339  The international unit is equipotent with the ...   \n",
              "\n",
              "                                           tokenized_pos     label  \n",
              "0      rb , cs at nn in nn nn , pps rb bez jj to vb c...  religion  \n",
              "1      at jj nns bed at jj nn in vbn nns -- cs at nn ...  religion  \n",
              "2      np np np , at jj nn in at nn , vbd ppl rb in a...  religion  \n",
              "3      rb rb , np rb vbd , at nn-tl md rb vb cs np ``...  religion  \n",
              "4      ppss nr ber * vbn to vb jj nns wps vbd np to b...  religion  \n",
              "...                                                  ...       ...  \n",
              "57335  in at ap nn , dt nn md be vbn in nns vbn in at...   learned  \n",
              "57336                                         np-hl .-hl   learned  \n",
              "57337        jj-hl nns-hl cc-hl nns-hl in-hl jj-hl nn-hl   learned  \n",
              "57338  at jj nn ( nn ) , vbn to vb jj at nn in nns in...   learned  \n",
              "57339  at jj nn bez jj in at nn nn vbn in cd , wdt be...   learned  \n",
              "\n",
              "[57340 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-facc60af-b675-4393-b37d-82b535c1484e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>para_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>tokenized_pos</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cd05</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Furthermore/rb ,/, as/cs an/at encouragement/n...</td>\n",
              "      <td>Furthermore , as an encouragement to revisioni...</td>\n",
              "      <td>rb , cs at nn in nn nn , pps rb bez jj to vb c...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cd05</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The/at Unitarian/jj clergy/nns were/bed an/at ...</td>\n",
              "      <td>The Unitarian clergy were an exclusive club of...</td>\n",
              "      <td>at jj nns bed at jj nn in vbn nns -- cs at nn ...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cd05</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Ezra/np Stiles/np Gannett/np ,/, an/at honorab...</td>\n",
              "      <td>Ezra Stiles Gannett , an honorable representat...</td>\n",
              "      <td>np np np , at jj nn in at nn , vbd ppl rb in a...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cd05</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Even/rb so/rb ,/, Gannett/np judiciously/rb ar...</td>\n",
              "      <td>Even so , Gannett judiciously argued , the Ass...</td>\n",
              "      <td>rb rb , np rb vbd , at nn-tl md rb vb cs np ``...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cd05</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>We/ppss today/nr are/ber not/* entitled/vbn to...</td>\n",
              "      <td>We today are not entitled to excoriate honest ...</td>\n",
              "      <td>ppss nr ber * vbn to vb jj nns wps vbd np to b...</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57335</th>\n",
              "      <td>cj14</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>For/in the/at most/ap part/nn ,/, this/dt disc...</td>\n",
              "      <td>For the most part , this discussion will be co...</td>\n",
              "      <td>in at ap nn , dt nn md be vbn in nns vbn in at...</td>\n",
              "      <td>learned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57336</th>\n",
              "      <td>cj14</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>A/np-hl ./.-hl</td>\n",
              "      <td>A .</td>\n",
              "      <td>np-hl .-hl</td>\n",
              "      <td>learned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57337</th>\n",
              "      <td>cj14</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>Standard/jj-hl preparations/nns-hl and/cc-hl u...</td>\n",
              "      <td>Standard preparations and units of thyroid-sti...</td>\n",
              "      <td>jj-hl nns-hl cc-hl nns-hl in-hl jj-hl nn-hl</td>\n",
              "      <td>learned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57338</th>\n",
              "      <td>cj14</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>The/at international/jj unit/nn (/( u./nn )/) ...</td>\n",
              "      <td>The international unit ( u. ) , adopted to mak...</td>\n",
              "      <td>at jj nn ( nn ) , vbn to vb jj at nn in nns in...</td>\n",
              "      <td>learned</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57339</th>\n",
              "      <td>cj14</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>The/at international/jj unit/nn is/bez equipot...</td>\n",
              "      <td>The international unit is equipotent with the ...</td>\n",
              "      <td>at jj nn bez jj in at nn nn vbn in cd , wdt be...</td>\n",
              "      <td>learned</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57340 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-facc60af-b675-4393-b37d-82b535c1484e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-facc60af-b675-4393-b37d-82b535c1484e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-facc60af-b675-4393-b37d-82b535c1484e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b82943d9-ffec-4d18-a273-445185a4f53c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b82943d9-ffec-4d18-a273-445185a4f53c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b82943d9-ffec-4d18-a273-445185a4f53c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 57340,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"cr06\",\n          \"ck24\",\n          \"cg30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"para_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 95,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          80,\n          77,\n          73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 123,\n        \"num_unique_values\": 124,\n        \"samples\": [\n          18,\n          42,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56464,\n        \"samples\": [\n          \"Bids/nns are/ber evaluated/vbn by/in the/at Division/nn-tl of/in-tl Purchases/nns-tl with/in the/at assistance/nn of/in pool/nn staff/nn ,/, and/cc awards/nns for/in the/at purchase/nn of/in the/at automobiles/nns are/ber made/vbn to/in the/at lowest/jjt responsible/jj bidders/nns ./.\",\n          \"The/at electoral/jj procedure/nn prevented/vbd the/at ready/jj identification/nn of/in party/nn affiliation/nn ,/, but/cc all/abn vitally/rb interested/vbn parties/nns ,/, including/in the/at government/nn itself/ppl ,/, were/bed busily/rb engaged/vbn in/in determining/vbg the/at party/nn identifications/nns of/in all/abn successful/jj candidates/nns the/at month/nn following/in the/at elections/nns ./.\",\n          \"The/at cry/nn ``/`` Garryowen/np ''/'' !/. !/.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56418,\n        \"samples\": [\n          \"At the bottom of this change were great strides forward in the technical equipment and technical standards of the historian .\",\n          \"But my people -- Martians , I mean ; ;\",\n          \"He found a match in his pocket and lit it .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized_pos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54442,\n        \"samples\": [\n          \"cc pn md vb at nn in abn dt cc dti jj jj nn doz vb abn dt cc doz vb ppo .\",\n          \"pps vbd cs at nn vbg at nn .\",\n          \"dts nns ber vbn nns in nns .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"belles_lettres\",\n          \"news\",\n          \"religion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "nfQAEJhqchZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = data['tokenized_text']\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOZ-AbLGcnvd",
        "outputId": "89a77a3a-a5f6-4c70-e0fd-e1f278fb29b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Furthermore , as an encouragement to revisioni...\n",
              "1        The Unitarian clergy were an exclusive club of...\n",
              "2        Ezra Stiles Gannett , an honorable representat...\n",
              "3        Even so , Gannett judiciously argued , the Ass...\n",
              "4        We today are not entitled to excoriate honest ...\n",
              "                               ...                        \n",
              "57335    For the most part , this discussion will be co...\n",
              "57336                                                  A .\n",
              "57337    Standard preparations and units of thyroid-sti...\n",
              "57338    The international unit ( u. ) , adopted to mak...\n",
              "57339    The international unit is equipotent with the ...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercase"
      ],
      "metadata": {
        "id": "niLvuyybci1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docs.apply(lambda x: x.lower())\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdjd-dUpclOH",
        "outputId": "31cfd55c-7d50-481e-da93-aceb3b7a0549"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        furthermore , as an encouragement to revisioni...\n",
              "1        the unitarian clergy were an exclusive club of...\n",
              "2        ezra stiles gannett , an honorable representat...\n",
              "3        even so , gannett judiciously argued , the ass...\n",
              "4        we today are not entitled to excoriate honest ...\n",
              "                               ...                        \n",
              "57335    for the most part , this discussion will be co...\n",
              "57336                                                  a .\n",
              "57337    standard preparations and units of thyroid-sti...\n",
              "57338    the international unit ( u. ) , adopted to mak...\n",
              "57339    the international unit is equipotent with the ...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove non words characters (punctuation, symbols and special characters)"
      ],
      "metadata": {
        "id": "KTUZplWjc8-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docs.replace(to_replace=r'[^\\w\\s]', value='', regex=True)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5u3Y_WLdDqB",
        "outputId": "84b08faf-bc11-415a-f60b-01bf7ed4110a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        furthermore  as an encouragement to revisionis...\n",
              "1        the unitarian clergy were an exclusive club of...\n",
              "2        ezra stiles gannett  an honorable representati...\n",
              "3        even so  gannett judiciously argued  the assoc...\n",
              "4        we today are not entitled to excoriate honest ...\n",
              "                               ...                        \n",
              "57335    for the most part  this discussion will be con...\n",
              "57336                                                   a \n",
              "57337    standard preparations and units of thyroidstim...\n",
              "57338    the international unit  u   adopted to make po...\n",
              "57339    the international unit is equipotent with the ...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove numerical digits since they do not provide significant meaning"
      ],
      "metadata": {
        "id": "sQuo_pf5dmN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docs.replace(to_replace=r'\\d', value='', regex=True)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JFg6A-Qds-W",
        "outputId": "98f99e9d-3df8-4331-f349-a6dff22dfc55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        furthermore  as an encouragement to revisionis...\n",
              "1        the unitarian clergy were an exclusive club of...\n",
              "2        ezra stiles gannett  an honorable representati...\n",
              "3        even so  gannett judiciously argued  the assoc...\n",
              "4        we today are not entitled to excoriate honest ...\n",
              "                               ...                        \n",
              "57335    for the most part  this discussion will be con...\n",
              "57336                                                   a \n",
              "57337    standard preparations and units of thyroidstim...\n",
              "57338    the international unit  u   adopted to make po...\n",
              "57339    the international unit is equipotent with the ...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "9Cxmpy5reX0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "docs_tokenized = docs.apply(word_tokenize)\n",
        "docs_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74UgzB9d0AX",
        "outputId": "e6969255-511d-4046-bff1-6157d8e0f393"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [furthermore, as, an, encouragement, to, revis...\n",
              "1        [the, unitarian, clergy, were, an, exclusive, ...\n",
              "2        [ezra, stiles, gannett, an, honorable, represe...\n",
              "3        [even, so, gannett, judiciously, argued, the, ...\n",
              "4        [we, today, are, not, entitled, to, excoriate,...\n",
              "                               ...                        \n",
              "57335    [for, the, most, part, this, discussion, will,...\n",
              "57336                                                  [a]\n",
              "57337    [standard, preparations, and, units, of, thyro...\n",
              "57338    [the, international, unit, u, adopted, to, mak...\n",
              "57339    [the, international, unit, is, equipotent, wit...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words removal"
      ],
      "metadata": {
        "id": "XAgsYeKXeaVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "docs_tokenized = docs_tokenized.apply(lambda x: [word for word in x if word not in stop_words])\n",
        "docs_tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZH2T6m4eaFe",
        "outputId": "9b4a7384-c3b9-4002-b719-51d966afbb77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [furthermore, encouragement, revisionist, thin...\n",
              "1        [unitarian, clergy, exclusive, club, cultivate...\n",
              "2        [ezra, stiles, gannett, honorable, representat...\n",
              "3        [even, gannett, judiciously, argued, associati...\n",
              "4        [today, entitled, excoriate, honest, men, beli...\n",
              "                               ...                        \n",
              "57335    [part, discussion, confined, results, obtained...\n",
              "57336                                                   []\n",
              "57337    [standard, preparations, units, thyroidstimula...\n",
              "57338    [international, unit, u, adopted, make, possib...\n",
              "57339    [international, unit, equipotent, usp, unit, a...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "b03V4eqHfJjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import pandas as pd\n",
        "\n",
        "# initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# define function to lemmatize tokens\n",
        "def lemmatize_tokens(tokens):\n",
        "    # convert POS tag to WordNet format\n",
        "    def get_wordnet_pos(word):\n",
        "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "        tag_dict = {\"J\": wordnet.ADJ,\n",
        "                    \"N\": wordnet.NOUN,\n",
        "                    \"V\": wordnet.VERB,\n",
        "                    \"R\": wordnet.ADV}\n",
        "        return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "    # lemmatize tokens\n",
        "    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
        "\n",
        "    # return lemmatized tokens as a list\n",
        "    return lemmas\n",
        "\n",
        "# apply lemmatization function to column of dataframe\n",
        "docs_lemmatized = docs_tokenized.apply(lemmatize_tokens)\n",
        "docs_lemmatized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwtpEQjofK0j",
        "outputId": "69bfc48d-6440-4e36-d85c-7e429c1d2482"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [furthermore, encouragement, revisionist, thin...\n",
              "1        [unitarian, clergy, exclusive, club, cultivate...\n",
              "2        [ezra, stile, gannett, honorable, representati...\n",
              "3        [even, gannett, judiciously, argue, associatio...\n",
              "4        [today, entitle, excoriate, honest, men, belie...\n",
              "                               ...                        \n",
              "57335    [part, discussion, confine, result, obtain, si...\n",
              "57336                                                   []\n",
              "57337    [standard, preparation, unit, thyroidstimulati...\n",
              "57338    [international, unit, u, adopt, make, possible...\n",
              "57339    [international, unit, equipotent, usp, unit, a...\n",
              "Name: tokenized_text, Length: 57340, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a set containing words in the training corpus with a frequency greater than a selected number"
      ],
      "metadata": {
        "id": "mv7LBzUSiBhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = int(len(docs_lemmatized) * 0.8)  # 80% of the paragraphs in the training set\n",
        "min_term_freq = 5\n",
        "\n",
        "# shuffle corpus and keep index (we will use it for the label when doing supervised learning)\n",
        "shuffled_docs = docs_lemmatized.sample(frac=1)\n",
        "indices = shuffled_docs.index\n",
        "print(shuffled_docs)\n",
        "\n",
        "# compute term frequency for each word in train\n",
        "term_freq = {}\n",
        "for i, sentence in enumerate(shuffled_docs):\n",
        "    if i == num_train:\n",
        "        break\n",
        "    for word in sentence:\n",
        "        term_freq[word] = term_freq.get(word, 0) + 1\n",
        "\n",
        "# make a vocabulary including words with a frequency greater than min_term_freq\n",
        "vocabulary = {word for word in term_freq.keys() if term_freq[word] >= min_term_freq}\n",
        "vocabulary.add('<UNK>')  # <UNK> indicates a unknown word\n",
        "\n",
        "print(vocabulary)\n",
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZWDYXzdiJnl",
        "outputId": "3f85d59a-e3c8-4584-de06-efdafcd30e45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43542     [hardly, deny, exaggerated, old, panorama, dead]\n",
            "48624                                           [burnside]\n",
            "40699    [pitiful, left, subsist, mainly, tourist, trad...\n",
            "16573    [college, gross, general, experience, may, var...\n",
            "29164    [organization, show, affinity, foreign, govern...\n",
            "                               ...                        \n",
            "38003                            [peasant, puzzle, andrei]\n",
            "6736        [oughta, able, build, new, house, contraption]\n",
            "7679                   [really, crucify, nail, yard, loss]\n",
            "55536    [instance, two, presidential, commission, high...\n",
            "5834     [sba, loan, may, make, small, manufacturer, sm...\n",
            "Name: tokenized_text, Length: 57340, dtype: object\n",
            "{'recording', 'leveling', 'beneath', 'hostess', 'ultimately', 'dwight', 'urgent', 'uh', 'downward', 'bail', 'perfection', 'dei', 'latent', 'sam', 'gear', 'wheat', 'chauffeur', 'lust', 'slat', 'batista', 'adoniram', 'wardrobe', 'wholly', 'developer', 'kafka', 'struck', 'muddy', 'passage', 'swore', 'herb', 'tightly', 'flu', 'tribunal', 'beg', 'levy', 'settler', 'alternative', 'pole', 'adjustment', 'occurrence', 'supplier', 'segregation', 'nearby', 'consequent', 'sherry', 'duke', 'assist', 'comparative', 'midwestern', 'rescue', 'stein', 'own', 'orange', 'neighborhood', 'borrow', 'geely', 'janitor', 'susan', 'emergency', 'staccato', 'vicepresident', 'vitally', 'heartily', 'greville', 'shann', 'sufficient', 'feeling', 'defender', 'trooper', 'collaboration', 'similar', 'kohnstammnegative', 'respondent', 'inevitably', 'slab', 'rebuild', 'refinement', 'weston', 'ration', 'bounce', 'comfort', 'permit', 'weider', 'emotion', 'vitality', 'differential', 'precede', 'duration', 'stricken', 'takeoff', 'rival', 'file', 'lean', 'sloans', 'recognize', 'yell', 'transformation', 'governmental', 'smoothness', 'bright', 'bob', 'fringe', 'flashlight', 'quadric', 'event', 'moody', 'project', 'geological', 'foul', 'edge', 'gen', 'shop', 'weird', 'consistently', 'barker', 'factual', 'vermont', 'trifle', 'broken', 'more', 'throw', 'portable', 'derive', 'kitti', 'either', 'doesnt', 'peace', 'trace', 'butcher', 'peninsula', 'dwell', 'dessert', 'jungle', 'undergo', 'oddly', 'growl', 'oddlot', 'pulley', 'rca', 'alloy', 'vacuum', 'visitor', 'hopelessly', 'inorganic', 'senator', 'bolt', 'barnes', 'tradition', 'bicycle', 'fellow', 'eyelid', 'dealt', 'strengthen', 'jan', 'maurice', 'recommendation', 'radiate', 'silently', 'gymnastics', 'spat', 'bang', 'iq', 'rosy', 'resumption', 'enrich', 'academic', 'gratt', 'whig', 'character', 'stravinsky', 'legion', 'shayne', 'apportionment', 'standard', 'meteorite', 'antitrust', 'varies', 'warehouse', 'slump', 'resist', 'exclamation', 'stevie', 'biscuit', 'crack', 'angie', 'premier', 'jew', 'glorify', 'popular', 'approximate', 'spectrum', 'belt', 'rebellion', 'occasionally', 'diocs', 'reinforce', 'bleeding', 'attainment', 'injured', 'gasp', 'vice', 'blew', 'sigh', 'sprout', 'house', 'eromonga', 'shelf', 'traditionally', 'magnetic', 'assault', 'hypocrisy', 'dune', 'steak', 'momentum', 'flatten', 'scott', 'impersonal', 'drilling', 'gossip', 'everlasting', 'fool', 'doll', 'ability', 'bud', 'purify', 'champion', 'parttime', 'prayed', 'appointment', 'smug', 'fashion', 'paid', 'duplication', 'persistence', 'siddo', 'discharge', 'jimmy', 'interplay', 'build', 'monk', 'treacherous', 'trot', 'mile', 'richness', 'drug', 'appliance', 'amy', 'buy', 'enrol', 'ap', 'vegetable', 'blast', 'subsequent', 'demythologize', 'purity', 'prohibition', 'testify', 'emancipation', 'throughout', 'nearly', 'responsible', 'seam', 'hanover', 'inning', 'weekend', 'accordance', 'lowerclass', 'believer', 'powerful', 'scaffold', 'background', 'impressive', 'shutter', 'scripture', 'recruit', 'immortal', 'contain', 'undertook', 'lotion', 'catharsis', 'parish', 'continuance', 'culture', 'earthly', 'conclude', 'lower', 'junior', 'borne', 'require', 'grumble', 'explains', 'sedan', 'burr', 'dapper', 'g', 'doctrine', 'theme', 'usual', 'portland', 'founder', 'slave', 'youngster', 'lunar', 'bet', 'campus', 'tutor', 'continually', 'wild', 'reappear', 'friendship', 'bed', 'drastic', 'photographer', 'hungarian', 'landlord', 'induce', 'detergent', 'unhappiness', 'directional', 'kid', 'warwick', 'configuration', 'purple', 'shorten', 'electrostatic', 'contraction', 'consonant', 'forbes', 'vanity', 'limp', 'junk', 'economical', 'laughter', 'admission', 'long', 'precisely', 'summon', 'prose', 'marked', 'defendant', 'helper', 'crop', 'everchanging', 'physician', 'solitary', 'routine', 'indebted', 'presumably', 'tremendous', 'unmarried', 'across', 'progress', 'reprint', 'negotiate', 'horn', 'planter', 'potentiality', 'domestic', 'shutdown', 'generally', 'pious', 'cloth', 'columbus', 'fasten', 'inventor', 'thesis', 'bill', 'movie', 'inhibit', 'sponge', 'skillful', 'sicken', 'tend', 'versa', 'dairy', 'hair', 'embrace', 'sympathy', 'intersect', 'entertainment', 'eugenia', 'alarmed', 'productive', 'roman', 'cattle', 'charles', 'somehow', 'dandy', 'ronald', 'tact', 'evolution', 'mince', 'anchor', 'thereof', 'realm', 'fiction', 'anywhere', 'im', 'sand', 'palazzo', 'planetary', 'smalltown', 'mislead', 'insult', 'screen', 'elaborate', 'servant', 'time', 'heritage', 'dozen', 'vecchio', 'currently', 'disturb', 'affords', 'interview', 'bloat', 'deliberate', 'ransom', 'march', 'outward', 'accepts', 'plywood', 'pick', 'modern', 'bulb', 'sketch', 'auxiliary', 'whereby', 'rug', 'truman', 'marvelous', 'langford', 'extent', 'eden', 'barn', 'loose', 'board', 'linda', 'simmons', 'publisher', 'cemetery', 'choke', 'human', 'acceptable', 'constantly', 'mask', 'mystery', 'ike', 'wale', 'dim', 'bury', 'row', 'hardware', 'chaplain', 'awkward', 'sleeve', 'activation', 'player', 'curve', 'adapt', 'acclaim', 'aesthetic', 'monteros', 'pond', 'argiento', 'consumption', 'oxford', 'autocoder', 'fur', 'custom', 'monitoring', 'honor', 'clearer', 'impaired', 'pulmonary', 'wilderness', 'reflector', 'contend', 'thru', 'posture', 'southwest', 'pas', 'reverse', 'estate', 'vulnerable', 'delegation', 'hettie', 'ocean', 'knife', 'circle', 'entrance', 'rivalry', 'goodness', 'tessie', 'swollen', 'memorable', 'lumumba', 'transit', 'via', 'provision', 'maggie', 'taxable', 'million', 'deem', 'holland', 'nine', 'circus', 'label', 'milligram', 'anna', 'grace', 'steadily', 'phrasing', 'tuition', 'successive', 'major', 'eastwest', 'tr', 'freak', 'annapolis', 'blazing', 'subtract', 'inefficient', 'recovery', 'allen', 'dissolve', 'wrist', 'indicate', 'hungry', 'vicious', 'artificial', 'busy', 'unexpected', 'alcohol', 'frantically', 'indian', 'cuba', 'bacterial', 'electrode', 'push', 'wait', 'breathe', 'marlowe', 'excite', 'textile', 'coarse', 'thrust', 'undue', 'exceedingly', 'department', 'anyway', 'handkerchief', 'pipe', 'liberalism', 'arrears', 'bead', 'leonard', 'ethical', 'anne', 'originate', 'wage', 'rein', 'shot', 'tabulate', 'easily', 'shoe', 'disbelief', 'measurement', 'eighteenth', 'rewrite', 'trujillo', 'jr', 'subdue', 'livelihood', 'vast', 'ton', 'swedish', 'inability', 'backward', 'recession', 'jerked', 'brother', 'stroll', 'deegan', 'judy', 'forbid', 'calderone', 'understood', 'sail', 'spray', 'official', 'forehead', 'sign', 'absurd', 'u', 'substance', 'lapse', 'gordon', 'ideological', 'repair', 'terrify', 'medal', 'hostile', 'manufacturing', 'peak', 'specialize', 'co', 'specie', 'terrain', 'hearst', 'heavy', 'twist', 'client', 'esthetic', 'blooming', 'destiny', 'democracy', 'thus', 'element', 'mm', 'invoked', 'swerve', 'congratulate', 'experienced', 'glenn', 'q', 'charter', 'wag', 'slip', 'salad', 'civilizational', 'petty', 'hopkins', 'automobile', 'fulltime', 'coordination', 'congregational', 'investment', 'subsidiary', 'eager', 'earth', 'ally', 'fifteenth', 'maneuver', 'representation', 'prophet', 'brahms', 'speaker', 'cereal', 'outsider', 'compelling', 'butter', 'analysis', 'autonomic', 'ah', 'relative', 'infestation', 'brutal', 'ptolemaic', 'corral', 'educate', 'luncheon', 'chest', 'taxpayer', 'halfbreed', 'lurk', 'lousy', 'yellow', 'displayed', 'auditorium', 'advance', 'scandal', 'prosecute', 'hague', 'scrutinize', 'careless', 'avantgarde', 'surplus', 'farrell', 'macbeth', 'maria', 'mainly', 'twitch', 'perpetual', 'absolutely', 'savior', 'rancher', 'lip', 'indiana', 'charlotte', 'resonance', 'soothe', 'etc', 'vein', 'enchant', 'johnnie', 'refrigerator', 'claude', 'colonial', 'solemnly', 'homeland', 'book', 'box', 'beech', 'qualification', 'interpret', 'preach', 'jupiter', 'capt', 'decision', 'inject', 'goin', 'schuylkill', 'chronological', 'buck', 'therapist', 'drive', 'dag', 'component', 'sandy', 'scotch', 'class', 'insure', 'peddler', 'byzantine', 'mistrust', 'sba', 'pitcher', 'grammatical', 'compromise', 'yet', 'moderate', 'specialty', 'vocabulary', 'straighten', 'unfortunately', 'hello', 'triumph', 'stagnant', 'populate', 'spacious', 'commerce', 'sporadic', 'clergy', 'container', 'batter', 'pine', 'payroll', 'grass', 'stimulate', 'gradual', 'grief', 'dorset', 'china', 'tape', 'arrive', 'reservation', 'signal', 'clifford', 'coil', 'frustrate', 'swadesh', 'rodgers', 'clutch', 'blenheim', 'roam', 'papasan', 'mahler', 'version', 'style', 'irradiate', 'emotional', 'dodger', 'decant', 'whipple', 'desirable', 'moliere', 'acquisition', 'transport', 'orthodox', 'indispensable', 'hitler', 'glimpse', 'frost', 'pour', 'parasympathetic', 'stall', 'program', 'liquid', 'kodyke', 'stiff', 'cartridge', 'heard', 'dig', 'commentary', 'wicked', 'revolutionary', 'objection', 'indirectly', 'hammer', 'tin', 'win', 'infinite', 'vastly', 'execute', 'share', 'peter', 'passing', 'smoking', 'paragraph', 'endurance', 'concession', 'ideally', 'commend', 'tight', 'invalid', 'fatigue', 'pip', 'rococo', 'survive', 'ive', 'monetary', 'mend', 'renewal', 'june', 'prestige', 'dunn', 'kenneth', 'occasional', 'telephone', 'breathing', 'despise', 'haze', 'consideration', 'sane', 'buzzing', 'handsome', 'pirate', 'sadly', 'southern', 'plumbing', 'utility', 'youve', 'rachel', 'diplomatic', 'fond', 'yield', 'icy', 'maple', 'multiply', 'proprietor', 'probability', 'discuss', 'chase', 'strife', 'spotlight', 'kohnstamm', 'ivory', 'friction', 'lawyer', 'bundle', 'decade', 'ad', 'practice', 'kidney', 'skilled', 'per', 'brief', 'resolution', 'salter', 'caught', 'oh', 'hiding', 'trio', 'liability', 'oersted', 'kent', 'turmoil', 'contempt', 'always', 'span', 'indictment', 'conserve', 'compensate', 'advertised', 'honesty', 'beaverton', 'intensely', 'yearn', 'broadway', 'arp', 'centennial', 'slant', 'roebuck', 'vincent', 'leer', 'sacred', 'achieve', 'full', 'steinberg', 'awful', 'prayer', 'autobiography', 'swivel', 'packaging', 'sultan', 'palatability', 'fearful', 'darn', 'dismount', 'consultation', 'omit', 'literal', 'aint', 'foundation', 'gyrostabilized', 'enzyme', 'example', 'sea', 'ruth', 'pleasure', 'deny', 'glance', 'precedent', 'afloat', 'diagnostic', 'cigarette', 'trail', 'among', 'blond', 'sponsorship', 'cruel', 'subspace', 'skin', 'correctly', 'act', 'personally', 'conversion', 'bag', 'illumination', 'humiliate', 'musical', 'outcome', 'bunch', 'midwest', 'napoleon', 'greasy', 'freshman', 'folklore', 'severe', 'riot', 'regional', 'deduction', 'brand', 'molecular', 'enter', 'shove', 'productivity', 'discrimination', 'invariably', 'pearl', 'manifest', 'parochial', 'lyrical', 'chain', 'represent', 'spencer', 'international', 'rule', 'vagina', 'stratford', 'classify', 'disposition', 'suitcase', 'auto', 'titer', 'groundwave', 'hopeful', 'callous', 'effectively', 'paste', 'caravan', 'artillery', 'enthusiasm', 'song', 'incur', 'scotty', 'con', 'well', 'ordinary', 'mat', 'perpetuate', 'mousie', 'along', 'plight', 'helvas', 'esther', 'scoop', 'irregular', 'dart', 'interest', 'chemically', 'apparatus', 'dismal', 'fitness', 'simms', 'revulsion', 'discontinue', 'mustache', 'flannagan', 'cruz', 'cochannel', 'gait', 'boldly', 'birthday', 'ambiguous', 'mileage', 'spare', 'grimly', 'garment', 'cheat', 'terrace', 'battery', 'age', 'wood', 'boil', 'hunch', 'grasped', 'vertex', 'locally', 'razor', 'prolusion', 'thee', 'brassnose', 'fromms', 'elder', 'allusion', 'disappearance', 'rust', 'rejection', 'elastic', 'seller', 'grenade', 'fuller', 'disapproval', 'presume', 'rubber', 'nobel', 'statesman', 'someplace', 'wail', 'connotation', 'angeles', 'speech', 'kirby', 'william', 'unifil', 'versus', 'impatience', 'utterance', 'equitable', 'verdi', 'carroll', 'ethic', 'deaecellulose', 'mood', 'idol', 'view', 'transom', 'index', 'infancy', 'forever', 'petitioner', 'howard', 'applause', 'breakdown', 'vital', 'laminate', 'completely', 'ugliness', 'dissatisfied', 'randolph', 'thigh', 'concentration', 'within', 'clergyman', 'seasonal', 'accuse', 'rabbit', 'discount', 'upon', 'want', 'contemplate', 'draped', 'paradoxically', 'accordingly', 'prepare', 'cruise', 'drab', 'superior', 'precarious', 'remarques', 'ink', 'variation', 'secondary', 'unusually', 'subside', 'hip', 'beginning', 'rayburns', 'float', 'doubtless', 'ramsey', 'toll', 'framework', 'breakthrough', 'stag', 'behalf', 'albert', 'force', 'hammarskjold', 'rail', 'charge', 'authenticity', 'everywhere', 'witness', 'performance', 'slight', 'yarn', 'consists', 'slowly', 'paper', 'invisible', 'dissent', 'sonata', 'bronx', 'installment', 'terribly', 'export', 'delay', 'radiant', 'rourke', 'equip', 'intimidate', 'thread', 'recipient', 'symbolize', 'fortunately', 'engender', 'spot', 'sink', 'organic', 'scottys', 'guise', 'forefinger', 'unstructured', 'vaguely', 'instead', 'fruit', 'volunteer', 'harvest', 'attendance', 'polyester', 'spouse', 'grim', 'sank', 'behave', 'truly', 'consolidation', 'adoption', 'hail', 'dividend', 'dependent', 'bachelor', 'grave', 'skiff', 'utilize', 'furnish', 'hamburger', 'crew', 'bow', 'elegance', 'memorize', 'constantine', 'rage', 'ritual', 'gall', 'excerpt', 'buff', 'industrial', 'reside', 'prof', 'notably', 'self', 'fade', 'leader', 'simultaneous', 'mahogany', 'constitutional', 'eloquent', 'innocence', 'swoop', 'du', 'valuable', 'mahayana', 'interested', 'proof', 'startle', 'fundamental', 'symptom', 'operand', 'drag', 'grind', 'dispute', 'surface', 'presentation', 'heaven', 'empirically', 'low', 'lester', 'happening', 'abel', 'gallop', 'antisubmarine', 'smile', 'alpha', 'skim', 'specialized', 'voltage', 'fuel', 'moon', 'inspiration', 'outoftown', 'teaspoon', 'practitioner', 'spontaneous', 'defective', 'concerned', 'stress', 'puppet', 'practicable', 'dowexchloride', 'several', 'sister', 'nov', 'deduct', 'problem', 'scent', 'chlorine', 'aerator', 'singular', 'interim', 'thicken', 'gee', 'gavins', 'freely', 'choked', 'aware', 'continue', 'cancer', 'regulation', 'pear', 'beadle', 'foil', 'filly', 'elongate', 'stark', 'fallout', 'depletion', 'slate', 'bultmann', 'propel', 'favor', 'receipt', 'delight', 'judged', 'garson', 'scoreboard', 'attentive', 'hardly', 'prowestern', 'orthodontist', 'gland', 'drone', 'equ', 'heavier', 'fact', 'majdanek', 'begotten', 'wholesale', 'late', 'longing', 'subtlety', 'detroit', 'amorphous', 'heat', 'forget', 'weekly', 'retrieve', 'everpresent', 'accord', 'seventeenth', 'relish', 'involves', 'convertible', 'barcus', 'russian', 'whatever', 'recede', 'deformation', 'donor', 'fog', 'guerrilla', 'disposal', 'handwrite', 'finding', 'onto', 'oppose', 'spending', 'boy', 'hino', 'crystal', 'album', 'glare', 'brace', 'jap', 'island', 'attitude', 'durable', 'cheese', 'adhere', 'alcoholic', 'stiffly', 'strange', 'weakness', 'twice', 'eventual', 'amusement', 'campaign', 'talk', 'twentysix', 'agrarian', 'grape', 'leadership', 'sorrow', 'lemma', 'stubborn', 'physicist', 'plot', 'nashville', 'plastic', 'massive', 'somewhat', 'function', 'slightly', 'incidentally', 'common', 'victory', 'october', 'prieur', 'despair', 'await', 'country', 'member', 'fund', 'shaken', 'aj', 'metallic', 'wildlife', 'polarity', 'bone', 'formula', 'clearly', 'partially', 'tim', 'chronic', 'rattlesnake', 'cheerful', 'fiber', 'elec', 'trip', 'legacy', 'distinctly', 'proponent', 'virtue', 'spade', 'humor', 'intend', 'robe', 'driveway', 'henrietta', 'accelerator', 'competition', 'ecclesiastical', 'oedipus', 'bend', 'core', 'grown', 'wrinkle', 'move', 'pleased', 'cincinnati', 'porter', 'medicine', 'quartet', 'cappy', 'post', 'ensure', 'continent', 'peaked', 'shin', 'bandit', 'motel', 'dock', 'overhaul', 'subtle', 'cromwell', 'adaptation', 'approach', 'know', 'disobedience', 'pump', 'maine', 'drawing', 'ledger', 'shovel', 'integral', 'pushup', 'copernicus', 'detective', 'extends', 'tapped', 'exemption', 'se', 'rush', 'favre', 's', 'make', 'confederation', 'bishop', 'pave', 'halt', 'delayed', 'cycle', 'sheldon', 'fish', 'picture', 'approximation', 'form', 'pilgrim', 'behind', 'larva', 'counterpart', 'shorter', 'sandwich', 'baroque', 'ax', 'smack', 'governor', 'tektite', 'beef', 'sunny', 'affection', 'correspond', 'train', 'building', 'dictate', 'inspector', 'loosely', 'impute', 'approximately', 'curtain', 'joseph', 'forthcoming', 'hurricane', 'emerald', 'istiqlal', 'collage', 'risk', 'keel', 'interlock', 'strive', 'cushion', 'brandon', 'twodigit', 'spent', 'dangerous', 'biological', 'tactual', 'leg', 'thereafter', 'knock', 'sniffed', 'seventeen', 'mop', 'slipper', 'anticommunist', 'secretly', 'grateful', 'target', 'twirl', 'workable', 'shipping', 'historic', 'cottage', 'elevate', 'ritter', 'pursuant', 'advantageous', 'illuminate', 'exact', 'completion', 'notable', 'substitute', 'bless', 'amuse', 'ernest', 'catholicism', 'tail', 'restoration', 'peaceful', 'rector', 'blind', 'machine', 'elaborately', 'experimental', 'marina', 'sen', 'synthesis', 'unhappily', 'precinct', 'consultant', 'stun', 'theyd', 'rupee', 'max', 'entire', 'hill', 'rabbi', 'switch', 'elementaryschool', 'vienna', 'steel', 'bald', 'pig', 'privileged', 'haste', 'glen', 'election', 'envelope', 'pp', 'mary', 'sidewise', 'admit', 'jurisdiction', 'skid', 'archaeology', 'slope', 'kindness', 'bizarre', 'way', 'incapable', 'prairie', 'interruption', 'spite', 'intervene', 'hernandez', 'rupture', 'canada', 'excessive', 'verse', 'gospel', 'theorem', 'gaiety', 'german', 'weep', 'partly', 'mining', 'document', 'trivial', 'hard', 'centralize', 'wooded', 'neglect', 'deliver', 'eh', 'aim', 'avoidance', 'lincoln', 'jane', 'claim', 'alveolar', 'mock', 'hotei', 'privilege', 'emphasize', 'straw', 'partnership', 'king', 'gay', 'weve', 'torment', 'land', 'vince', 'chamber', 'trading', 'geneva', 'av', 'gallium', 'magnificent', 'childrens', 'philadelphia', 'magnitude', 'plague', 'vanish', 'spoilage', 'cold', 'loop', 'intelligence', 'ballot', 'quality', 'inclined', 'autumn', 'convert', 'congregation', 'prospect', 'sat', 'sort', 'collection', 'brass', 'erotic', 'analogous', 'prescription', 'grouped', 'merchandising', 'stitch', 'positivist', 'bard', 'absorb', 'berman', 'globulin', 'remark', 'monsieur', 'intermediate', 'pen', 'sever', 'tumble', 'elevator', 'frieze', 'bathroom', 'episode', 'accessory', 'alive', 'diarrhea', 'skyline', 'bank', 'secant', 'think', 'breast', 'labor', 'street', 'lance', 'surprised', 'columbia', 'lagoon', 'slim', 'immensely', 'pattern', 'aide', 'healthy', 'scramble', 'happy', 'midway', 'citation', 'strenuous', 'beowulf', 'money', 'franklin', 'america', 'numerical', 'ireland', 'incredible', 'bear', 'cm', 'caldwell', 'activity', 'delegate', 'expedient', 'erosion', 'chancellor', 'tendency', 'famed', 'transducer', 'analogy', 'berlin', 'dietrich', 'pamphlet', 'demographic', 'dialect', 'situs', 'chicken', 'exchequer', 'reply', 'gravely', 'masonry', 'movable', 'parliament', 'british', 'computer', 'evil', 'tournament', 'genuine', 'audition', 'affiliation', 'submit', 'ratio', 'fragile', 'front', 'winslow', 'pike', 'athabascan', 'inspection', 'acquire', 'manifestly', 'deserves', 'new', 'deacon', 'beautiful', 'halfman', 'independently', 'manipulation', 'dame', 'gonzales', 'suspicious', 'calif', 'adjacent', 'category', 'gosson', 'liver', 'firework', 'highschool', 'announce', 'delphine', 'depth', 'anticipation', 'install', 'usage', 'amazement', 'hogan', '<UNK>', 'kay', 'pier', 'distributor', 'turtle', 'disorder', 'apportion', 'unpaid', 'schoolhouse', 'menace', 'weave', 'reality', 'equate', 'gladdy', 'heal', 'manure', 'absorbed', 'interlobular', 'temperature', 'institution', 'cardinal', 'flare', 'ultrasonic', 'registration', 'centrifuge', 'exaggerated', 'solvent', 'facto', 'faust', 'agriculture', 'kirov', 'forum', 'magic', 'grafton', 'point', 'density', 'differs', 'agricultural', 'enforcement', 'fletcher', 'veteran', 'patronage', 'grab', 'crisis', 'compound', 'harrington', 'gust', 'monotony', 'dark', 'pedal', 'innocent', 'encompass', 'adolescent', 'bond', 'michelangelo', 'crow', 'blasphemy', 'doris', 'powell', 'receives', 'today', 'speedy', 'friday', 'grownup', 'prosperity', 'architecture', 'readymade', 'credit', 'decorator', 'awake', 'kyoto', 'ask', 'discrepancy', 'hesiometer', 'blade', 'seldom', 'depend', 'text', 'delude', 'microscopically', 'gunfire', 'hundred', 'cunning', 'golfer', 'youth', 'crown', 'strength', 'hell', 'priority', 'paul', 'succumbed', 'sing', 'protein', 'mansion', 'reversible', 'streetcar', 'traveler', 'celebration', 'holy', 'bust', 'authorization', 'moritz', 'shirt', 'storage', 'revolve', 'solace', 'saving', 'context', 'clatter', 'seal', 'proper', 'splash', 'uranium', 'lens', 'typical', 'stomach', 'martyr', 'amateur', 'month', 'conceal', 'tenure', 'preserve', 'food', 'poland', 'ole', 'participation', 'lion', 'bourbon', 'optimum', 'rusk', 'statutory', 'obanion', 'tube', 'offensive', 'epidemic', 'cherished', 'obviously', 'institute', 'ohio', 'reference', 'symbolically', 'hydride', 'outer', 'familiar', 'warfare', 'appal', 'moss', 'ethnic', 'coefficient', 'shrine', 'ceasefire', 'sport', 'comprehend', 'daylight', 'aperture', 'slug', 'patriotism', 'endorse', 'cheap', 'destroyed', 'wise', 'clark', 'yesterday', 'proposal', 'ban', 'evidence', 'symptomatic', 'listing', 'hot', 'merit', 'mustard', 'depressed', 'sicilian', 'bankruptcy', 'frank', 'earthquake', 'weary', 'basketball', 'parkway', 'trance', 'professional', 'drugstore', 'footnote', 'series', 'swim', 'telescope', 'bad', 'eminent', 'browning', 'disarmament', 'endlessly', 'incorporate', 'fry', 'sorry', 'pageant', 'kentucky', 'dangle', 'segment', 'da', 'year', 'refugee', 'transform', 'errand', 'faintly', 'swallow', 'step', 'churchill', 'recover', 'tooth', 'keen', 'nightmare', 'mastery', 'sp', 'xydis', 'mythological', 'middleclass', 'choose', 'salt', 'assures', 'athletic', 'mule', 'dancer', 'drunk', 'anatomical', 'castro', 'sentence', 'gorboduc', 'upheld', 'endear', 'vessel', 'diplomacy', 'associate', 'roof', 'triple', 'indelible', 'lately', 'surge', 'privacy', 'noncatholic', 'hire', 'shrewd', 'contention', 'thought', 'expressive', 'refers', 'rob', 'incentive', 'penetrate', 'salami', 'lucille', 'redhead', 'automation', 'illustrate', 'quill', 'soften', 'tremble', 'monastic', 'ham', 'sox', 'discredit', 'anguish', 'argues', 'toy', 'superstition', 'baptist', 'dot', 'venice', 'consensus', 'elbow', 'contrast', 'castle', 'connection', 'corinthian', 'procommunist', 'royalty', 'daughter', 'compact', 'thank', 'bitter', 'rd', 'acquaintance', 'inner', 'clever', 'howl', 'irresistible', 'chromatic', 'iron', 'satisfied', 'log', 'naive', 'catastrophe', 'ever', 'anta', 'nonspecific', 'kehl', 'although', 'distinction', 'wtv', 'la', 'muffle', 'dialysis', 'potent', 'others', 'aspect', 'arrangement', 'mail', 'spindle', 'sincerity', 'shout', 'sacrifice', 'badly', 'flip', 'ear', 'coronary', 'broad', 'amen', 'richert', 'existential', 'excess', 'pottery', 'guardian', 'bull', 'poetry', 'arrives', 'skeptical', 'tour', 'tolerant', 'angrily', 'electric', 'della', 'jar', 'clash', 'apprehension', 'repeat', 'christ', 'outstanding', 'drum', 'inexplicable', 'television', 'curb', 'commercially', 'automotive', 'infection', 'insistent', 'proposes', 'transaction', 'chant', 'chapter', 'superimpose', 'allows', 'disconcert', 'subjectively', 'municipality', 'wisely', 'conceivable', 'pastoral', 'american', 'workman', 'rustle', 'whiskey', 'dogtown', 'anxious', 'earnestly', 'airborne', 'hospital', 'toward', 'optimism', 'nail', 'broke', 'slum', 'abstract', 'maximize', 'materialism', 'ring', 'compiler', 'toronto', 'regardless', 'forerunner', 'compulsory', 'journalism', 'thirteen', 'hawk', 'working', 'aircraft', 'consecutive', 'mason', 'delaware', 'hetman', 'sway', 'wednesday', 'card', 'khrushchev', 'map', 'graphic', 'pan', 'van', 'layman', 'thyroglobulin', 'habitual', 'amount', 'carriage', 'feeble', 'able', 'irony', 'composer', 'seventh', 'appearance', 'hessian', 'figure', 'hold', 'inventory', 'alienation', 'glass', 'voice', 'funny', 'robinson', 'strict', 'jenks', 'bulge', 'arrange', 'elect', 'conveniently', 'royal', 'weather', 'newer', 'impatient', 'abide', 'bark', 'nevertheless', 'explode', 'bat', 'ossification', 'tempt', 'cowboy', 'haunt', 'bandage', 'inc', 'half', 'crazy', 'idle', 'chilly', 'equipment', 'eastern', 'stone', 'two', 'critical', 'humble', 'informs', 'device', 'aft', 'afford', 'nogol', 'solely', 'allocation', 'un', 'desegregate', 'mixed', 'red', 'grocer', 'successfully', 'mobility', 'breakfast', 'brake', 'crept', 'molecule', 'ben', 'eastwick', 'andrus', 'intensive', 'vault', 'oriole', 'aeration', 'civil', 'harriet', 'meaningful', 'soar', 'propose', 'condensation', 'englishman', 'sweetheart', 'accompaniment', 'fragmentary', 'crackle', 'acid', 'attack', 'saline', 'tilghman', 'progressively', 'attract', 'cooptation', 'stockade', 'monopoly', 'authorize', 'apply', 'shuffle', 'uniformity', 'allout', 'anthropology', 'many', 'barney', 'draper', 'saloon', 'recipe', 'abruptly', 'futility', 'hurry', 'religion', 'chef', 'explicitly', 'inward', 'stereotype', 'editor', 'employment', 'anonymous', 'imply', 'deterrent', 'momentarily', 'jointly', 'town', 'december', 'bellow', 'fit', 'literary', 'center', 'quarter', 'appropriate', 'victoria', 'revise', 'operetta', 'domination', 'cellulose', 'prosperous', 'ripped', 'belgian', 'marie', 'sole', 'central', 'ramble', 'ave', 'popped', 'cod', 'breeze', 'cabinet', 'buddhism', 'styrene', 'painter', 'corporate', 'gap', 'hope', 'shotgun', 'prowl', 'gate', 'fatal', 'doaty', 'oxygen', 'pull', 'resignation', 'spin', 'alam', 'accurately', 'pigment', 'drain', 'orbit', 'seemingly', 'placid', 'tactical', 'producer', 'hypothalamic', 'smoke', 'outboard', 'unanimously', 'arent', 'exclusion', 'mere', 'schizophrenic', 'join', 'primary', 'montpelier', 'c', 'reduction', 'drought', 'expense', 'satisfy', 'architect', 'advent', 'brandy', 'bacteria', 'mutter', 'state', 'david', 'manor', 'sansom', 'narrower', 'umbrella', 'hey', 'axis', 'lot', 'provisional', 'taxation', 'enclose', 'warning', 'announcement', 'admiration', 'fulfillment', 'photochemical', 'threshold', 'assemble', 'chester', 'devotion', 'hoot', 'hotter', 'grievance', 'endure', 'municipal', 'kept', 'eighty', 'interaction', 'ace', 'northerner', 'w', 'generalize', 'mad', 'sovereignty', 'louis', 'unreconstructed', 'caput', 'gasket', 'uniquely', 'inquest', 'brumidi', 'pillow', 'michigan', 'biography', 'morphophonemic', 'hebrew', 'boss', 'smash', 'condense', 'tension', 'surprising', 'hudson', 'sept', 'fertilizer', 'claret', 'embody', 'upstairs', 'spectacle', 'uneasy', 'eighth', 'terry', 'game', 'simplest', 'regression', 'repeal', 'angle', 'doatys', 'larry', 'sprung', 'race', 'industry', 'unlocked', 'encouragement', 'evans', 'proxy', 'plant', 'soprano', 'historically', 'cynical', 'dilute', 'interstate', 'poignant', 'janice', 'pacific', 'issuance', 'grabski', 'frighten', 'greene', 'buffalo', 'carolina', 'shelley', 'panorama', 'williams', 'damn', 'assume', 'subsidy', 'stairway', 'turn', 'gas', 'another', 'dos', 'opening', 'oconnor', 'glaze', 'asia', 'entail', 'murray', 'summarize', 'negligible', 'geographical', 'hoof', 'lantern', 'shepherd', 'delinquency', 'grin', 'architectural', 'corrupt', 'page', 'difference', 'crusade', 'flake', 'supplement', 'extravagant', 'billion', 'allegiance', 'ann', 'tense', 'loading', 'bus', 'surrender', 'french', 'oclock', 'coach', 'tractor', 'soloist', 'snore', 'beverly', 'gratify', 'monday', 'width', 'buckle', 'whenever', 'followup', 'print', 'pont', 'ground', 'coolidge', 'iliad', 'turkey', 'bay', 'less', 'coffee', 'organ', 'multiplication', 'render', 'organize', 'deficit', 'reconsider', 'tenth', 'hum', 'wearily', 'occurs', 'flank', 'contract', 'hung', 'strongly', 'autocollimator', 'radar', 'stole', 'president', 'actually', 'cast', 'mutton', 'paula', 'poetics', 'fill', 'hull', 'graph', 'bin', 'vote', 'immigration', 'inadequacy', 'smooth', 'yearround', 'transition', 'soap', 'propaganda', 'arlene', 'overrun', 'unquestionably', 'tenant', 'prescribed', 'boulder', 'explorer', 'commuter', 'impinge', 'burton', 'whistle', 'complain', 'odor', 'russell', 'pierre', 'boris', 'investor', 'spun', 'shes', 'format', 'vineyard', 'subsection', 'price', 'totalitarian', 'mingle', 'bother', 'invade', 'bound', 'camper', 'reconstruction', 'retreat', 'contingency', 'lengthy', 'painful', 'since', 'medium', 'fuse', 'tingle', 'geometric', 'look', 'cdc', 'rooster', 'possess', 'sit', 'craft', 'optimal', 'thief', 'honeybee', 'crashed', 'pronounce', 'methodically', 'likely', 'subsequently', 'era', 'success', 'thermometer', 'headache', 'missouri', 'mcclellan', 'seed', 'outside', 'detection', 'devote', 'shone', 'ribbon', 'golden', 'toilet', 'constituent', 'constable', 'directs', 'curse', 'arc', 'judge', 'appeal', 'pale', 'zenith', 'alaska', 'docherty', 'mob', 'flour', 'tennessee', 'disrupt', 'balance', 'meynell', 'political', 'italy', 'purchasing', 'thornburg', 'nomenclature', 'casually', 'suspension', 'lublin', 'piano', 'overcast', 'acquaint', 'similarly', 'threw', 'maintain', 'survivor', 'treasury', 'dan', 'md', 'cry', 'carnegie', 'inspire', 'white', 'cooler', 'recite', 'here', 'colonel', 'fortunate', 'rangoni', 'data', 'pack', 'uppermiddleclass', 'contemplation', 'mistaken', 'mythology', 'promise', 'enormous', 'drip', 'hollow', 'blight', 'coating', 'spatial', 'sweet', 'clog', 'installation', 'millidegree', 'defiance', 'doings', 'initiative', 'supervisor', 'selfish', 'military', 'situate', 'farm', 'banker', 'samuel', 'shade', 'vowel', 'monument', 'chestnut', 'freeze', 'silly', 'melody', 'futile', 'newman', 'wellbeing', 'hodges', 'grease', 'widely', 'pelham', 'february', 'grain', 'association', 'wallpaper', 'sell', 'sincerely', 'tuesday', 'absence', 'ideology', 'injection', 'discover', 'manufacture', 'starvation', 'imagination', 'refrigeration', 'immediacy', 'publicly', 'thou', 'pillar', 'ball', 'cradle', 'nearer', 'ph', 'sullivan', 'tammany', 'empire', 'reputation', 'roughly', 'sizable', 'wendell', 'ga', 'therein', 'formidable', 'felicity', 'surprisingly', 'shipment', 'simply', 'paxton', 'mckinley', 'actively', 'relic', 'modify', 'blaze', 'inside', 'barrier', 'congressman', 'tower', 'guilty', 'officiate', 'panel', 'kohnstammpositive', 'exaggerate', 'outbreak', 'treasure', 'shrill', 'restriction', 'fidelity', 'pete', 'perform', 'mast', 'pending', 'hong', 'celebrity', 'watershed', 'vacancy', 'convenient', 'magnify', 'thcentury', 'mature', 'yr', 'jersey', 'grosse', 'ray', 'daniel', 'determines', 'shape', 'bout', 'generous', 'businessmen', 'tear', 'voter', 'essence', 'greer', 'hebephrenic', 'photocathode', 'baton', 'colorado', 'hidden', 'hartsfield', 'vicinity', 'specifically', 'cocktail', 'everybody', 'line', 'attribute', 'darling', 'split', 'restless', 'alike', 'heater', 'sunset', 'mild', 'anecdote', 'haney', 'stove', 'debris', 'neither', 'writing', 'tentative', 'potato', 'quaint', 'pitch', 'personnel', 'blackman', 'patiently', 'rep', 'sag', 'rotary', 'specify', 'ardent', 'garibaldi', 'twentiethcentury', 'hopefully', 'fierce', 'imagery', 'down', 'position', 'victor', 'alienate', 'sky', 'three', 'transparent', 'pupil', 'couperin', 'violence', 'economic', 'pit', 'synagogue', 'competence', 'indirect', 'attire', 'shylock', 'ready', 'enthusiastic', 'astound', 'happiness', 'savannah', 'whod', 'carleton', 'purport', 'vantage', 'jazz', 'dictator', 'withdraw', 'antithyroid', 'richest', 'monotonous', 'farmhouse', 'subgroup', 'fragment', 'tangible', 'imperative', 'sportsman', 'confess', 'classical', 'senate', 'sew', 'bulk', 'wound', 'orchestration', 'give', 'microscope', 'roadway', 'sponsor', 'upton', 'lobby', 'wheel', 'plate', 'rico', 'madison', 'harsh', 'vermejo', 'insert', 'athenian', 'giveaway', 'mutual', 'acceptance', 'unbearable', 'united', 'wont', 'mari', 'chiefly', 'incidence', 'banner', 'conform', 'utter', 'population', 'diversity', 'economy', 'odd', 'appreciate', 'hide', 'conception', 'showdown', 'dugout', 'especially', 'eventually', 'allow', 'rue', 'resemblance', 'billy', 'tentatively', 'casual', 'chocolate', 'forth', 'splinter', 'yugoslav', 'baker', 'pint', 'mann', 'commonwealth', 'providence', 'elemental', 'manager', 'knit', 'perfectly', 'tragic', 'digest', 'teenager', 'highly', 'armament', 'adequately', 'influence', 'freud', 'fifteen', 'lazy', 'fiery', 'violently', 'argue', 'highroad', 'bosis', 'socialization', 'cleaner', 'detach', 'colorful', 'cornell', 'joel', 'suffocate', 'cypress', 'yuri', 'poorly', 'asset', 'givin', 'intellectually', 'see', 'manufacturer', 'pearson', 'brushing', 'preparation', 'enact', 'shame', 'rare', 'clarification', 'gala', 'yokuts', 'op', 'dean', 'persistent', 'pro', 'jim', 'jarrodsville', 'slot', 'glendora', 'beginner', 'shunt', 'guidepost', 'exist', 'strode', 'revive', 'coffin', 'worth', 'express', 'nicolas', 'whereas', 'mechanic', 'divan', 'draft', 'tile', 'frenchman', 'head', 'surveyor', 'cell', 'cop', 'kick', 'advocate', 'vacate', 'parameter', 'businessman', 'study', 'diana', 'scholastic', 'breeding', 'absorption', 'hollywood', 'jefferson', 'taut', 'legislation', 'fine', 'ensemble', 'carla', 'institutional', 'bangjensens', 'cady', 'thirtyfour', 'committee', 'typically', 'pink', 'bump', 'connecticut', 'compile', 'congestion', 'afterwards', 'von', 'oak', 'assign', 'spoil', 'gyp', 'timing', 'desolation', 'toss', 'straight', 'grapple', 'sip', 'gallon', 'scar', 'stalin', 'profess', 'excellence', 'tourist', 'screw', 'helplessness', 'pace', 'hasten', 'constitution', 'explanation', 'switzerland', 'virginia', 'courteous', 'being', 'wholewheat', 'locale', 'sloanaker', 'coin', 'doc', 'practically', 'scenery', 'interlude', 'edwin', 'orleans', 'lightly', 'underwater', 'administrative', 'tank', 'kansa', 'confer', 'occupy', 'ensue', 'intensification', 'fluorescence', 'gon', 'furrow', 'noon', 'weaken', 'teach', 'momentous', 'gadget', 'kayabashi', 'ugly', 'necessity', 'mamma', 'few', 'lodge', 'postmaster', 'smu', 'attention', 'decree', 'clump', 'bomber', 'eg', 'chrome', 'manifestation', 'invasion', 'thatll', 'orchard', 'peanut', 'walk', 'expect', 'roberta', 'ultracentrifugation', 'bold', 'symphonic', 'delhi', 'lighter', 'everyone', 'magical', 'curia', 'theyre', 'close', 'cruiser', 'mayor', 'accommodation', 'butler', 'los', 'persists', 'neurosis', 'willingness', 'writ', 'centrally', 'us', 'denote', 'romance', 'salvage', 'peck', 'replacement', 'principle', 'challenged', 'anglican', 'taxfree', 'herald', 'ballistic', 'aug', 'warren', 'epithet', 'convincing', 'conscientious', 'detect', 'bug', 'canon', 'b', 'carpenter', 'cosmic', 'harold', 'adult', 'master', 'conrad', 'flemish', 'taller', 'law', 'twentytwo', 'water', 'exists', 'snelling', 'motion', 'clinical', 'curriculum', 'cool', 'abrupt', 'sings', 'timothy', 'verify', 'foot', 'theatre', 'happens', 'bony', 'earnest', 'keynote', 'evidently', 'archbishop', 'teen', 'dramatically', 'space', 'living', 'technology', 'california', 'successor', 'lenin', 'flame', 'patriot', 'pulse', 'groom', 'lizzie', 'carl', 'inactive', 'withdrew', 'extension', 'accrue', 'embodiment', 'irregularly', 'acre', 'besides', 'brannon', 'rally', 'singer', 'brood', 'angel', 'fundamentally', 'incite', 'rate', 'vest', 'preferable', 'reunion', 'blanket', 'blend', 'five', 'premium', 'cooper', 'vague', 'private', 'boast', 'discard', 'lucky', 'tallyho', 'disgust', 'mention', 'business', 'contour', 'clarity', 'create', 'involvement', 'hitter', 'jaw', 'engineering', 'papal', 'remove', 'monthly', 'mount', 'forest', 'mercenary', 'soak', 'socially', 'trunk', 'cigar', 'yearly', 'flee', 'intuitive', 'cautiously', 'selkirk', 'instrumental', 'donate', 'chorus', 'attractive', 'homemaker', 'platoon', 'polyphosphate', 'casework', 'evaluate', 'admirable', 'x', 'crisp', 'revolution', 'underdeveloped', 'flutter', 'communicative', 'tough', 'accelerate', 'instance', 'identity', 'escape', 'rehabilitation', 'extreme', 'knelt', 'abuse', 'inevitable', 'stand', 'contributes', 'differentiation', 'later', 'dam', 'copenhagen', 'missionary', 'perspective', 'cylindrical', 'warrior', 'debenture', 'general', 'demonstration', 'non', 'inadequate', 'courtier', 'bathing', 'sensor', 'distortion', 'twenty', 'claimed', 'lauderdale', 'sought', 'cooked', 'resistance', 'amendment', 'portray', 'interface', 'implication', 'wry', 'evangelism', 'declares', 'write', 'fighter', 'newport', 'quicker', 'craftsmanship', 'handley', 'interdependent', 'pedersen', 'indoors', 'jake', 'band', 'stack', 'pregnant', 'intangible', 'vocal', 'almighty', 'goat', 'batten', 'hulk', 'politically', 'gasoline', 'competitive', 'confusion', 'subordinate', 'utopian', 'countryman', 'internally', 'episcopal', 'omission', 'old', 'gorgeous', 'radish', 'hypothalamus', 'covet', 'sailor', 'payment', 'maximization', 'housewife', 'prince', 'inauguration', 'rid', 'unified', 'assent', 'mimesis', 'repay', 'legislator', 'patient', 'righteousness', 'humanity', 'superb', 'dignify', 'copper', 'play', 'impeccable', 'pohl', 'phonemic', 'sensory', 'socialist', 'princeton', 'meteor', 'okay', 'flatly', 'insect', 'immense', 'protestantism', 'betrayal', 'mobilize', 'destructive', 'morgan', 'mutually', 'rifleman', 'sensational', 'bent', 'secrecy', 'atlas', 'condemnation', 'wolf', 'wreath', 'politely', 'mortal', 'infectious', 'victim', 'glamour', 'academy', 'payne', 'diffraction', 'carve', 'neck', 'jacket', 'rapid', 'furiously', 'identifies', 'contractor', 'maintains', 'coast', 'esteem', 'orator', 'zen', 'pass', 'vow', 'comment', 'sociological', 'muzzle', 'sprinkle', 'sanction', 'suggests', 'meanwhile', 'absently', 'gradually', 'parson', 'perfume', 'othon', 'hohlbein', 'distal', 'recognizable', 'attachment', 'phonologic', 'pork', 'resign', 'weigh', 'rebut', 'term', 'promptly', 'main', 'whisper', 'ignorant', 'pathetic', 'absent', 'morning', 'throne', 'transmit', 'sheriff', 'stacy', 'edythe', 'endless', 'tax', 'clip', 'restraint', 'gal', 'annoy', 'anything', 'timber', 'judging', 'dylan', 'shaft', 'jacoby', 'aqueous', 'comrade', 'church', 'establishment', 'competent', 'philosophic', 'baltimore', 'pm', 'seattle', 'depress', 'proverb', 'shear', 'madrigal', 'find', 'individualist', 'facility', 'peel', 'however', 'teenage', 'tray', 'injustice', 'insane', 'juvenile', 'reminds', 'radiation', 'layout', 'gradient', 'functional', 'earl', 'texas', 'barco', 'quietly', 'friend', 'gravity', 'dumped', 'severely', 'bottom', 'stretch', 'lessen', 'noble', 'aerial', 'burma', 'fee', 'branch', 'originally', 'unite', 'plug', 'number', 'placename', 'call', 'stride', 'straightforward', 'instruction', 'prelude', 'tore', 'mahzeer', 'teaching', 'jason', 'gaunt', 'kitten', 'apprentice', 'weed', 'highland', 'poll', 'salvation', 'sonar', 'teeth', 'decline', 'katherine', 'stain', 'johnson', 'handful', 'fast', 'educational', 'racial', 'politician', 'bible', 'chatter', 'commonplace', 'meat', 'westfield', 'observation', 'meek', 'psyche', 'uncle', 'crombie', 'builder', 'entirely', 'wrench', 'cause', 'obnoxious', 'readily', 'fold', 'decorative', 'duly', 'deal', 'change', 'gamble', 'exclusively', 'sick', 'laugh', 'scrap', 'benson', 'war', 'anniston', 'unhappy', 'fare', 'demon', 'pursue', 'legal', 'stagger', 'partial', 'hemphill', 'determine', 'chandler', 'grunt', 'riddle', 'variety', 'puerto', 'listen', 'tiger', 'shrug', 'illustration', 'demand', 'hazard', 'pioneer', 'italian', 'martini', 'monitor', 'slightest', 'spread', 'rigorous', 'crouch', 'scoot', 'outset', 'offering', 'martian', 'id', 'bong', 'cave', 'conservatism', 'mccormick', 'feature', 'admissible', 'tony', 'decoration', 'wink', 'vaginal', 'subjective', 'fuzzy', 'autonomy', 'amplifier', 'korea', 'field', 'compete', 'aristotle', 'overly', 'coughlin', 'try', 'mortgage', 'ideal', 'dream', 'faith', 'sesame', 'probe', 'narrow', 'reasonable', 'dose', 'faster', 'wisman', 'barcos', 'digby', 'blunder', 'guilt', 'mountainside', 'stature', 'shafer', 'bestow', 'bastard', 'fantastic', 'realistically', 'reveals', 'avoid', 'infrared', 'inaction', 'finale', 'pituitary', 'concur', 'treaty', 'historian', 'imagine', 'irenaeus', 'agglutinin', 'generation', 'illinois', 'adequate', 'saturation', 'frankfurter', 'electricity', 'thy', 'investigation', 'combine', 'eleanor', 'peripheral', 'velocity', 'brazil', 'police', 'idiom', 'faculty', 'intensity', 'enjoy', 'shoulder', 'congressional', 'immortality', 'phillips', 'best', 'registrant', 'roosevelt', 'debt', 'disagree', 'flux', 'courage', 'grandmother', 'modification', 'kitty', 'popularly', 'luggage', 'turkish', 'desire', 'calhoun', 'incoming', 'cherish', 'soup', 'experimentation', 'andrena', 'retention', 'vine', 'counter', 'simultaneously', 'crossroad', 'stillness', 'succession', 'rank', 'philip', 'disappear', 'liaison', 'retail', 'awkwardly', 'western', 'grimace', 'convince', 'algerian', 'bonn', 'goldberg', 'berry', 'arm', 'cage', 'fig', 'cavalry', 'monkey', 'wool', 'georgia', 'individually', 'texture', 'pest', 'preamble', 'station', 'lawrence', 'multiplicity', 'nitrogen', 'nbc', 'saxon', 'spokesman', 'chance', 'classmate', 'properly', 'abolish', 'lush', 'purely', 'eight', 'fear', 'separate', 'pleasant', 'occasion', 'relinquish', 'admire', 'supervise', 'sweater', 'sustain', 'james', 'orthography', 'owner', 'thompson', 'debutante', 'louisville', 'utopia', 'strategy', 'bernard', 'athens', 'derives', 'gary', 'eclipse', 'railway', 'frown', 'cabana', 'action', 'art', 'supper', 'thirtyfive', 'operates', 'god', 'showmanship', 'bidder', 'brotherhood', 'swirl', 'expend', 'teamster', 'award', 'headquarters', 'furnace', 'range', 'offense', 'though', 'dance', 'inhabitant', 'fromm', 'succeed', 'pill', 'heighten', 'annoyance', 'hart', 'theft', 'sciencefiction', 'borden', 'dynamic', 'drastically', 'frail', 'candidacy', 'suffice', 'borrowing', 'washington', 'cousin', 'beggar', 'publicize', 'nostalgic', 'intent', 'reserve', 'walton', 'slop', 'spiritually', 'supernatural', 'dramatic', 'refresh', 'cape', 'much', 'impress', 'bedtime', 'loosen', 'participant', 'guam', 'warmth', 'slick', 'selden', 'bienville', 'capone', 'paramagnetic', 'shakespeare', 'publish', 'slide', 'gown', 'spontaneity', 'captain', 'arthur', 'dillon', 'fatty', 'chair', 'code', 'calmly', 'havana', 'opposition', 'slippery', 'solemn', 'reporting', 'lightning', 'involution', 'patchens', 'elderly', 'ralph', 'disease', 'roy', 'fourth', 'jury', 'akin', 'prokofieffs', 'dead', 'passenger', 'pegboard', 'spectator', 'different', 'kerosene', 'shapeless', 'recur', 'bubble', 'gapt', 'downtown', 'host', 'normally', 'evaluation', 'somebody', 'speak', 'enlist', 'fifty', 'status', 'support', 'rag', 'conscious', 'sadie', 'utilization', 'jig', 'mistake', 'democratic', 'genetic', 'hugh', 'lie', 'request', 'preliminary', 'hr', 'jay', 'imperial', 'acknowledge', 'antiparty', 'address', 'saviour', 'brave', 'inconsistent', 'decrease', 'budapest', 'organization', 'sherlock', 'cleaning', 'fork', 'care', 'blindness', 'safe', 'fort', 'meaning', 'buzz', 'trademark', 'critic', 'dental', 'corruptible', 'enhance', 'efficiency', 'protestant', 'informal', 'bogey', 'bride', 'fountain', 'stupidity', 'shakespearean', 'paw', 'lend', 'foolish', 'cathy', 'coverage', 'economically', 'include', 'confidence', 'opium', 'quo', 'investigator', 'ctca', 'immature', 'fight', 'minnesota', 'ancient', 'sensuality', 'duty', 'break', 'stimulation', 'variable', 'probation', 'graduate', 'ultimate', 'show', 'copy', 'sturdy', 'infringement', 'mountain', 'stranger', 'gush', 'chord', 'flexible', 'arrest', 'niece', 'socialclass', 'mae', 'pope', 'disappointment', 'workmanship', 'twoyear', 'green', 'guy', 'entirety', 'depends', 'shopping', 'dense', 'native', 'felt', 'astonish', 'learns', 'north', 'morton', 'ceiling', 'ransack', 'clayton', 'degreesc', 'management', 'fille', 'suggestion', 'industrialize', 'qualify', 'determination', 'overreach', 'jack', 'foremost', 'accelerometer', 'compassion', 'porch', 'welfare', 'heed', 'symphony', 'light', 'prevents', 'london', 'buggy', 'convey', 'deduce', 'brick', 'technological', 'rodent', 'burn', 'inferiority', 'downright', 'integrity', 'inmate', 'brow', 'quarterback', 'brush', 'contribution', 'disc', 'preposterous', 'stoicism', 'owen', 'nationalism', 'germanic', 'mighty', 'stable', 'winchester', 'comfortably', 'pa', 'mandate', 'scholarly', 'monroe', 'phil', 'alternately', 'stop', 'lane', 'observes', 'compress', 'horizontal', 'radically', 'cling', 'devise', 'fin', 'knight', 'leo', 'bronchus', 'govern', 'coward', 'mess', 'maximum', 'preventive', 'enormously', 'whitey', 'ford', 'extremely', 'almost', 'restrictive', 'trend', 'fiscal', 'mysterious', 'overture', 'texan', 'wouldnt', 'hesitation', 'reactor', 'speaks', 'intimately', 'masterpiece', 'squeeze', 'horror', 'vinegar', 'conspiracy', 'equilibrium', 'diplomat', 'unlike', 'beverage', 'rockefeller', 'solo', 'domain', 'raymond', 'repel', 'finelooking', 'va', 'pb', 'paramount', 'researcher', 'yearold', 'workshop', 'advantage', 'morphophonemics', 'bucket', 'dry', 'dreadful', 'contractual', 'middle', 'styka', 'maid', 'jug', 'operating', 'advice', 'opera', 'delicacy', 'irrelevant', 'nationally', 'sexual', 'huge', 'thorough', 'third', 'wept', 'proportionate', 'ripe', 'say', 'reputable', 'threaten', 'hierarchy', 'drier', 'obligation', 'consequently', 'traditional', 'remains', 'steal', 'hows', 'strictly', 'dwindle', 'forecasting', 'load', 'respond', 'eddie', 'tender', 'fixture', 'revel', 'province', 'semantic', 'ionize', 'also', 'carbine', 'marker', 'alone', 'nassau', 'tone', 'smoothly', 'bern', 'apt', 'oral', 'relieve', 'tar', 'convenience', 'staircase', 'mussorgsky', 'played', 'route', 'understandable', 'scrub', 'various', 'publicity', 'killpaths', 'certificate', 'demonstrate', 'graduation', 'nick', 'anniversary', 'twostory', 'cambridge', 'policeman', 'redcoat', 'credo', 'irresponsible', 'regime', 'impurity', 'bloc', 'source', 'zinc', 'employer', 'large', 'austin', 'laid', 'reliance', 'miriam', 'gain', 'strait', 'babe', 'appoint', 'simplify', 'musician', 'comin', 'repression', 'keelson', 'confederate', 'aimless', 'gray', 'temporarily', 'pierce', 'invariant', 'czarina', 'worn', 'fair', 'yankee', 'cheek', 'average', 'membrane', 'discern', 'udall', 'blush', 'patronize', 'disadvantage', 'reader', 'brutality', 'creativity', 'special', 'promising', 'maker', 'final', 'beebread', 'drizzle', 'inaugural', 'diameter', 'induction', 'refuse', 'pencil', 'spell', 'rig', 'recall', 'expose', 'liable', 'translate', 'pure', 'reception', 'currency', 'rely', 'ago', 'salesman', 'tell', 'republican', 'unwanted', 'gentile', 'truth', 'shoreline', 'parliamentary', 'comprehensive', 'machinist', 'end', 'nonsense', 'h', 'warrant', 'square', 'nowhere', 'sioux', 'ministry', 'paris', 'taxi', 'rotunda', 'mentally', 'favorite', 'somers', 'analyst', 'prone', 'whisky', 'nervous', 'throat', 'savage', 'thumb', 'ticket', 'marriage', 'hillside', 'chapman', 'sample', 'isnt', 'upward', 'never', 'definitely', 'unconsciously', 'temperament', 'marsh', 'alexander', 'grudge', 'sin', 'bias', 'piepsam', 'lid', 'replace', 'instructor', 'open', 'dial', 'yacht', 'japanese', 'articulate', 'et', 'interpreter', 'intention', 'condition', 'asleep', 'dealer', 'fresco', 'reflex', 'bully', 'intercept', 'transfer', 'lad', 'interrelation', 'federal', 'intact', 'alice', 'recreation', 'twentyone', 'allowance', 'coat', 'benjamin', 'secure', 'reckless', 'headlight', 'control', 'syndicate', 'basement', 'alter', 'fielder', 'unload', 'na', 'palm', 'andrew', 'characteristically', 'motivate', 'sol', 'accumulate', 'foreseen', 'opportunity', 'theoretical', 'sadness', 'introduce', 'enforce', 'snake', 'publishing', 'suburb', 'reproduce', 'mist', 'happen', 'dilemma', 'january', 'dreadnought', 'inn', 'costly', 'physic', 'applicant', 'damp', 'maxwell', 'disliked', 'j', 'basically', 'perch', 'unsatisfactory', 'killer', 'stalk', 'dimly', 'dash', 'narrator', 'actor', 'mission', 'parenthood', 'organification', 'path', 'journalist', 'insight', 'scotland', 'altogether', 'complicity', 'plane', 'vanished', 'titan', 'lumber', 'feast', 'obeyed', 'technical', 'al', 'montero', 'controller', 'herd', 'jowl', 'columnist', 'hint', 'described', 'honestly', 'fails', 'perhaps', 'actress', 'take', 'speculative', 'comfortable', 'subdivision', 'fourteen', 'mar', 'diane', 'park', 'harvard', 'hose', 'paradigm', 'hutchins', 'clarence', 'developed', 'ingenious', 'entitle', 'sorbed', 'ruling', 'mao', 'graham', 'strap', 'proud', 'favorable', 'accounting', 'happily', 'el', 'usefulness', 'arterial', 'violate', 'torso', 'exhaust', 'oppression', 'portrait', 'pressure', 'adviser', 'soul', 'every', 'stability', 'mailbox', 'april', 'jump', 'narrowly', 'magnificently', 'tougher', 'usually', 'juror', 'burnside', 'deliberation', 'steichen', 'skyros', 'lucien', 'summary', 'couch', 'gavin', 'intrusion', 'afterward', 'sure', 'null', 'mainland', 'adjunct', 'chine', 'psychoanalysis', 'faint', 'nuclear', 'beyond', 'keith', 'blockade', 'prospective', 'freddy', 'byron', 'charm', 'feathertop', 'near', 'mindful', 'vivian', 'top', 'gibby', 'schweitzer', 'korean', 'structure', 'schnabel', 'compost', 'drill', 'terminology', 'barricade', 'allied', 'grotesque', 'coombs', 'foam', 'jenny', 'widespread', 'sound', 'heretofore', 'connect', 'philharmonic', 'outfit', 'communion', 'mercy', 'darkness', 'crave', 'hengesbach', 'waiter', 'glowed', 'repeatedly', 'marvel', 'calculate', 'francisco', 'frenzy', 'crucial', 'wartime', 'spontaneously', 'helium', 'justice', 'acquiescence', 'negotiation', 'bluntly', 'denomination', 'steep', 'wholesome', 'apocalyptic', 'theological', 'dampen', 'delta', 'deed', 'complexity', 'reexamine', 'without', 'hypothetical', 'germany', 'orvis', 'wreck', 'lolotte', 'retain', 'reign', 'home', 'liberal', 'display', 'gently', 'undertaken', 'tall', 'harry', 'anticipate', 'penalty', 'miniature', 'cabin', 'saturday', 'skirmish', 'identification', 'financially', 'prisoner', 'churn', 'vega', 'auspex', 'rocky', 'afternoon', 'thereby', 'congress', 'cholesterol', 'p', 'tremendously', 'athlete', 'complete', 'involve', 'communication', 'constitute', 'milwaukee', 'diffuse', 'declarative', 'watch', 'reminder', 'sheer', 'propulsion', 'theresa', 'unorthodox', 'exclaim', 'distinctive', 'atlantic', 'volatile', 'disperse', 'mouthpiece', 'temptation', 'winston', 'fetch', 'makeup', 'constrictor', 'refusal', 'operation', 'advancement', 'mine', 'scout', 'travel', 'childish', 'science', 'interpretation', 'recruitment', 'sufferer', 'apollo', 'impulse', 'hall', 'persuasion', 'lamp', 'antislavery', 'saint', 'sandal', 'erase', 'supporter', 'suspend', 'olive', 'shower', 'hatch', 'ceremony', 'cork', 'value', 'resistor', 'accumulation', 'maze', 'procedure', 'strikingly', 'beard', 'kremlin', 'hamilton', 'anode', 'expressway', 'reef', 'majestic', 'cavity', 'opponent', 'prosecution', 'enables', 'oil', 'rider', 'kowalski', 'table', 'gracefully', 'moses', 'katanga', 'pretty', 'billing', 'eighteen', 'polynomial', 'overweight', 'yard', 'necessarily', 'side', 'warsaw', 'dread', 'absolute', 'cotton', 'august', 'prefer', 'fragmentation', 'hence', 'gene', 'blonde', 'yow', 'mcbride', 'distinct', 'woman', 'sturley', 'pavement', 'wagner', 'seep', 'refer', 'substantially', 'berger', 'wyoming', 'touch', 'lafayette', 'integrate', 'undesirable', 'taunt', 'posterity', 'infant', 'numbered', 'beauclerk', 'abundant', 'cplane', 'room', 'spherical', 'someday', 'susie', 'departure', 'boycott', 'pulpit', 'dec', 'lamb', 'dimensional', 'suspect', 'fishing', 'gross', 'lay', 'isle', 'em', 'cleveland', 'punch', 'shield', 'division', 'wally', 'judicial', 'dartmouth', 'honeymoon', 'gang', 'admirer', 'eccentricity', 'selfcertainty', 'intimate', 'gibbs', 'pound', 'slow', 'blue', 'invoke', 'acute', 'troubled', 'voting', 'presence', 'luminous', 'morality', 'recital', 'tex', 'commodity', 'fame', 'grows', 'alarm', 'personal', 'bird', 'animal', 'magnum', 'direction', 'lowcost', 'cult', 'welchs', 'gleam', 'commissioner', 'inform', 'pool', 'impartial', 'ram', 'fate', 'nancy', 'burlington', 'encroachment', 'expensive', 'declare', 'dominican', 'candy', 'unlikely', 'minuteman', 'emerges', 'wheeler', 'exercise', 'clay', 'pratt', 'vientiane', 'hiroshima', 'hat', 'weight', 'discus', 'chosen', 'outofdoors', 'flourish', 'accessible', 'grok', 'ammunition', 'questionable', 'fusion', 'herbert', 'wad', 'clock', 'bare', 'margaret', 'skywave', 'gin', 'economics', 'counselor', 'track', 'clothing', 'dominant', 'realtor', 'gum', 'exhibition', 'sent', 'fla', 'memory', 'stake', 'donald', 'viewpoint', 'prod', 'injunction', 'jet', 'scene', 'limited', 'sterile', 'poise', 'climbed', 'escort', 'stern', 'swamp', 'spear', 'feasible', 'metaphor', 'doubt', 'fabric', 'couldnt', 'supposedly', 'customer', 'experimentally', 'bdikkat', 'watercolor', 'arbitrary', 'administration', 'maryland', 'plainly', 'exportimport', 'image', 'sometime', 'certainty', 'catalogue', 'discrete', 'procreation', 'crash', 'hamper', 'selfdiscipline', 'availability', 'unprecedented', 'pause', 'gripped', 'formulate', 'ice', 'australian', 'satellite', 'predecessor', 'penny', 'commission', 'woe', 'divinity', 'electronic', 'changeable', 'former', 'alvin', 'aia', 'multnomah', 'dill', 'katie', 'adios', 'utilized', 'clumsy', 'paint', 'verdict', 'sculpture', 'tennis', 'naked', 'unitarian', 'fly', 'portrayed', 'till', 'yf', 'brodie', 'holden', 'marty', 'property', 'agrees', 'aerate', 'sincere', 'ken', 'ripple', 'valve', 'movement', 'marquis', 'barre', 'six', 'meant', 'earthy', 'taste', 'employee', 'myra', 'cough', 'bridegroom', 'exclusive', 'appropriation', 'salisbury', 'laboratory', 'peril', 'john', 'egg', 'resolve', 'smith', 'hay', 'basic', 'pot', 'parlor', 'useless', 'pat', 'packard', 'burke', 'speck', 'precipitate', 'hunt', 'unconscious', 'documentary', 'rigid', 'upper', 'waist', 'ballet', 'sewer', 'proceeds', 'splendor', 'rake', 'helen', 'block', 'lexington', 'traitor', 'rape', 'additionally', 'ego', 'bacon', 'mccarthy', 'ferry', 'existence', 'blink', 'ordinarily', 'thermal', 'distress', 'stuff', 'economize', 'spirit', 'veer', 'landscape', 'family', 'root', 'disapprove', 'party', 'bullseye', 'ross', 'voyage', 'robber', 'wed', 'experiment', 'fortyfive', 'crime', 'laundering', 'visible', 'cossack', 'bind', 'shortterm', 'violent', 'streak', 'current', 'sally', 'hurl', 'naval', 'charcoal', 'intellectual', 'sensitivity', 'exploit', 'impassioned', 'waterfront', 'sodium', 'nineteenthcentury', 'col', 'herman', 'none', 'precaution', 'dual', 'landmark', 'proceeding', 'ballplayer', 'possible', 'wolfe', 'complication', 'ludie', 'customary', 'homeric', 'encounter', 'disguise', 'marijuana', 'lilac', 'celebrate', 'pilot', 'sung', 'germanium', 'chronicle', 'civilization', 'sterilization', 'vesole', 'lively', 'pasture', 'irrational', 'seaman', 'independence', 'draw', 'commonly', 'residue', 'bursting', 'knowledge', 'probably', 'frantic', 'memphis', 'hem', 'murmur', 'worry', 'young', 'broadly', 'potentially', 'film', 'participate', 'generate', 'jess', 'troop', 'locate', 'shake', 'dwarf', 'grasp', 'unnatural', 'affixed', 'synthetic', 'juanita', 'pail', 'plunge', 'shouldnt', 'gran', 'negro', 'mississippi', 'stereo', 'facet', 'whereof', 'skeletal', 'small', 'defense', 'terrier', 'alternate', 'isaac', 'lecture', 'surgeon', 'motorist', 'physically', 'ballad', 'worthy', 'polaris', 'faction', 'approve', 'airfield', 'hostility', 'attrition', 'pompeii', 'artie', 'youll', 'palace', 'tech', 'harvey', 'bee', 'envy', 'fraction', 'rearrange', 'coincide', 'tide', 'roger', 'wipe', 'krims', 'accreditation', 'tshombe', 'inlet', 'nadine', 'independent', 'arkansas', 'apparent', 'sticky', 'validity', 'spy', 'urban', 'diagnosis', 'galaxy', 'thoughtfully', 'oneinch', 'hug', 'local', 'decide', 'cathode', 'barley', 'shatter', 'superbly', 'adherence', 'trevelyan', 'coroner', 'men', 'unique', 'greatly', 'letch', 'socalled', 'something', 'obanions', 'compulsivity', 'cane', 'collision', 'tyranny', 'lou', 'empirical', 'terror', 'suite', 'sore', 'gravel', 'shu', 'hon', 'cartoon', 'forbidden', 'boulevard', 'gorton', 'proclamation', 'zion', 'beaten', 'carrot', 'additive', 'shiver', 'part', 'laura', 'modest', 'soon', 'lick', 'unaware', 'skill', 'conformist', 'folly', 'newcomer', 'ventilation', 'ride', 'cerv', 'psychology', 'urge', 'ridicule', 'bite', 'yank', 'accept', 'slack', 'foreigner', 'reflection', 'random', 'ed', 'twin', 'wan', 'specific', 'johnny', 'muse', 'plasma', 'presidency', 'joe', 'inhabit', 'jonathan', 'nice', 'motif', 'research', 'embassy', 'grip', 'reactionary', 'female', 'father', 'delivers', 'alumnus', 'solidarity', 'erect', 'definition', 'tattered', 'morse', 'leaf', 'met', 'remarkable', 'ulyate', 'amplify', 'integration', 'squarely', 'bearing', 'press', 'single', 'richer', 'wedge', 'affair', 'killpath', 'purchase', 'exceptionally', 'teammate', 'richard', 'effective', 'marry', 'promote', 'justification', 'align', 'jed', 'divine', 'lewis', 'alert', 'date', 'nod', 'temporary', 'jesss', 'fully', 'oscar', 'tap', 'electronics', 'hooked', 'fiberglas', 'great', 'supreme', 'tibet', 'selfdetermination', 'prize', 'weak', 'ten', 'verb', 'rus', 'registry', 'ionic', 'gentle', 'fell', 'mouse', 'ancestry', 'derby', 'biwa', 'someone', 'atmospheric', 'namely', 'frankfurt', 'escalation', 'relief', 'tapestry', 'output', 'isolation', 'nominal', 'fireman', 'valid', 'comedie', 'copernican', 'crest', 'uncertain', 'buddy', 'pricing', 'inherit', 'marr', 'assumption', 'joyce', 'do', 'hawaii', 'philosopher', 'defines', 'arnold', 'edition', 'endeavor', 'realization', 'interior', 'sixtyone', 'calf', 'sixteenth', 'manhattan', 'administrator', 'ambitious', 'joint', 'patron', 'hamlet', 'european', 'wide', 'fun', 'overhead', 'benefactor', 'professionally', 'wall', 'anew', 'trade', 'photograph', 'rim', 'obsess', 'unsuccessful', 'spice', 'flat', 'deadlock', 'alibi', 'maintenance', 'photographic', 'robert', 'miscellaneous', 'cooperation', 'musket', 'describes', 'purse', 'heap', 'destination', 'jerry', 'extremity', 'pittsburgh', 'septum', 'dominates', 'visit', 'world', 'agreeable', 'twentythree', 'loyalty', 'reduce', 'import', 'loaf', 'thin', 'carmer', 'grope', 'angular', 'corporation', 'similarity', 'four', 'accuracy', 'newark', 'theyve', 'development', 'countryside', 'mandatory', 'plus', 'philosophical', 'contestant', 'knot', 'silver', 'saddle', 'illness', 'mechanism', 'catcher', 'universal', 'government', 'afraid', 'phalanx', 'inhuman', 'politeness', 'relatively', 'japan', 'arrival', 'pam', 'closing', 'dimension', 'presidential', 'deaf', 'bleak', 'social', 'testimony', 'canyon', 'carter', 'earlier', 'liberate', 'wax', 'betrayed', 'fleet', 'trailer', 'nowadays', 'tokyo', 'pony', 'membership', 'revere', 'garrison', 'workbench', 'dirt', 'thereto', 'blow', 'exceptional', 'technique', 'headline', 'explain', 'strangely', 'conductor', 'gentleman', 'cylinder', 'wismans', 'quack', 'rusty', 'addict', 'whatsoever', 'unrelated', 'secular', 'elaine', 'rehearsal', 'suffuse', 'bristle', 'confirm', 'fulton', 'simpkins', 'venus', 'feel', 'fake', 'linear', 'superset', 'cortex', 'starve', 'sandburg', 'oso', 'ominous', 'blizzard', 'regulus', 'catskill', 'shelter', 'sang', 'conservation', 'ache', 'speed', 'responds', 'hank', 'decease', 'barge', 'recreational', 'distort', 'persecution', 'museum', 'differ', 'caress', 'inquire', 'english', 'pile', 'metaphysical', 'publiclimit', 'isolated', 'spill', 'backlog', 'gage', 'compute', 'obscure', 'doorway', 'turnpike', 'dystopian', 'legislature', 'radioactive', 'booth', 'criticism', 'drawer', 'highway', 'dependence', 'menshikov', 'tract', 'profound', 'metal', 'mosque', 'statistical', 'vertical', 'prior', 'vas', 'cleanse', 'ordinance', 'sullen', 'dispel', 'beer', 'garbage', 'bombing', 'scale', 'julian', 'impose', 'denies', 'centimeter', 'graf', 'punishment', 'expire', 'attach', 'lit', 'curiosity', 'puritan', 'willow', 'pantheon', 'gubernatorial', 'nasty', 'stool', 'applies', 'command', 'acceleration', 'administer', 'stick', 'big', 'kasavubu', 'horace', 'silhouette', 'willis', 'toe', 'dime', 'hymn', 'slam', 'unfair', 'extend', 'perennial', 'put', 'nilpotent', 'hero', 'towel', 'sleep', 'bodily', 'enlarge', 'gregs', 'relegate', 'jam', 'security', 'little', 'btu', 'alcove', 'hiss', 'nickel', 'stream', 'collective', 'vend', 'hormone', 'delighted', 'hartweger', 'abandon', 'unchanged', 'tool', 'incidental', 'boxcar', 'confession', 'mathematical', 'particle', 'collins', 'albany', 'cake', 'israel', 'garth', 'ambassador', 'student', 'approval', 'cooperative', 'solution', 'papa', 'denunciation', 'broadcast', 'legitimate', 'lao', 'england', 'slept', 'factor', 'ward', 'constitutes', 'thrown', 'elimination', 'arise', 'emperor', 'tommy', 'spanish', 'formation', 'search', 'satisfactorily', 'practical', 'varied', 'nikita', 'sixty', 'polished', 'excellent', 'enemy', 'bunk', 'untouched', 'argon', 'catatonia', 'milk', 'dilution', 'nineteenth', 'aureomycin', 'thing', 'university', 'loudly', 'advisor', 'continuity', 'material', 'quiet', 'district', 'republic', 'method', 'worm', 'lift', 'thence', 'attributable', 'rain', 'atomic', 'possibility', 'faithful', 'serf', 'struggle', 'surprise', 'harmless', 'propagandist', 'vigorous', 'graceful', 'compliance', 'account', 'national', 'lease', 'onestory', 'vulgar', 'foreign', 'gotten', 'regulate', 'lone', 'charlie', 'test', 'permanently', 'nominate', 'onslaught', 'bass', 'finger', 'serpent', 'turner', 'clean', 'forego', 'ship', 'paradox', 'linguist', 'newton', 'secretion', 'weapon', 'bravado', 'reluctantly', 'holmes', 'enclosure', 'persuade', 'accident', 'indicator', 'crawl', 'falcon', 'concert', 'vivid', 'dubious', 'attend', 'pepper', 'author', 'constancy', 'twentyfour', 'seat', 'waste', 'therapy', 'vain', 'bar', 'distribute', 'preference', 'obstruct', 'expel', 'unusual', 'compare', 'partlow', 'uncertainty', 'prohibit', 'singly', 'can', 'calibration', 'blank', 'lace', 'splendid', 'handicapped', 'perceive', 'sector', 'flop', 'damage', 'pry', 'tolerate', 'automatically', 'curt', 'belonging', 'nurse', 'avocado', 'earnings', 'outdoor', 'dick', 'forsythe', 'widow', 'income', 'yc', 'prevail', 'breed', 'tart', 'polish', 'finite', 'slid', 'left', 'accent', 'necessitate', 'loan', 'parasol', 'jackson', 'nature', 'thwart', 'extrapolation', 'itll', 'coupler', 'characteristic', 'george', 'fat', 'fingerprint', 'chaos', 'union', 'lure', 'grassland', 'drove', 'redecorate', 'reluctant', 'married', 'communism', 'tropical', 'temple', 'amend', 'blackout', 'contributor', 'improvement', 'sudden', 'pal', 'promotion', 'classification', 'jeep', 'indie', 'discontent', 'understand', 'cure', 'referral', 'disturbance', 'phase', 'merge', 'particularly', 'dull', 'consciously', 'woodruff', 'appraise', 'cairo', 'fever', 'commemorate', 'carpet', 'profitable', 'sharp', 'unify', 'serum', 'scratch', 'deposition', 'sculptor', 'rib', 'site', 'description', 'backyard', 'temper', 'connoisseur', 'macneff', 'increasingly', 'honorable', 'process', 'mental', 'winner', 'thoughtful', 'mollie', 'assertion', 'manchester', 'girl', 'readiness', 'masculine', 'task', 'presbyterian', 'cautious', 'employes', 'buffet', 'feat', 'similitude', 'stammer', 'allotment', 'man', 'tomb', 'aggressive', 'protect', 'yorker', 'brown', 'somewhere', 'impart', 'token', 'undergraduate', 'unknown', 'matter', 'cripple', 'numerous', 'unfamiliar', 'certainly', 'belch', 'century', 'spark', 'influential', 'planet', 'earn', 'dust', 'polarization', 'psychiatrist', 'gathering', 'prolong', 'beatrice', 'eichmann', 'fume', 'acetate', 'threat', 'relation', 'marx', 'illustrative', 'pilgrimage', 'anatomy', 'interfaith', 'selection', 'remind', 'barnett', 'americana', 'elli', 'garryowen', 'shudder', 'tomato', 'hi', 'handler', 'wiley', 'hate', 'bulky', 'reactivity', 'work', 'glint', 'grandma', 'still', 'foreman', 'proportional', 'retailing', 'fictional', 'federation', 'johnandlinda', 'charity', 'merry', 'free', 'overlook', 'tribute', 'predominantly', 'hillsboro', 'marvin', 'mind', 'glorious', 'outlook', 'barrel', 'speculate', 'trick', 'vulnerability', 'offset', 'pastern', 'muscular', 'suffers', 'murderer', 'addition', 'nationwide', 'short', 'davis', 'scottish', 'doubtful', 'principal', 'chill', 'day', 'india', 'township', 'blown', 'life', 'dislike', 'serene', 'director', 'rather', 'chairman', 'competitor', 'ditch', 'zero', 'alec', 'letter', 'inclination', 'choir', 'airline', 'start', 'z', 'taiwan', 'naturally', 'clung', 'mechanical', 'report', 'dumb', 'sock', 'history', 'esprit', 'feb', 'stage', 'adventurous', 'lead', 'dish', 'clarify', 'handle', 'enjoys', 'sneak', 'pain', 'meager', 'capitalism', 'poetic', 'sober', 'hed', 'profession', 'vacation', 'voltaire', 'desert', 'daytime', 'hez', 'cup', 'closet', 'ala', 'sex', 'beethoven', 'witch', 'sanctuary', 'relaxation', 'plenty', 'chisel', 'wagnerpeyser', 'defeat', 'mix', 'ramey', 'skirt', 'directive', 'eccentric', 'resent', 'christopher', 'divorce', 'squad', 'sum', 'matriculate', 'ivy', 'preoccupation', 'bullet', 'supplementary', 'protrude', 'transportation', 'electrical', 'wart', 'downstairs', 'communist', 'retains', 'rhine', 'stew', 'parking', 'unprepared', 'equation', 'fiedler', 'microscopic', 'pleasantly', 'merchant', 'furthermore', 'elicit', 'brooding', 'kennan', 'argument', 'simplicity', 'alligator', 'liquidate', 'alongside', 'awed', 'inexpensive', 'behavior', 'huff', 'beat', 'creak', 'accommodate', 'plow', 'patterson', 'admirably', 'dad', 'broaden', 'carry', 'largely', 'shine', 'sphere', 'appreciation', 'totally', 'anaconda', 'chromatography', 'claw', 'ryan', 'memorial', 'tucked', 'organism', 'shrink', 'tale', 'diversion', 'rationalize', 'stint', 'road', 'firm', 'plain', 'invent', 'cheaper', 'ridiculous', 'certain', 'sixtyfive', 'dr', 'postwar', 'trustee', 'anxiously', 'emission', 'shell', 'contains', 'insistence', 'differently', 'conquest', 'confident', 'avenue', 'reaction', 'broadcasting', 'chore', 'flexibility', 'chapel', 'periodic', 'failure', 'birth', 'internal', 'career', 'wore', 'moist', 'oval', 'dizzy', 'trig', 'frontage', 'offspring', 'interfacial', 'racket', 'interfere', 'hoop', 'spend', 'proprietorship', 'concord', 'cancel', 'door', 'moisten', 'artificially', 'murder', 'loyal', 'torque', 'inert', 'civic', 'miserable', 'fogg', 'segregate', 'transmission', 'oyster', 'prosper', 'reassurance', 'relate', 'de', 'far', 'wisconsin', 'bale', 'wine', 'uphold', 'establish', 'outburst', 'place', 'exposure', 'sentimental', 'highpriced', 'molesworth', 'privately', 'zing', 'define', 'norton', 'wasnt', 'face', 'linguistic', 'blunt', 'football', 'sting', 'accurate', 'archaeological', 'grudgingly', 'horrify', 'pavilion', 'deductible', 'symbol', 'skinny', 'dedication', 'lengthen', 'machinery', 'enable', 'jammed', 'rebel', 'farewell', 'compel', 'pathology', 'asian', 'settlement', 'rear', 'leather', 'inch', 'lowell', 'bedroom', 'obtain', 'nut', 'relive', 'indianapolis', 'melt', 'news', 'group', 'become', 'quarrel', 'joan', 'conflict', 'clown', 'rh', 'scour', 'submarine', 'ted', 'inference', 'carcass', 'offer', 'alpert', 'inescapable', 'latter', 'ankle', 'deadly', 'badness', 'tappet', 'beneficial', 'latch', 'venture', 'albumin', 'dumont', 'saami', 'camera', 'procurement', 'interference', 'thaw', 'case', 'stewart', 'urgency', 'florida', 'intensify', 'madden', 'claimant', 'sympathize', 'dc', 'spelman', 'cord', 'suggest', 'graveyard', 'improve', 'black', 'increase', 'object', 'airy', 'monster', 'martha', 'menu', 'wrong', 'engineer', 'legendary', 'shred', 'osaka', 'planning', 'drift', 'obvious', 'manual', 'discovery', 'accidentally', 'annually', 'incident', 'visual', 'frequency', 'useful', 'swell', 'countenance', 'hopeless', 'passion', 'boat', 'awe', 'sundown', 'cab', 'militia', 'ie', 'around', 'tally', 'breath', 'ibm', 'yeah', 'smart', 'closeup', 'stevens', 'garland', 'sluice', 'patience', 'boa', 'spit', 'replenish', 'grandeur', 'r', 'swiss', 'goodby', 'thom', 'sensitive', 'ponts', 'phony', 'rooney', 'cliff', 'coalition', 'correspondence', 'glad', 'quest', 'set', 'decomposition', 'candidate', 'unconcerned', 'christianity', 'irregularity', 'son', 'unequivocally', 'benington', 'warp', 'virgin', 'cent', 'confrontation', 'lilian', 'careful', 'whether', 'johnston', 'told', 'everything', 'education', 'designation', 'antique', 'eisenhower', 'undertaking', 'heiser', 'calendar', 'energetic', 'bumblebee', 'likelihood', 'superiority', 'must', 'antiseptic', 'fission', 'beach', 'patrol', 'dress', 'instant', 'sanitation', 'dinner', 'quickly', 'child', 'librarian', 'steam', 'eileen', 'ta', 'embarrassment', 'conjunction', 'refrain', 'definite', 'out', 'impossible', 'schubert', 'challenge', 'caper', 'leyte', 'further', 'watson', 'collaborate', 'brightly', 'mulligan', 'county', 'freed', 'significantly', 'hideous', 'upside', 'ch', 'stock', 'uniformed', 'blower', 'dont', 'beloved', 'sweep', 'pel', 'firearm', 'burial', 'guidance', 'rossoff', 'inquiry', 'suddenly', 'halfhour', 'obey', 'vividly', 'hesitate', 'obedience', 'nude', 'ephesian', 'imaginary', 'guild', 'chris', 'stray', 'dawn', 'drop', 'mama', 'assembly', 'powder', 'askington', 'sidney', 'ab', 'withdrawal', 'del', 'acreage', 'eat', 'goodbye', 'frankly', 'stowey', 'flower', 'insured', 'mass', 'efficacy', 'marble', 'exotic', 'alliance', 'sac', 'overheard', 'brooklyn', 'sharpe', 'criminal', 'tree', 'misery', 'anyhow', 'frame', 'retaliation', 'briefly', 'exert', 'gouge', 'hatred', 'creature', 'mullins', 'kc', 'turk', 'affectionate', 'resin', 'anyone', 'nighttime', 'absurdity', 'corner', 'insist', 'battle', 'peculiar', 'sociology', 'result', 'court', 'solve', 'lieutenant', 'grade', 'relaxed', 'outright', 'flatter', 'recorder', 'allnegro', 'implement', 'realistic', 'andy', 'mankind', 'presently', 'compulsive', 'interamerican', 'pansy', 'parallel', 'miami', 'nevada', 'power', 'expedition', 'instinctively', 'bell', 'par', 'rock', 'tongue', 'introduction', 'chin', 'team', 'mistress', 'clubhouse', 'hearing', 'carvey', 'despite', 'dutch', 'bari', 'pakistan', 'sake', 'bandstand', 'inexperienced', 'release', 'replaces', 'writes', 'freight', 'ya', 'knee', 'hysteria', 'operate', 'consumer', 'shadow', 'radio', 'drink', 'scatter', 'counting', 'calm', 'piazza', 'bluff', 'screech', 'leave', 'vaudeville', 'halfback', 'picket', 'serious', 'treat', 'deposit', 'twelve', 'conveyed', 'consistent', 'pessimistic', 'bathtub', 'python', 'lookup', 'congruence', 'urethane', 'philippine', 'cyclist', 'vue', 'chop', 'furniture', 'sensibility', 'ordain', 'onion', 'club', 'hang', 'cologne', 'trouble', 'trigger', 'france', 'egypt', 'suspicion', 'commute', 'ant', 'restaurant', 'solicitor', 'verbal', 'plentiful', 'terrestrial', 'brute', 'launch', 'sunrise', 'jumped', 'attempt', 'receptionist', 'nostalgia', 'importantly', 'placement', 'predisposition', 'achievement', 'puzzle', 'enactment', 'doctor', 'steele', 'northern', 'sequence', 'goddamn', 'audience', 'patchen', 'nonfiction', 'daily', 'tackle', 'filter', 'tread', 'fe', 'eyebrow', 'participates', 'obstacle', 'criticize', 'blessing', 'gunman', 'requirement', 'stumble', 'performer', 'trader', 'brisk', 'formulaic', 'indifferent', 'cat', 'mixture', 'dominance', 'network', 'pocket', 'apologetically', 'therefore', 'pant', 'compulsion', 'advanced', 'ran', 'stroke', 'passive', 'raise', 'wiry', 'torture', 'wonder', 'declaration', 'diverse', 'cta', 'choreographer', 'glue', 'remember', 'donovan', 'russia', 'use', 'circulate', 'array', 'overt', 'specialist', 'kearton', 'podger', 'hal', 'whats', 'intervention', 'spoken', 'antenna', 'converse', 'isolate', 'who', 'air', 'grabbed', 'amaze', 'count', 'future', 'caribbean', 'reconnaissance', 'uniform', 'resentment', 'specimen', 'mother', 'hitch', 'kizzie', 'alfred', 'vandiver', 'stump', 'trumpet', 'gully', 'houston', 'ranch', 'nose', 'decorate', 'regret', 'stood', 'string', 'littlepage', 'portrays', 'significant', 'resident', 'access', 'rayburn', 'accomplish', 'will', 'secretary', 'remainder', 'hound', 'patch', 'awoke', 'soft', 'typewriter', 'illustrates', 'civilian', 'youthful', 'eve', 'suicide', 'railroad', 'voluntary', 'hypothesis', 'dazzle', 'disclose', 'bobbie', 'already', 'nigger', 'etcetera', 'counteract', 'flyer', 'erupt', 'lifelike', 'ramp', 'emma', 'apron', 'lord', 'infantry', 'reject', 'proudly', 'resource', 'territorial', 'spoon', 'mid', 'silent', 'distaste', 'intricate', 'communicate', 'potential', 'lever', 'unreal', 'comparison', 'uncomfortable', 'writhe', 'ghastly', 'thunder', 'hinge', 'lady', 'disappointed', 'banter', 'electoral', 'tea', 'unavailable', 'traverse', 'hostage', 'pseudophloem', 'monstrous', 'chose', 'poke', 'he', 'appreciably', 'meekers', 'wither', 'weld', 'survival', 'pennant', 'cooky', 'difficult', 'course', 'capture', 'aerosol', 'entry', 'inflict', 'plantation', 'thor', 'upland', 'assert', 'iodine', 'injury', 'adjoin', 'todman', 'clerical', 'exalt', 'tiny', 'wasteful', 'previous', 'might', 'chew', 'dirty', 'displace', 'comparatively', 'leak', 'karns', 'casualty', 'link', 'undermine', 'assumes', 'hike', 'leap', 'sediment', 'immigrant', 'stephen', 'area', 'pair', 'navy', 'confine', 'wrath', 'car', 'th', 'rhythmic', 'experimenter', 'greatness', 'coachman', 'conversation', 'cite', 'hear', 'acrylic', 'meet', 'nucleus', 'affect', 'dave', 'vigorously', 'n', 'justified', 'wright', 'holiday', 'expenditure', 'huddle', 'evanston', 'chuck', 'entity', 'hand', 'barber', 'ridge', 'allege', 'neurotic', 'tame', 'let', 'longer', 'beast', 'select', 'creation', 'comparable', 'one', 'sovereign', 'paradise', 'repute', 'congolese', 'extra', 'eligible', 'vocational', 'prevails', 'metropolitan', 'diversified', 'rocket', 'cafeteria', 'mean', 'dollar', 'balafrej', 'fire', 'northeast', 'good', 'micelle', 'patent', 'ruin', 'doolin', 'characterize', 'worried', 'metropolis', 'binding', 'strong', 'muller', 'abortion', 'henri', 'rhetoric', 'rhythm', 'rigidly', 'metabolite', 'arcade', 'mineralogy', 'abroad', 'gardner', 'rainy', 'active', 'alleviate', 'statistic', 'attorney', 'sprawl', 'confirmation', 'surely', 'hanford', 'disturbed', 'heave', 'indecent', 'carbon', 'essex', 'reliable', 'unpopular', 'ferment', 'penetration', 'dipper', 'owl', 'balloon', 'noise', 'essentially', 'public', 'uncommon', 'narragansett', 'indicates', 'tunnel', 'predict', 'interviewed', 'list', 'flavor', 'pledge', 'subsystem', 'dare', 'brandt', 'morale', 'abundance', 'mill', 'past', 'rise', 'folk', 'phosphate', 'homely', 'bit', 'quirt', 'chart', 'cant', 'moreland', 'generalization', 'oregon', 'burning', 'vitamin', 'bought', 'abstraction', 'annoyed', 'cafe', 'artist', 'excitement', 'rogers', 'statue', 'magnification', 'conjugate', 'rational', 'marginal', 'antagonist', 'distract', 'misconception', 'pastime', 'come', 'tranquilizer', 'lunch', 'christian', 'manpower', 'metaphysics', 'shall', 'dystopia', 'lt', 'stadium', 'oblige', 'biblical', 'corollary', 'certify', 'upset', 'viola', 'honest', 'baptize', 'african', 'cooperate', 'spire', 'congenial', 'ecumenical', 'lilly', 'rehearse', 'tangle', 'due', 'cumulative', 'teacher', 'snow', 'fireplace', 'overwhelmingly', 'torn', 'moore', 'deeper', 'marketing', 'discourse', 'effectiveness', 'longterm', 'britain', 'dialogue', 'duck', 'order', 'cover', 'greeting', 'south', 'tangent', 'emotionally', 'engulfed', 'oven', 'remote', 'lyric', 'palfrey', 'paralysis', 'colt', 'legend', 'concessionaire', 'extrude', 'loses', 'review', 'diffusion', 'checked', 'convict', 'stare', 'unbroken', 'maude', 'proportionately', 'neutral', 'globe', 'beside', 'foster', 'tailor', 'assess', 'estimate', 'spectacular', 'bronchial', 'shave', 'pet', 'substantial', 'decay', 'forecast', 'flock', 'available', 'emile', 'void', 'narcotic', 'desperately', 'sharply', 'chap', 'anderson', 'name', 'dammit', 'grow', 'disregard', 'attain', 'sewage', 'cellar', 'lather', 'goal', 'conductivity', 'dough', 'rousseau', 'opinion', 'type', 'ailment', 'corso', 'midnight', 'magistrate', 'workout', 'cook', 'sugar', 'autistic', 'baer', 'fore', 'kindly', 'outgo', 'outlaw', 'grill', 'mo', 'present', 'boost', 'garry', 'cherry', 'perilous', 'aside', 'nelson', 'belongs', 'confederacy', 'round', 'chic', 'zone', 'distribution', 'destruction', 'champagne', 'sixth', 'pickup', 'stateowned', 'extensively', 'society', 'right', 'shed', 'scan', 'essential', 'brings', 'stir', 'cluster', 'mirror', 'implies', 'micrometeorite', 'purge', 'towne', 'dogma', 'sensible', 'conclusive', 'gather', 'flew', 'confront', 'seek', 'restrain', 'photo', 'morris', 'barren', 'brook', 'planner', 'awfully', 'silence', 'emerge', 'cuban', 'highpitched', 'please', 'pie', 'dosage', 'michael', 'countless', 'else', 'polite', 'medical', 'faulty', 'fiat', 'deliberately', 'petition', 'thursday', 'swarm', 'atom', 'cluck', 'oath', 'assistance', 'bowl', 'sax', 'continuation', 'compression', 'meeker', 'activate', 'confuse', 'denver', 'diamond', 'uhhuh', 'zg', 'hallway', 'wilmington', 'newspaper', 'virtually', 'rome', 'composition', 'snort', 'controversy', 'mexico', 'raucous', 'die', 'whose', 'housekeep', 'majority', 'chinese', 'dive', 'ambush', 'modernization', 'electron', 'check', 'sherman', 'attest', 'cosmetic', 'relationship', 'treatment', 'longrange', 'habitat', 'mystic', 'democrat', 'collect', 'bulwark', 'tucker', 'twentieth', 'fault', 'buffer', 'tristate', 'bring', 'captive', 'hasnt', 'dripped', 'ft', 'custer', 'rhodes', 'rich', 'feudal', 'thurber', 'mathematics', 'systematically', 'consciousness', 'observe', 'reconcile', 'upwards', 'dekalb', 'held', 'comedy', 'professor', 'heidenstam', 'prevent', 'nd', 'battlefield', 'pianist', 'intuition', 'greenwich', 'downhill', 'assimilation', 'lavender', 'publication', 'rumble', 'wire', 'cd', 'rang', 'flick', 'previously', 'inverse', 'explicit', 'coconut', 'refine', 'fluid', 'depict', 'translation', 'tory', 'symmetric', 'selective', 'banquet', 'hoarse', 'printing', 'reform', 'whole', 'collector', 'magician', 'southeast', 'ease', 'follow', 'secede', 'presentday', 'fifth', 'deadline', 'coincidence', 'capability', 'invite', 'exasperation', 'misplace', 'unbreakable', 'bench', 'homer', 'assistant', 'keep', 'compliment', 'luis', 'continued', 'shut', 'drawn', 'bobby', 'sack', 'knuckle', 'tribune', 'male', 'birmingham', 'cubic', 'groove', 'gregory', 'warmly', 'latitude', 'hunter', 'sophomore', 'brilliant', 'decent', 'signature', 'indeed', 'bod', 'revelation', 'fix', 'preface', 'fertility', 'dulles', 'execution', 'cf', 'appointee', 'contribute', 'natural', 'disastrous', 'seminary', 'expand', 'second', 'may', 'gesture', 'dentist', 'provincial', 'maestro', 'handy', 'basis', 'obesity', 'hastily', 'waco', 'sentiment', 'eagerly', 'juet', 'endow', 'margin', 'length', 'porous', 'prison', 'multiple', 'driver', 'quaker', 'exit', 'lee', 'sidewalk', 'nickname', 'interdependence', 'echo', 'conant', 'terminal', 'kind', 'glory', 'espionage', 'bureau', 'gaze', 'furnishes', 'e', 'retard', 'adjust', 'preoccupy', 'impressed', 'reb', 'airplane', 'therefrom', 'compose', 'flurry', 'propagation', 'complaint', 'library', 'degreesf', 'disinterested', 'circumstance', 'irritation', 'design', 'whichever', 'away', 'harris', 'carrier', 'pertinent', 'ascend', 'army', 'clear', 'lump', 'strasbourg', 'tom', 'sabella', 'predictable', 'embarrass', 'missile', 'threedimensional', 'dealing', 'beth', 'pentagon', 'expression', 'primarily', 'purdew', 'skorich', 'painting', 'atmosphere', 'growth', 'heating', 'thud', 'haul', 'vehicle', 'east', 'milton', 'garage', 'unwelcome', 'journal', 'immunity', 'forgotten', 'picked', 'shoot', 'rip', 'unduly', 'flair', 'poker', 'largescale', 'cooking', 'region', 'mostly', 'favorably', 'floor', 'attic', 'lash', 'lose', 'nursery', 'intake', 'nutrient', 'chimney', 'incense', 'drinking', 'undertake', 'city', 'refuge', 'romantic', 'peacock', 'theodore', 'plead', 'script', 'nap', 'superficial', 'window', 'hop', 'schaffner', 'patriotic', 'hoag', 'thanksgiving', 'emory', 'needy', 'lesson', 'linen', 'churchyard', 'congo', 'cubism', 'becomes', 'individualism', 'f', 'prediction', 'profile', 'alex', 'poem', 'deviation', 'citizen', 'wisdom', 'listener', 'vengeance', 'krogers', 'housing', 'environmental', 'assessment', 'entrepreneur', 'hook', 'abbey', 'robbery', 'parker', 'considerable', 'symbolic', 'manipulate', 'pinch', 'vapor', 'arena', 'restorative', 'walker', 'office', 'rameau', 'tetrachloride', 'glisten', 'curl', 'curious', 'interval', 'tip', 'scholar', 'outline', 'disciple', 'reservoir', 'conclusion', 'rode', 'effluent', 'bleacher', 'everyday', 'ounce', 'subsidize', 'embark', 'illiterate', 'grant', 'midst', 'investigate', 'degree', 'discourage', 'pineapple', 'respective', 'disk', 'overall', 'glove', 'clad', 'mark', 'juice', 'love', 'infield', 'thickness', 'palette', 'wealthy', 'gloucester', 'distrust', 'gaudy', 'shortcoming', 'meltzer', 'pursuit', 'profit', 'krim', 'marksman', 'paso', 'grand', 'caliber', 'consequence', 'logic', 'detectable', 'ignition', 'advertising', 'havent', 'feather', 'mantle', 'deputy', 'double', 'anachronism', 'normal', 'traffic', 'taper', 'malocclusion', 'arizona', 'notte', 'lake', 'villain', 'distil', 'quite', 'mel', 'consent', 'additional', 'mcfeeley', 'sentry', 'viet', 'unit', 'hedge', 'volume', 'crowd', 'imitate', 'formally', 'olgivanna', 'distance', 'essay', 'partner', 'indulge', 'need', 'continuous', 'beautifully', 'appendix', 'mulch', 'assail', 'pelt', 'blatz', 'bevel', 'cream', 'withheld', 'even', 'alexs', 'illegal', 'facilitate', 'insulate', 'solid', 'marshal', 'backwoods', 'nc', 'underneath', 'exceeds', 'session', 'squat', 'strip', 'brandishing', 'kenning', 'ther', 'drank', 'commit', 'annual', 'obsolete', 'production', 'outofstate', 'sonofabitch', 'couple', 'nutrition', 'buckley', 'prompt', 'bertha', 'least', 'odds', 'insoluble', 'ingredient', 'revenue', 'instruct', 'clap', 'role', 'complement', 'ruler', 'guaranteed', 'fella', 'busily', 'hadnt', 'recommend', 'bloody', 'rotation', 'doze', 'lover', 'retirement', 'bosom', 'shaw', 'summer', 'manuscript', 'combination', 'ox', 'centum', 'mare', 'literature', 'pay', 'conceivably', 'contest', 'iodide', 'openly', 'probable', 'protection', 'brighter', 'lime', 'gram', 'hughes', 'undergone', 'census', 'minute', 'brilliantly', 'cable', 'introject', 'dedicate', 'health', 'tissue', 'unnecessary', 'litter', 'ash', 'generosity', 'unto', 'gem', 'obtainable', 'yes', 'crib', 'dome', 'constant', 'thanks', 'manhood', 'latin', 'gold', 'holster', 'item', 'responsibility', 'crosby', 'expert', 'seize', 'conviction', 'dog', 'shore', 'worldwide', 'homecoming', 'dodge', 'urbanization', 'mickey', 'thoroughly', 'nymphomaniac', 'dipole', 'craftsman', 'elite', 'ernie', 'incest', 'barbecue', 'championship', 'ambiguity', 'westminster', 'rouse', 'indonesia', 'supervision', 'squire', 'molotov', 'photography', 'clause', 'posterior', 'foe', 'emphasis', 'lauro', 'impact', 'braque', 'preservation', 'disclosure', 'nineteen', 'focus', 'resume', 'tragedy', 'sarah', 'meteoritic', 'touchdown', 'complex', 'total', 'connally', 'firmly', 'corridor', 'deserve', 'oct', 'worship', 'otherwise', 'voluntarily', 'laissezfaire', 'ornament', 'drexel', 'guard', 'oliver', 'built', 'system', 'equity', 'hurt', 'sympathetic', 'query', 'theologian', 'tactic', 'personality', 'antagonism', 'experience', 'summit', 'capillary', 'idea', 'humility', 'spiral', 'abolition', 'scant', 'sale', 'theatrical', 'lobe', 'opposite', 'overcome', 'shock', 'unfortunate', 'picasso', 'residential', 'martin', 'structural', 'rhode', 'yale', 'chip', 'observer', 'violin', 'sinister', 'shortly', 'fitting', 'dispose', 'basket', 'conditioning', 'remedy', 'linden', 'limb', 'riverside', 'lb', 'yalta', 'drunken', 'fervor', 'engage', 'utterly', 'talent', 'marshall', 'minimal', 'banister', 'navigation', 'aboard', 'faulkner', 'key', 'ageold', 'loom', 'condemn', 'jastrow', 'hit', 'comprise', 'bum', 'finish', 'wash', 'formal', 'rugged', 'important', 'elizabethan', 'atlanta', 'strike', 'susceptible', 'tribe', 'daddy', 'arch', 'company', 'freeway', 'ascertain', 'mercury', 'gigantic', 'charley', 'jenkins', 'barefoot', 'negative', 'childhood', 'slice', 'effort', 'training', 'mode', 'cap', 'exactly', 'slash', 'issue', 'elementary', 'huxley', 'inhibition', 'gm', 'textbook', 'calorie', 'dallas', 'overwhelm', 'frustration', 'scarcely', 'liner', 'advise', 'whirl', 'symposium', 'prostitute', 'emerson', 'conference', 'record', 'aloud', 'questionnaire', 'recollection', 'mystical', 'corruption', 'aberrant', 'pea', 'robards', 'net', 'pedestrian', 'commercial', 'dominion', 'notify', 'eye', 'authority', 'reed', 'plaintiff', 'steady', 'engagement', 'dell', 'fan', 'din', 'az', 'antonio', 'anarchy', 'surround', 'bequest', 'positively', 'solidly', 'sir', 'socialism', 'refund', 'antigen', 'bc', 'wharf', 'marine', 'anionic', 'inclusion', 'elegant', 'atop', 'jesus', 'product', 'kong', 'selfhelp', 'cope', 'radius', 'learn', 'itch', 'expansion', 'antiserum', 'boundary', 'senior', 'reach', 'lounge', 'spoke', 'confidential', 'icbm', 'aaron', 'representative', 'evident', 'renew', 'sermon', 'anthony', 'plato', 'descend', 'reduces', 'matilda', 'identifiable', 'periodically', 'notorious', 'wayne', 'bangjensen', 'smell', 'phenomenon', 'ill', 'complexion', 'formulation', 'asks', 'raw', 'induced', 'giffen', 'relevant', 'pin', 'indication', 'fraternity', 'spends', 'greg', 'ashamed', 'financial', 'bitterly', 'indignant', 'trap', 'generously', 'driven', 'perception', 'wonderful', 'plod', 'mound', 'equivalent', 'jealousy', 'high', 'szold', 'rental', 'brightness', 'savor', 'constructive', 'packed', 'clue', 'seven', 'minor', 'epic', 'termination', 'minneapolis', 'topic', 'shaefer', 'belly', 'designate', 'uncompromising', 'sloan', 'formerly', 'household', 'morally', 'sheep', 'size', 'pore', 'malraux', 'aborigine', 'commitment', 'reading', 'wherever', 'thrill', 'blot', 'identical', 'lawn', 'barbed', 'profoundly', 'setback', 'organizational', 'direct', 'protest', 'veto', 'instal', 'remarkably', 'respectively', 'superintendent', 'insurance', 'exclude', 'lesser', 'capitol', 'carefully', 'whoever', 'garden', 'deficiency', 'wealth', 'toynbee', 'service', 'delightful', 'plymouth', 'malaise', 'visibly', 'identify', 'gracious', 'bruckner', 'veil', 'fed', 'interrupt', 'geometry', 'doom', 'gore', 'closely', 'defensive', 'misunderstand', 'story', 'bush', 'examination', 'viewer', 'scheme', 'dickens', 'ho', 'feed', 'get', 'prevot', 'setup', 'mityukh', 'cash', 'shift', 'reorganize', 'creates', 'accompany', 'likewise', 'preside', 'quote', 'remembers', 'developmental', 'norberg', 'ironic', 'ceramic', 'port', 'corresponds', 'attraction', 'permission', 'melancholy', 'violet', 'invitation', 'deeply', 'setting', 'flesh', 'exchange', 'fashionable', 'duplicate', 'frequent', 'sad', 'poultry', 'reason', 'creek', 'whine', 'nellie', 'intercourse', 'restrict', 'falter', 'limit', 'confide', 'bread', 'passport', 'australia', 'horizon', 'job', 'expectation', 'forage', 'separately', 'jumping', 'friendly', 'roast', 'motor', 'employ', 'invest', 'ruthless', 'nonetheless', 'middleaged', 'grey', 'difficulty', 'provoke', 'bomb', 'unless', 'dignity', 'rapidly', 'swift', 'proven', 'augment', 'classic', 'store', 'quint', 'insofar', 'witty', 'affected', 'early', 'twothirds', 'companion', 'unwilling', 'ekstrohm', 'sec', 'onset', 'villa', 'upright', 'fulfill', 'sunlight', 'peer', 'eleven', 'brenner', 'eternity', 'discretion', 'classroom', 'column', 'nation', 'positive', 'reorganization', 'marrow', 'lending', 'inspect', 'shea', 'humorous', 'guide', 'habit', 'troublesome', 'highlight', 'casey', 'enlighten', 'liquor', 'slit', 'judgment', 'mister', 'broader', 'chien', 'newspaperman', 'devil', 'liberation', 'live', 'ownership', 'wear', 'next', 'christiana', 'arlen', 'revolt', 'response', 'adversary', 'guest', 'tablespoon', 'luxury', 'november', 'consist', 'promotional', 'misfortune', 'deja', 'insists', 'efficiently', 'pushpull', 'retire', 'elephant', 'slacken', 'subsistence', 'barbara', 'tolley', 'blossom', 'receiver', 'follower', 'puny', 'officially', 'physical', 'frequently', 'there', 'liberty', 'saturate', 'dwelling', 'hub', 'snatch', 'consult', 'broadening', 'unification', 'linger', 'proportion', 'potter', 'philosophy', 'static', 'drama', 'suitable', 'rent', 'messenger', 'tolerance', 'equality', 'resultant', 'survey', 'closest', 'boston', 'wedding', 'giles', 'attendant', 'husband', 'oklahoma', 'detailed', 'ne', 'wooden', 'cement', 'pollock', 'convention', 'gop', 'wobble', 'novel', 'phoenix', 'prop', 'storm', 'projection', 'gazette', 'preferably', 'construction', 'ultraviolet', 'meal', 'youd', 'meeting', 'meter', 'recent', 'depart', 'agitation', 'v', 'note', 'nicely', 'shriek', 'rite', 'pastor', 'resort', 'merchandise', 'prevention', 'fabrication', 'crimson', 'recently', 'chicago', 'recount', 'armstrong', 'displacement', 'designer', 'dismay', 'penance', 'benefit', 'adolescence', 'historical', 'knew', 'andrei', 'catkin', 'territory', 'grandfather', 'percentage', 'contemporary', 'stronghold', 'july', 'helion', 'testament', 'hardsurface', 'heel', 'novelist', 'affinity', 'score', 'cheer', 'aegean', 'dismiss', 'gilborn', 'sauce', 'alan', 'unfold', 'overseas', 'efficient', 'aunt', 'fbi', 'hut', 'suppression', 'liquidation', 'conspicuously', 'lock', 'primitive', 'repository', 'geographic', 'phosphor', 'frederick', 'distant', 'progressive', 'grigorss', 'discomfort', 'popularity', 'istanbul', 'technically', 'pretend', 'corn', 'burst', 'iodinate', 'blowing', 'optical', 'anterior', 'meditation', 'minimum', 'opener', 'flail', 'algae', 'halfway', 'welch', 'hamrick', 'terminate', 'rack', 'blood', 'concede', 'mammalian', 'norman', 'crush', 'bridge', 'partition', 'nursing', 'spring', 'adelia', 'soviet', 'frivolous', 'clerk', 'reciprocal', 'encourage', 'willie', 'minority', 'roar', 'technician', 'moral', 'revolver', 'saw', 'austere', 'cohesive', 'article', 'worldly', 'gratitude', 'possession', 'colony', 'adamant', 'imaginative', 'reassure', 'calculation', 'sub', 'combat', 'complicate', 'dusty', 'augusta', 'conscience', 'perfect', 'substrate', 'heart', 'finally', 'livestock', 'reasonably', 'true', 'hunger', 'angelo', 'measure', 'creep', 'adverse', 'dump', 'overlap', 'underworld', 'lonely', 'carefree', 'roll', 'bake', 'mold', 'athletics', 'humidity', 'intelligible', 'julie', 'crater', 'snap', 'lo', 'polar', 'piece', 'robbed', 'flash', 'specification', 'rot', 'ryusenji', 'swung', 'nobody', 'entrench', 'develops', 'possibly', 'collar', 'cannery', 'owe', 'mountainous', 'deerstalker', 'correspondent', 'apparently', 'novelty', 'hansen', 'examiner', 'praise', 'really', 'tease', 'europe', 'newsletter', 'griffith', 'duf', 'swept', 'trait', 'depot', 'super', 'frankie', 'fraud', 'supply', 'fidel', 'canadian', 'genius', 'alabama', 'quiver', 'height', 'harper', 'scholarship', 'postpone', 'ballroom', 'slogan', 'semester', 'sweden', 'narrative', 'chunk', 'burden', 'saga', 'steeple', 'simpler', 'helpless', 'exaggeration', 'creator', 'concentrate', 'prosecutor', 'forgot', 'fall', 'engine', 'inscrutable', 'bazaar', 'fascinate', 'fairly', 'help', 'discipline', 'adopt', 'send', 'analyze', 'edward', 'prepared', 'perry', 'regiment', 'nerve', 'recognition', 'merely', 'pennsylvania', 'tag', 'maybe', 'suit', 'hetmans', 'fisher', 'poverty', 'bronze', 'hobby', 'harlem', 'catch', 'pardon', 'civilize', 'cultivate', 'sandman', 'golf', 'tilt', 'shortage', 'roleplay', 'batting', 'swayed', 'mash', 'base', 'register', 'consume', 'prejudice', 'option', 'bates', 'quiney', 'pose', 'save', 'medieval', 'community', 'last', 'intensifier', 'suggestive', 'belong', 'clearing', 'manifold', 'queer', 'explosive', 'gallery', 'instantly', 'clicked', 'hawksley', 'harass', 'trophy', 'systematic', 'stimulus', 'authoritative', 'suvorov', 'abandonment', 'authentic', 'zoo', 'irradiation', 'binomial', 'initiation', 'fearless', 'thomas', 'rope', 'fury', 'danger', 'license', 'bloom', 'reportedly', 'defend', 'environment', 'residence', 'fellowship', 'brought', 'logical', 'jacques', 'demonstrates', 'montgomery', 'village', 'accepted', 'stanley', 'exterior', 'respiratory', 'selfcontained', 'conclusively', 'statement', 'exceed', 'incumbent', 'unlimited', 'rhyme', 'back', 'phedre', 'wilson', 'radiopasteurization', 'divide', 'rod', 'pathet', 'crane', 'squeal', 'ambition', 'indignation', 'relevance', 'precision', 'suds', 'waterway', 'appetite', 'jones', 'eliminate', 'choice', 'cultural', 'joke', 'stabilize', 'realism', 'peculiarly', 'controversial', 'stuart', 'waddell', 'picnic', 'maguire', 'contrary', 'fairway', 'digital', 'ninth', 'flight', 'magazine', 'whip', 'assure', 'newly', 'hurtle', 'mr', 'color', 'realize', 'hour', 'sense', 'generates', 'bermuda', 'message', 'destine', 'attacker', 'psychologist', 'anger', 'astronomical', 'relax', 'depreciation', 'boom', 'eternal', 'bancroft', 'cease', 'nightclub', 'ignore', 'concern', 'dear', 'baby', 'selfconsciousness', 'bypass', 'correlation', 'shingle', 'rejoice', 'exile', 'regularly', 'terrible', 'mph', 'smother', 'plaster', 'lovely', 'user', 'psychological', 'anastomosis', 'depression', 'inflection', 'topography', 'stupid', 'enjoin', 'alteration', 'settle', 'regain', 'safety', 'rarely', 'di', 'defy', 'loot', 'baseball', 'rotate', 'richards', 'nicholas', 'eagle', 'nomination', 'taught', 'chemistry', 'hereunto', 'milling', 'underground', 'neatly', 'diagonalizable', 'evolve', 'nonviolent', 'taylor', 'wretched', 'ashore', 'freedom', 'overcoat', 'taxed', 'truck', 'quota', 'bartender', 'risen', 'denounce', 'surfaceactive', 'capitalist', 'fisherman', 'found', 'taxexempt', 'schwarzkopf', 'sparkle', 'rattle', 'death', 'optimistic', 'neon', 'external', 'schedule', 'precious', 'discussion', 'equal', 'occur', 'necessary', 'madame', 'intersection', 'meantime', 'punish', 'persist', 'criterion', 'respectable', 'thermostat', 'arises', 'stance', 'logically', 'mg', 'occupant', 'executive', 'poor', 'inquirer', 'desperate', 'eugene', 'thick', 'l', 'commander', 'agent', 'rub', 'kahler', 'league', 'lalaurie', 'famous', 'real', 'desegregation', 'stockholder', 'information', 'beckon', 'thayer', 'deteriorate', 'fantasy', 'duclos', 'windshield', 'bending', 'grove', 'thanked', 'kitchen', 'candle', 'bridget', 'lipton', 'oat', 'moscow', 'uniformly', 'suck', 'wonderfully', 'vacant', 'preacher', 'displeased', 'removal', 'boredom', 'newt', 'secret', 'limitation', 'leisure', 'reverend', 'tub', 'foresight', 'continental', 'scenic', 'harbor', 'indefinite', 'giggle', 'affiliate', 'vector', 'jean', 'loss', 'ingenuity', 'rest', 'wish', 'sitter', 'rice', 'evoke', 'wellknown', 'defect', 'match', 'twofold', 'disarm', 'thrive', 'meadow', 'vernon', 'therapeutic', 'furnishing', 'ought', 'theology', 'wrangler', 'persian', 'passionate', 'moment', 'salem', 'specialization', 'economist', 'moreover', 'julia', 'labormanagement', 'ass', 'karl', 'fail', 'upkeep', 'proceed', 'howe', 'mourn', 'collapse', 'respect', 'flow', 'ample', 'shy', 'universe', 'reel', 'strain', 'statewide', 'periodical', 'idly', 'holder', 'conditioner', 'ghetto', 'fibrosis', 'directory', 'orthodontic', 'southward', 'clothes', 'stayed', 'thousand', 'withholding', 'mexican', 'throttle', 'megaton', 'appear', 'sunday', 'awaken', 'syllable', 'strewn', 'nephew', 'bos', 'rubbed', 'chuckle', 'elizabeth', 'felix', 'kate', 'ny', 'excellently', 'staff', 'kilometer', 'run', 'decides', 'scream', 'pertain', 'writer', 'related', 'winter', 'hole', 'sprang', 'disaster', 'thats', 'miracle', 'noticeable', 'han', 'fist', 'carnival', 'canoe', 'regard', 'seriously', 'blister', 'wind', 'specially', 'separation', 'banish', 'conquer', 'stair', 'torrent', 'kern', 'implicit', 'speculation', 'calcium', 'percussive', 'would', 'circulation', 'softly', 'lauren', 'usable', 'bean', 'energy', 'mud', 'situation', 'ridden', 'often', 'desk', 'snarl', 'putt', 'descent', 'college', 'widen', 'simple', 'larkin', 'assassin', 'rookie', 'freeman', 'portion', 'irish', 'excuse', 'appraisal', 'sr', 'people', 'laundry', 'signing', 'parade', 'whereupon', 'loud', 'sofa', 'assessor', 'curiously', 'policy', 'pollen', 'moisture', 'objective', 'gabriel', 'impression', 'beckett', 'anxiety', 'gut', 'slavery', 'sergeant', 'protective', 'sensation', 'conceive', 'arouse', 'cruelty', 'continuously', 'surveillance', 'duel', 'exception', 'gyro', 'kill', 'transpire', 'merger', 'successful', 'suppress', 'africa', 'spar', 'valley', 'vibrant', 'slap', 'wider', 'reveal', 'pathological', 'theyll', 'herr', 'imprisonment', 'kiss', 'flap', 'maladjustment', 'prominent', 'sap', 'swiftly', 'bronc', 'mobile', 'treasurer', 'intrigue', 'vary', 'partisan', 'consider', 'hardest', 'beam', 'shallow', 'could', 'mahzeers', 'receive', 'cross', 'fink', 'adhesive', 'toast', 'laborer', 'unpleasant', 'oily', 'louisiana', 'harness', 'alien', 'dy', 'exploration', 'courtyard', 'deck', 'rap', 'processing', 'dictionary', 'batch', 'transferor', 'overnight', 'imitation', 'continual', 'bargaining', 'xray', 'wing', 'butt', 'characterization', 'desolate', 'lemon', 'princess', 'interchange', 'equally', 'hoover', 'southerner', 'tune', 'explosion', 'mortality', 'contemptuous', 'construe', 'closer', 'panic', 'k', 'exhibit', 'itemize', 'warm', 'drown', 'seem', 'wake', 'tire', 'detail', 'sooner', 'sheet', 'rpm', 'danish', 'platform', 'highspeed', 'francis', 'dolores', 'focal', 'lap', 'spur', 'truce', 'wife', 'unemployment', 'cart', 'elmer', 'unadjusted', 'bitterness', 'revenge', 'outrage', 'progression', 'bosphorus', 'strand', 'heavily', 'recognizes', 'sunshine', 'outweigh', 'lack', 'cathedral', 'serve', 'unexpectedly', 'wave', 'torrio', 'fosdick', 'fox', 'wet', 'methodist', 'mink', 'read', 'apologize', 'mineral', 'revision', 'word', 'input', 'allocate', 'salary', 'giant', 'macklin', 'arrow', 'jerusalem', 'lyricist', 'strategic', 'continuum', 'violation', 'gunny', 'literally', 'didnt', 'coal', 'telegram', 'catholic', 'elsewhere', 'lurch', 'concerto', 'describe', 'harden', 'prophecy', 'islander', 'plank', 'officer', 'committeeman', 'conformity', 'quit', 'orientation', 'grocery', 'neutralist', 'forty', 'night', 'artistic', 'affirm', 'editorial', 'tsunami', 'quick', 'ion', 'deepest', 'heir', 'confines', 'aid', 'audit', 'norm', 'massachusetts', 'cobb', 'buyer', 'allowable', 'apple', 'hesperus', 'premise', 'millennium', 'slender', 'proctor', 'notion', 'foliage', 'incredibly', 'forge', 'importance', 'engrave', 'produce', 'cone', 'location', 'composite', 'marital', 'frightful', 'oilseed', 'dolly', 'consistency', 'perceptual', 'commence', 'adlai', 'fulfil', 'diagram', 'stem', 'joy', 'harmony', 'web', 'pamela', 'overboard', 'notice', 'inheritance', 'parent', 'mate', 'flag', 'pray', 'af', 'dialectic', 'bargain', 'fortune', 'desperation', 'horse', 'content', 'tends', 'thinker', 'ate', 'moonlight', 'granny', 'tumor', 'stoop', 'corp', 'frontier', 'analytic', 'unable', 'conduct', 'swing', 'lifetime', 'lunge', 'immediately', 'go', 'unwed', 'market', 'conversely', 'harder', 'satisfactory', 'carryover', 'lucy', 'tie', 'strut', 'concurrent', 'conventional', 'oneshot', 'westward', 'language', 'original', 'advertiser', 'trust', 'nag', 'contradict', 'mercer', 'enough', 'nixon', 'devastate', 'louise', 'distinguish', 'assignment', 'allot', 'resemble', 'return', 'button', 'climax', 'motivation', 'debut', 'border', 'impetus', 'aspire', 'impatiently', 'stevenson', 'generator', 'snack', 'dissatisfaction', 'ussr', 'ada', 'rating', 'familiarity', 'vent', 'premiere', 'drainage', 'combustion', 'channel', 'illusion', 'diet', 'gulf', 'occupational', 'period', 'viscosity', 'glitter', 'remain', 'blur', 'meredith', 'dormitory', 'jail', 'sens', 'squall', 'cow', 'satisfaction', 'christmas', 'amid', 'compilation', 'creed', 'worker', 'midday', 'operator', 'consonantal', 'mesh', 'agree', 'managerial', 'claire', 'vigor', 'sunk', 'ruandaurundi', 'coexistence', 'hood', 'trespass', 'borough', 'gloom', 'purpose', 'neighbor', 'bottle', 'sweat', 'vision', 'stuck', 'outlet', 'motive', 'entertain', 'buckskin', 'specificity', 'pop', 'advisory', 'frozen', 'differentiate', 'swear', 'prewar', 'deprive', 'intelligent', 'overflow', 'forward', 'arterypulmonary', 'rifle', 'thyroid', 'dice', 'footstep', 'stamp', 'west', 'transitional', 'juicy', 'tsh', 'procedural', 'worthwhile', 'examine', 'faget', 'guess', 'dominate', 'poison', 'theory', 'mike', 'model', 'initial', 'cutter', 'quantitative', 'disagreement', 'underlie', 'standpoint', 'cloud', 'add', 'budgeting', 'born', 'modulation', 'false', 'applicable', 'wallet', 'scope', 'costume', 'pity', 'outmode', 'greek', 'awareness', 'provide', 'virus', 'believe', 'origin', 'zeal', 'spiritual', 'scot', 'thyroxine', 'nothing', 'prime', 'soybean', 'stiffen', 'fragrance', 'hotel', 'gansevoort', 'applaud', 'title', 'delivery', 'assurance', 'skip', 'le', 'mortar', 'phone', 'wander', 'considerably', 'utmost', 'application', 'antisemitism', 'wavelength', 'develop', 'antibody', 'priest', 'decisive', 'question', 'extensive', 'poet', 'diary', 'mouth', 'bonner', 'peterson', 'woke', 'apology', 'palestine', 'st', 'gov', 'litigation', 'timely', 'cadillac', 'restore', 'madman', 'automatic', 'willing', 'palmer', 'sixteen', 'suburban', 'richardson', 'wildly', 'santa', 'blame', 'accustom', 'insufficient', 'trial', 'pretentious', 'confinement', 'tomorrow', 'twentyfive', 'rat', 'star', 'grouping', 'muscle', 'legislative', 'concept', 'alkali', 'ingroup', 'incomplete', 'magnetism', 'tenor', 'circular', 'lloyd', 'numb', 'improves', 'eyed', 'scarce', 'mitchell', 'recourse', 'ladder', 'precise', 'symbolism', 'walter', 'kingdom', 'correlate', 'avert', 'significance', 'onethird', 'astronomy', 'richmond', 'birdie', 'rough', 'apartment', 'flood', 'barely', 'yl', 'hardship', 'chat', 'trim', 'clover', 'san', 'diminish', 'tobacco', 'tv', 'resembles', 'inherent', 'nam', 'stay', 'pollution', 'quantity', 'operational', 'directly', 'sophisticated', 'minister', 'hemisphere', 'cascade', 'bath', 'indifference', 'revival', 'insulation', 'react', 'brain', 'scrutiny', 'queen', 'studio', 'occupation', 'plea', 'reconstruct', 'subject', 'prostitution', 'bodybuilder', 'delicate', 'dispatch', 'yin', 'lore', 'sun', 'section', 'compatible', 'comb', 'renaissance', 'coordinator', 'reformation', 'dietary', 'polymerization', 'adc', 'pronoun', 'colleague', 'hampshire', 'epiphysis', 'package', 'enjoyment', 'greet', 'tenuous', 'educator', 'stormy', 'contact', 'creaked', 'boot', 'offend', 'initially', 'particular', 'murphy', 'myth', 'construct', 'phrase', 'decency', 'reward', 'invention', 'peg', 'mose', 'forceful', 'fresh', 'aspiration', 'safely', 'symmetry', 'soldier', 'jubal', 'backing', 'prove', 'analytical', 'lag', 'pad', 'proposition', 'rouge', 'harm', 'chemical', 'unavoidable', 'reporter', 'soil', 'enters', 'fleeting', 'miller', 'duct', 'runway', 'denominational', 'debate', 'instrument', 'anybody', 'bulletin', 'jurist', 'considers', 'crude', 'orderly', 'towards', 'principally', 'physiological', 'drunkard', 'enterprise', 'bruise', 'correction', 'answer', 'manner', 'surmise', 'misunderstood', 'pension', 'easter', 'prey', 'northwest', 'fortify', 'commune', 'upgrade', 'yang', 'fancy', 'larson', 'sometimes', 'victorian', 'microorganism', 'locality', 'neat', 'error', 'cut', 'youre', 'commenced', 'easy', 'barton', 'furious', 'kennedy', 'anglosaxon', 'locker', 'coordinate', 'pasadena', 'ye', 'cost', 'tonight', 'gag', 'onehalf', 'shook', 'notch', 'adventure', 'ok', 'drew', 'reluctance', 'telegraph', 'aggregate', 'except', 'matsuo', 'bore', 'raid', 'doorman', 'piston', 'council', 'oriental', 'rotor', 'hysterical', 'patrolman', 'sword', 'beauty', 'scientific', 'cerebral', 'suffer', 'body', 'loneliness', 'steer', 'belief', 'scorn', 'envision', 'orient', 'budget', 'welcome', 'egyptian', 'fortress', 'pride', 'proclaim', 'silk', 'diiodotyrosine', 'farmer', 'hardy', 'fete', 'negroappeal', 'wit', 'beneficiary', 'disabled', 'curts', 'deer', 'deep', 'honey', 'textform', 'extraordinary', 'fence', 'whitehead', 'prokofieff', 'kruger', 'explore', 'rinse', 'lightweight', 'tan', 'unimportant', 'layer', 'like', 'first', 'theater', 'noel', 'individual', 'ledge', 'aluminum', 'dug', 'clerfayt', 'diaphragm', 'journey', 'fuss', 'biting', 'dictatorship', 'werent', 'statute', 'beating', 'factory', 'innovation', 'hammock', 'orchestra', 'flush', 'blanche', 'surgery', 'farther', 'ml', 'cockpit', 'denial', 'motionless', 'caution', 'circuit', 'noteworthy', 'pistol', 'linguistics', 'gauge', 'siberia', 'trouser', 'congratulation', 'seward', 'happier', 'sutherland', 'school', 'wagon', 'ignorance', 'funeral', 'maturity', 'destroy', 'solar', 'denotes', 'fred', 'spectral', 'person', 'odyssey', 'intense', 'ontological', 'surroundings', 'heroic', 'homogeneity', 'immediate', 'sinner', 'submerge', 'rose', 'polymer', 'begin', 'accidental', 'airport', 'misdeed', 'posse', 'matson', 'ellen', 'creative', 'celestial', 'mute', 'actuality', 'cargo', 'needle', 'york', 'ld', 'angry', 'comic', 'forgive', 'skepticism', 'peasant', 'scientist', 'radical', 'hears', 'fudo', 'wishful', 'kneel', 'insignificant', 'tighten', 'jessica', 'twelfth', 'sunburn', 'evening', 'provocative', 'gibson', 'postulate', 'capacity', 'postcard', 'conservative', 'edit', 'helva', 'river', 'sight', 'hen', 'agreement', 'walnut', 'avail', 'season', 'nazi', 'universally', 'contradiction', 'politics', 'flung', 'tent', 'festival', 'beatnik', 'initiate', 'subcommittee', 'climb', 'bid', 'microphone', 'genuinely', 'rev', 'engross', 'ahead', 'henry', 'harrow', 'ghost', 'tick', 'canvas', 'nest', 'painfully', 'tonal', 'costaggini', 'bronchiole', 'inscription', 'reflect', 'dane', 'heavenly', 'thirty', 'regular', 'monacle', 'demoralize', 'triumphantly', 'fiske', 'louder', 'justify', 'filing', 'unity', 'balcony', 'guarantee', 'religious', 'compensation', 'rumor', 'feminine', 'ptolemy', 'byrd', 'clutched', 'shortstop', 'rural', 'capital', 'manage', 'buying', 'filthy', 'fought', 'grandchild', 'undoubtedly', 'september', 'oldfashioned', 'gun', 'empty', 'wrap', 'camp', 'level', 'inflation', 'chief', 'reckon', 'music', 'forgiveness', 'accomplishment', 'unstable', 'dependable', 'gift', 'mint', 'quantum', 'guitar', 'hydrogen', 'lung', 'cranston', 'pauling', 'prominently', 'instinct', 'disability', 'meaningless', 'comply', 'beset', 'correct', 'concrete', 'expandable', 'uneasily', 'luck', 'apart', 'outdoors', 'horrible', 'ancestor', 'greece', 'sue', 'pretext', 'hemorrhage', 'bun', 'pretense', 'aggression', 'stud', 'percent', 'dusk', 'woven', 'finance', 'orgasm', 'artery', 'plan', 'modernize', 'sufficiently', 'darken', 'together', 'quotation', 'counsel', 'taliesin', 'tollroad', 'minimize', 'cliche', 'arose', 'permanent', 'rankin', 'halfmile', 'compass', 'actual', 'lioness', 'jewish', 'capable', 'hymen', 'echoed', 'veranda', 'serial', 'nato', 'diagnose', 'agency', 'miss', 'oxidation', 'slaughter', 'week', 'warn', 'suppose', 'climate', 'extract', 'bureaucracy', 'adam', 'harcourt', 'bryan', 'glow', 'satire', 'repetition', 'ninety', 'nozzle', 'douglas', 'effect', 'financing', 'compartment', 'helpful'}\n",
            "9637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Probabilistic Language Model data preparation and model building and training"
      ],
      "metadata": {
        "id": "ahCDB7rfuish"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making n-grams from sentences"
      ],
      "metadata": {
        "id": "Eg6WazmEnnO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# if the word is not in the vocabulary build using the training set it is replaced with <UNK>\n",
        "def replace_unknown_word(word, vocabulary):\n",
        "    if word in vocabulary:\n",
        "        return word\n",
        "    else:\n",
        "        return '<UNK>'\n",
        "\n",
        "# return the ids for each word in the n-gram\n",
        "def get_ngram_ids(ngram, encoder):\n",
        "    return encoder.transform(ngram)\n",
        "\n",
        "\n",
        "n_grams_len = 10  # n-gram length\n",
        "min_len = n_grams_len  # minimum sentence length\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "word_ids = encoder.fit_transform(list(vocabulary))  # encode words into ids\n",
        "print(word_ids)\n",
        "\n",
        "n_grams_train = []\n",
        "n_grams_test = []\n",
        "for i, sentence in enumerate(shuffled_docs):\n",
        "    # skip sentences with less words than min_len\n",
        "    if len(sentence) < min_len:\n",
        "        continue\n",
        "    # iterate through the sentence and build n-grams (the last word is the word to predict)\n",
        "    for j, word in enumerate(sentence):\n",
        "        if j < len(sentence) - (n_grams_len-1):\n",
        "            if i <= num_train:\n",
        "                n_grams_train.append([replace_unknown_word(sentence[j+k], vocabulary) for k in range(n_grams_len) if k < n_grams_len])\n",
        "            else:\n",
        "                n_grams_test.append([replace_unknown_word(sentence[j+k], vocabulary) for k in range(n_grams_len) if k < n_grams_len])\n",
        "\n",
        "# numpy array conversion\n",
        "n_grams_train = np.array(n_grams_train)\n",
        "n_grams_test = np.array(n_grams_test)\n",
        "\n",
        "# replace words with ids\n",
        "for i in range(n_grams_len):\n",
        "    n_grams_train[:, i] = encoder.transform(n_grams_train[:, i])\n",
        "    n_grams_test[:, i] = encoder.transform(n_grams_test[:, i])\n",
        "\n",
        "print(n_grams_train.shape)\n",
        "print(n_grams_test.shape)"
      ],
      "metadata": {
        "id": "FaQWyVItnmym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3413aa2-1c43-4e64-e705-51bc116d5331"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7059 4999  851 ... 3335 1690 4061]\n",
            "(118417, 10)\n",
            "(29154, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split X and y"
      ],
      "metadata": {
        "id": "QvV4qEgF8tVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_grams_train = np.array(n_grams_train, dtype=int)\n",
        "n_grams_test = np.array(n_grams_test, dtype=int)\n",
        "\n",
        "X_train = n_grams_train[:, 0:n_grams_len-1]\n",
        "y_train = n_grams_train[:, -1]\n",
        "X_test = n_grams_test[:, 0:n_grams_len-1]\n",
        "y_test = n_grams_test[:, -1]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "GqQUEjX98sz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ea2cb3-7840-4b30-ca12-fb0b475db8c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(118417, 9)\n",
            "(118417,)\n",
            "(29154, 9)\n",
            "(29154,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to torch tensor and make a torch Dataset\n"
      ],
      "metadata": {
        "id": "QUiiyMVWLAT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "X_train = torch.LongTensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "X_test = torch.LongTensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "train_data = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_data = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "HTC4G4PUK90g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build NPLM model (based on Bengio's A Neural Probabilistic Language Model)"
      ],
      "metadata": {
        "id": "DRhSZxVWjPG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class NPLM(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dim, hidden_dim, context_size):\n",
        "        super(NPLM, self).__init__()\n",
        "        self.train_losses = []\n",
        "        self.eval_losses = []\n",
        "\n",
        "        self.embedding = nn.Embedding(vocabulary_size, embedding_dim)\n",
        "        # the hidden layer takes in input a number of embeddings equal to the context size\n",
        "        self.hidden_layer = nn.Linear(context_size * embedding_dim, hidden_dim)\n",
        "        self.hidden_layer_2 = nn.Linear(hidden_dim, vocabulary_size, bias=False)\n",
        "\n",
        "        # self.criterion = nn.NLLLoss()\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # concatenation of the embeddings of n-1 words of the n-gram\n",
        "        emb = self.embedding(x).reshape(x.shape[0], -1)\n",
        "        out = torch.tanh(self.hidden_layer(emb))\n",
        "        out = self.hidden_layer_2(out)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "\n",
        "        return probs\n",
        "\n",
        "    def loss(self, output, target):\n",
        "        return self.criterion(target, output)\n"
      ],
      "metadata": {
        "id": "CQHz55ADHkoA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NPLM parameters\n",
        "vocab_size = len(vocabulary)\n",
        "embedding_dim = 256\n",
        "hidden_dim = 1024\n",
        "context_size = n_grams_len - 1\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 500\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = NPLM(vocab_size, embedding_dim, hidden_dim, context_size)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "model = model.to(device)\n",
        "\n",
        "print('Model')\n",
        "print(model)\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('Trainable parameters: {:,}'.format(trainable_params))\n",
        "print('Optimizer')\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRaYhVi6HmHy",
        "outputId": "684e50ee-02b1-48d3-e115-9878619aec24"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model\n",
            "NPLM(\n",
            "  (embedding): Embedding(9571, 256)\n",
            "  (hidden_layer): Linear(in_features=2304, out_features=1024, bias=True)\n",
            "  (hidden_layer_2): Linear(in_features=1024, out_features=9571, bias=False)\n",
            "  (criterion): CrossEntropyLoss()\n",
            ")\n",
            "Trainable parameters: 14,611,200\n",
            "Optimizer\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # train loop\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(train_data):\n",
        "        input = batch[0].to(device)\n",
        "        target = batch[1].to(device)\n",
        "\n",
        "        output = model(input)\n",
        "\n",
        "        loss = model.criterion(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # print loss of some batches\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch [{}/{}], batch {}, batch loss: {}'.format(epoch+1, num_epochs, i, loss.item()))\n",
        "\n",
        "    epoch_loss = epoch_loss / len(train_data)\n",
        "    model.train_losses.append(epoch_loss)\n",
        "    print('Epoch [{}/{}], epoch mean loss: {}'.format(epoch+1, num_epochs, epoch_loss))\n",
        "\n",
        "    # evaluation loop\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    for batch in test_data:\n",
        "        input = batch[0].to(device)\n",
        "        target = batch[1].to(device)\n",
        "\n",
        "        output = model(input)\n",
        "\n",
        "        loss = model.criterion(output, target)\n",
        "\n",
        "        eval_loss += loss.item()\n",
        "\n",
        "    eval_loss = eval_loss / len(test_data)\n",
        "    model.eval_losses.append(eval_loss)\n",
        "    print('Epoch [{}/{}], evaluation loss: {}'.format(epoch+1, num_epochs, eval_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqyV-oKiHofU",
        "outputId": "34287d2e-edcd-4354-d666-a7c8df50169b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], batch 0, batch loss: 9.16649341583252\n",
            "Epoch [1/500], batch 100, batch loss: 9.10129451751709\n",
            "Epoch [1/500], epoch mean loss: 9.120501378486896\n",
            "Epoch [1/500], evaluation loss: 9.088843444298053\n",
            "Epoch [2/500], batch 0, batch loss: 9.104970932006836\n",
            "Epoch [2/500], batch 100, batch loss: 9.079690933227539\n",
            "Epoch [2/500], epoch mean loss: 9.099397149579278\n",
            "Epoch [2/500], evaluation loss: 9.080929854820514\n",
            "Epoch [3/500], batch 0, batch loss: 9.105002403259277\n",
            "Epoch [3/500], batch 100, batch loss: 9.07713508605957\n",
            "Epoch [3/500], epoch mean loss: 9.089867567193918\n",
            "Epoch [3/500], evaluation loss: 9.072750683488517\n",
            "Epoch [4/500], batch 0, batch loss: 9.080291748046875\n",
            "Epoch [4/500], batch 100, batch loss: 9.089437484741211\n",
            "Epoch [4/500], epoch mean loss: 9.084033431677982\n",
            "Epoch [4/500], evaluation loss: 9.068731176442114\n",
            "Epoch [5/500], batch 0, batch loss: 9.068252563476562\n",
            "Epoch [5/500], batch 100, batch loss: 9.08470630645752\n",
            "Epoch [5/500], epoch mean loss: 9.081093344195136\n",
            "Epoch [5/500], evaluation loss: 9.067100820870236\n",
            "Epoch [6/500], batch 0, batch loss: 9.078404426574707\n",
            "Epoch [6/500], batch 100, batch loss: 9.083100318908691\n",
            "Epoch [6/500], epoch mean loss: 9.079278436200372\n",
            "Epoch [6/500], evaluation loss: 9.065527850183948\n",
            "Epoch [7/500], batch 0, batch loss: 9.063087463378906\n",
            "Epoch [7/500], batch 100, batch loss: 9.077138900756836\n",
            "Epoch [7/500], epoch mean loss: 9.078084707260132\n",
            "Epoch [7/500], evaluation loss: 9.065282065292884\n",
            "Epoch [8/500], batch 0, batch loss: 9.071948051452637\n",
            "Epoch [8/500], batch 100, batch loss: 9.073648452758789\n",
            "Epoch [8/500], epoch mean loss: 9.07720762285693\n",
            "Epoch [8/500], evaluation loss: 9.064358185077536\n",
            "Epoch [9/500], batch 0, batch loss: 9.07646369934082\n",
            "Epoch [9/500], batch 100, batch loss: 9.085597038269043\n",
            "Epoch [9/500], epoch mean loss: 9.076415990961008\n",
            "Epoch [9/500], evaluation loss: 9.063789170363854\n",
            "Epoch [10/500], batch 0, batch loss: 9.069967269897461\n",
            "Epoch [10/500], batch 100, batch loss: 9.074596405029297\n",
            "Epoch [10/500], epoch mean loss: 9.075968462845374\n",
            "Epoch [10/500], evaluation loss: 9.063422926541033\n",
            "Epoch [11/500], batch 0, batch loss: 9.091455459594727\n",
            "Epoch [11/500], batch 100, batch loss: 9.071048736572266\n",
            "Epoch [11/500], epoch mean loss: 9.075650955068655\n",
            "Epoch [11/500], evaluation loss: 9.063182995237153\n",
            "Epoch [12/500], batch 0, batch loss: 9.08071231842041\n",
            "Epoch [12/500], batch 100, batch loss: 9.065092086791992\n",
            "Epoch [12/500], epoch mean loss: 9.07482360971385\n",
            "Epoch [12/500], evaluation loss: 9.062418904797784\n",
            "Epoch [13/500], batch 0, batch loss: 9.084476470947266\n",
            "Epoch [13/500], batch 100, batch loss: 9.091392517089844\n",
            "Epoch [13/500], epoch mean loss: 9.07428447131453\n",
            "Epoch [13/500], evaluation loss: 9.061789512634277\n",
            "Epoch [14/500], batch 0, batch loss: 9.087538719177246\n",
            "Epoch [14/500], batch 100, batch loss: 9.086970329284668\n",
            "Epoch [14/500], epoch mean loss: 9.074058491608191\n",
            "Epoch [14/500], evaluation loss: 9.061989554043475\n",
            "Epoch [15/500], batch 0, batch loss: 9.077775955200195\n",
            "Epoch [15/500], batch 100, batch loss: 9.081974029541016\n",
            "Epoch [15/500], epoch mean loss: 9.07379597630994\n",
            "Epoch [15/500], evaluation loss: 9.06206436814933\n",
            "Epoch [16/500], batch 0, batch loss: 9.062968254089355\n",
            "Epoch [16/500], batch 100, batch loss: 9.076828002929688\n",
            "Epoch [16/500], epoch mean loss: 9.073540745110348\n",
            "Epoch [16/500], evaluation loss: 9.061448228770288\n",
            "Epoch [17/500], batch 0, batch loss: 9.084510803222656\n",
            "Epoch [17/500], batch 100, batch loss: 9.081696510314941\n",
            "Epoch [17/500], epoch mean loss: 9.073018583758124\n",
            "Epoch [17/500], evaluation loss: 9.061856697345602\n",
            "Epoch [18/500], batch 0, batch loss: 9.071928024291992\n",
            "Epoch [18/500], batch 100, batch loss: 9.086544036865234\n",
            "Epoch [18/500], epoch mean loss: 9.072796821594238\n",
            "Epoch [18/500], evaluation loss: 9.061389955981024\n",
            "Epoch [19/500], batch 0, batch loss: 9.070718765258789\n",
            "Epoch [19/500], batch 100, batch loss: 9.052441596984863\n",
            "Epoch [19/500], epoch mean loss: 9.072493865572174\n",
            "Epoch [19/500], evaluation loss: 9.061727984198209\n",
            "Epoch [20/500], batch 0, batch loss: 9.081684112548828\n",
            "Epoch [20/500], batch 100, batch loss: 9.050825119018555\n",
            "Epoch [20/500], epoch mean loss: 9.071744762617966\n",
            "Epoch [20/500], evaluation loss: 9.06159101683518\n",
            "Epoch [21/500], batch 0, batch loss: 9.064902305603027\n",
            "Epoch [21/500], batch 100, batch loss: 9.069784164428711\n",
            "Epoch [21/500], epoch mean loss: 9.070684293220783\n",
            "Epoch [21/500], evaluation loss: 9.062015993841763\n",
            "Epoch [22/500], batch 0, batch loss: 9.069355010986328\n",
            "Epoch [22/500], batch 100, batch loss: 9.067412376403809\n",
            "Epoch [22/500], epoch mean loss: 9.069484735357351\n",
            "Epoch [22/500], evaluation loss: 9.062111920323865\n",
            "Epoch [23/500], batch 0, batch loss: 9.054919242858887\n",
            "Epoch [23/500], batch 100, batch loss: 9.06690788269043\n",
            "Epoch [23/500], epoch mean loss: 9.067535161972046\n",
            "Epoch [23/500], evaluation loss: 9.062355041503906\n",
            "Epoch [24/500], batch 0, batch loss: 9.055156707763672\n",
            "Epoch [24/500], batch 100, batch loss: 9.060083389282227\n",
            "Epoch [24/500], epoch mean loss: 9.065062457117541\n",
            "Epoch [24/500], evaluation loss: 9.062402692334405\n",
            "Epoch [25/500], batch 0, batch loss: 9.045564651489258\n",
            "Epoch [25/500], batch 100, batch loss: 9.064193725585938\n",
            "Epoch [25/500], epoch mean loss: 9.06195278003298\n",
            "Epoch [25/500], evaluation loss: 9.062512562192719\n",
            "Epoch [26/500], batch 0, batch loss: 9.05996036529541\n",
            "Epoch [26/500], batch 100, batch loss: 9.050358772277832\n",
            "Epoch [26/500], epoch mean loss: 9.058454201139252\n",
            "Epoch [26/500], evaluation loss: 9.062914059079926\n",
            "Epoch [27/500], batch 0, batch loss: 9.06527042388916\n",
            "Epoch [27/500], batch 100, batch loss: 9.058643341064453\n",
            "Epoch [27/500], epoch mean loss: 9.054546750825027\n",
            "Epoch [27/500], evaluation loss: 9.062912875208362\n",
            "Epoch [28/500], batch 0, batch loss: 9.032428741455078\n",
            "Epoch [28/500], batch 100, batch loss: 9.042157173156738\n",
            "Epoch [28/500], epoch mean loss: 9.050654098905365\n",
            "Epoch [28/500], evaluation loss: 9.063075887745825\n",
            "Epoch [29/500], batch 0, batch loss: 9.061442375183105\n",
            "Epoch [29/500], batch 100, batch loss: 9.041321754455566\n",
            "Epoch [29/500], epoch mean loss: 9.047180611511756\n",
            "Epoch [29/500], evaluation loss: 9.062678008243955\n",
            "Epoch [30/500], batch 0, batch loss: 9.0260648727417\n",
            "Epoch [30/500], batch 100, batch loss: 9.037591934204102\n",
            "Epoch [30/500], epoch mean loss: 9.043954125766096\n",
            "Epoch [30/500], evaluation loss: 9.062749204964474\n",
            "Epoch [31/500], batch 0, batch loss: 9.051111221313477\n",
            "Epoch [31/500], batch 100, batch loss: 9.048291206359863\n",
            "Epoch [31/500], epoch mean loss: 9.040982698572092\n",
            "Epoch [31/500], evaluation loss: 9.062662880996179\n",
            "Epoch [32/500], batch 0, batch loss: 9.051753997802734\n",
            "Epoch [32/500], batch 100, batch loss: 9.03677749633789\n",
            "Epoch [32/500], epoch mean loss: 9.038576915346344\n",
            "Epoch [32/500], evaluation loss: 9.062964636704017\n",
            "Epoch [33/500], batch 0, batch loss: 9.034655570983887\n",
            "Epoch [33/500], batch 100, batch loss: 9.041513442993164\n",
            "Epoch [33/500], epoch mean loss: 9.036420312421075\n",
            "Epoch [33/500], evaluation loss: 9.062744502363534\n",
            "Epoch [34/500], batch 0, batch loss: 9.013264656066895\n",
            "Epoch [34/500], batch 100, batch loss: 9.028449058532715\n",
            "Epoch [34/500], epoch mean loss: 9.034561708055694\n",
            "Epoch [34/500], evaluation loss: 9.063184705273859\n",
            "Epoch [35/500], batch 0, batch loss: 9.029061317443848\n",
            "Epoch [35/500], batch 100, batch loss: 9.033939361572266\n",
            "Epoch [35/500], epoch mean loss: 9.032590455022351\n",
            "Epoch [35/500], evaluation loss: 9.06274861302869\n",
            "Epoch [36/500], batch 0, batch loss: 9.05345630645752\n",
            "Epoch [36/500], batch 100, batch loss: 9.01677417755127\n",
            "Epoch [36/500], epoch mean loss: 9.030818355494532\n",
            "Epoch [36/500], evaluation loss: 9.063129096195615\n",
            "Epoch [37/500], batch 0, batch loss: 9.01424503326416\n",
            "Epoch [37/500], batch 100, batch loss: 9.022537231445312\n",
            "Epoch [37/500], epoch mean loss: 9.029020301226911\n",
            "Epoch [37/500], evaluation loss: 9.06294296527731\n",
            "Epoch [38/500], batch 0, batch loss: 9.020294189453125\n",
            "Epoch [38/500], batch 100, batch loss: 9.023090362548828\n",
            "Epoch [38/500], epoch mean loss: 9.027566342518247\n",
            "Epoch [38/500], evaluation loss: 9.063156292356293\n",
            "Epoch [39/500], batch 0, batch loss: 9.021835327148438\n",
            "Epoch [39/500], batch 100, batch loss: 9.04454517364502\n",
            "Epoch [39/500], epoch mean loss: 9.026302567843732\n",
            "Epoch [39/500], evaluation loss: 9.062761569845266\n",
            "Epoch [40/500], batch 0, batch loss: 9.011791229248047\n",
            "Epoch [40/500], batch 100, batch loss: 9.02702522277832\n",
            "Epoch [40/500], epoch mean loss: 9.024902417741973\n",
            "Epoch [40/500], evaluation loss: 9.063199109044568\n",
            "Epoch [41/500], batch 0, batch loss: 9.007731437683105\n",
            "Epoch [41/500], batch 100, batch loss: 9.00372314453125\n",
            "Epoch [41/500], epoch mean loss: 9.023521004051998\n",
            "Epoch [41/500], evaluation loss: 9.063069606649465\n",
            "Epoch [42/500], batch 0, batch loss: 9.034804344177246\n",
            "Epoch [42/500], batch 100, batch loss: 9.03657054901123\n",
            "Epoch [42/500], epoch mean loss: 9.022083307134695\n",
            "Epoch [42/500], evaluation loss: 9.063252745003537\n",
            "Epoch [43/500], batch 0, batch loss: 9.022745132446289\n",
            "Epoch [43/500], batch 100, batch loss: 9.03786849975586\n",
            "Epoch [43/500], epoch mean loss: 9.02061520773789\n",
            "Epoch [43/500], evaluation loss: 9.063394414967505\n",
            "Epoch [44/500], batch 0, batch loss: 9.013764381408691\n",
            "Epoch [44/500], batch 100, batch loss: 9.024697303771973\n",
            "Epoch [44/500], epoch mean loss: 9.019252982632867\n",
            "Epoch [44/500], evaluation loss: 9.063010445956525\n",
            "Epoch [45/500], batch 0, batch loss: 9.036347389221191\n",
            "Epoch [45/500], batch 100, batch loss: 9.019308090209961\n",
            "Epoch [45/500], epoch mean loss: 9.017850958067795\n",
            "Epoch [45/500], evaluation loss: 9.063433647155762\n",
            "Epoch [46/500], batch 0, batch loss: 9.0269775390625\n",
            "Epoch [46/500], batch 100, batch loss: 9.01253604888916\n",
            "Epoch [46/500], epoch mean loss: 9.016505479812622\n",
            "Epoch [46/500], evaluation loss: 9.063037872314453\n",
            "Epoch [47/500], batch 0, batch loss: 9.015695571899414\n",
            "Epoch [47/500], batch 100, batch loss: 9.015289306640625\n",
            "Epoch [47/500], epoch mean loss: 9.015316346596027\n",
            "Epoch [47/500], evaluation loss: 9.063456699765961\n",
            "Epoch [48/500], batch 0, batch loss: 9.013484954833984\n",
            "Epoch [48/500], batch 100, batch loss: 9.001677513122559\n",
            "Epoch [48/500], epoch mean loss: 9.014064147554596\n",
            "Epoch [48/500], evaluation loss: 9.063143401310361\n",
            "Epoch [49/500], batch 0, batch loss: 8.995692253112793\n",
            "Epoch [49/500], batch 100, batch loss: 9.017178535461426\n",
            "Epoch [49/500], epoch mean loss: 9.013009022022116\n",
            "Epoch [49/500], evaluation loss: 9.063672526129361\n",
            "Epoch [50/500], batch 0, batch loss: 9.008228302001953\n",
            "Epoch [50/500], batch 100, batch loss: 9.033482551574707\n",
            "Epoch [50/500], epoch mean loss: 9.011812999330719\n",
            "Epoch [50/500], evaluation loss: 9.06376026416647\n",
            "Epoch [51/500], batch 0, batch loss: 9.005819320678711\n",
            "Epoch [51/500], batch 100, batch loss: 9.0196533203125\n",
            "Epoch [51/500], epoch mean loss: 9.010644830506424\n",
            "Epoch [51/500], evaluation loss: 9.063746781184756\n",
            "Epoch [52/500], batch 0, batch loss: 8.994258880615234\n",
            "Epoch [52/500], batch 100, batch loss: 9.009647369384766\n",
            "Epoch [52/500], epoch mean loss: 9.009690013425104\n",
            "Epoch [52/500], evaluation loss: 9.063418684334591\n",
            "Epoch [53/500], batch 0, batch loss: 9.030485153198242\n",
            "Epoch [53/500], batch 100, batch loss: 8.997237205505371\n",
            "Epoch [53/500], epoch mean loss: 9.008498364481433\n",
            "Epoch [53/500], evaluation loss: 9.063656708289837\n",
            "Epoch [54/500], batch 0, batch loss: 8.997933387756348\n",
            "Epoch [54/500], batch 100, batch loss: 9.006568908691406\n",
            "Epoch [54/500], epoch mean loss: 9.00740489466437\n",
            "Epoch [54/500], evaluation loss: 9.063577487550933\n",
            "Epoch [55/500], batch 0, batch loss: 8.990009307861328\n",
            "Epoch [55/500], batch 100, batch loss: 8.976926803588867\n",
            "Epoch [55/500], epoch mean loss: 9.006544762644275\n",
            "Epoch [55/500], evaluation loss: 9.063921270699337\n",
            "Epoch [56/500], batch 0, batch loss: 9.003739356994629\n",
            "Epoch [56/500], batch 100, batch loss: 9.005022048950195\n",
            "Epoch [56/500], epoch mean loss: 9.005236576343405\n",
            "Epoch [56/500], evaluation loss: 9.064087374456998\n",
            "Epoch [57/500], batch 0, batch loss: 8.997278213500977\n",
            "Epoch [57/500], batch 100, batch loss: 9.011429786682129\n",
            "Epoch [57/500], epoch mean loss: 9.004089223927465\n",
            "Epoch [57/500], evaluation loss: 9.0638673716578\n",
            "Epoch [58/500], batch 0, batch loss: 9.019523620605469\n",
            "Epoch [58/500], batch 100, batch loss: 8.986699104309082\n",
            "Epoch [58/500], epoch mean loss: 9.00301271471484\n",
            "Epoch [58/500], evaluation loss: 9.064375449871195\n",
            "Epoch [59/500], batch 0, batch loss: 9.000432014465332\n",
            "Epoch [59/500], batch 100, batch loss: 9.011631965637207\n",
            "Epoch [59/500], epoch mean loss: 9.0021880988417\n",
            "Epoch [59/500], evaluation loss: 9.064232760462268\n",
            "Epoch [60/500], batch 0, batch loss: 9.010577201843262\n",
            "Epoch [60/500], batch 100, batch loss: 9.01695442199707\n",
            "Epoch [60/500], epoch mean loss: 9.001048532025568\n",
            "Epoch [60/500], evaluation loss: 9.064198263760272\n",
            "Epoch [61/500], batch 0, batch loss: 8.969297409057617\n",
            "Epoch [61/500], batch 100, batch loss: 9.007219314575195\n",
            "Epoch [61/500], epoch mean loss: 8.999969704397794\n",
            "Epoch [61/500], evaluation loss: 9.064095858869882\n",
            "Epoch [62/500], batch 0, batch loss: 8.992935180664062\n",
            "Epoch [62/500], batch 100, batch loss: 8.997732162475586\n",
            "Epoch [62/500], epoch mean loss: 8.999104318947628\n",
            "Epoch [62/500], evaluation loss: 9.064305700104812\n",
            "Epoch [63/500], batch 0, batch loss: 9.023153305053711\n",
            "Epoch [63/500], batch 100, batch loss: 8.989895820617676\n",
            "Epoch [63/500], epoch mean loss: 8.997928775590042\n",
            "Epoch [63/500], evaluation loss: 9.063936430832435\n",
            "Epoch [64/500], batch 0, batch loss: 8.987757682800293\n",
            "Epoch [64/500], batch 100, batch loss: 8.996611595153809\n",
            "Epoch [64/500], epoch mean loss: 8.997017474010073\n",
            "Epoch [64/500], evaluation loss: 9.064241310645794\n",
            "Epoch [65/500], batch 0, batch loss: 9.003646850585938\n",
            "Epoch [65/500], batch 100, batch loss: 8.98691463470459\n",
            "Epoch [65/500], epoch mean loss: 8.996235822809153\n",
            "Epoch [65/500], evaluation loss: 9.064414978027344\n",
            "Epoch [66/500], batch 0, batch loss: 8.986992835998535\n",
            "Epoch [66/500], batch 100, batch loss: 8.977516174316406\n",
            "Epoch [66/500], epoch mean loss: 8.995235780189777\n",
            "Epoch [66/500], evaluation loss: 9.064669378872576\n",
            "Epoch [67/500], batch 0, batch loss: 8.990955352783203\n",
            "Epoch [67/500], batch 100, batch loss: 9.006500244140625\n",
            "Epoch [67/500], epoch mean loss: 8.994016384256296\n",
            "Epoch [67/500], evaluation loss: 9.064857745992727\n",
            "Epoch [68/500], batch 0, batch loss: 8.984979629516602\n",
            "Epoch [68/500], batch 100, batch loss: 8.997194290161133\n",
            "Epoch [68/500], epoch mean loss: 8.993164621550461\n",
            "Epoch [68/500], evaluation loss: 9.065112640117777\n",
            "Epoch [69/500], batch 0, batch loss: 8.979283332824707\n",
            "Epoch [69/500], batch 100, batch loss: 8.980606079101562\n",
            "Epoch [69/500], epoch mean loss: 8.991850450121124\n",
            "Epoch [69/500], evaluation loss: 9.064724659097605\n",
            "Epoch [70/500], batch 0, batch loss: 8.996078491210938\n",
            "Epoch [70/500], batch 100, batch loss: 8.990822792053223\n",
            "Epoch [70/500], epoch mean loss: 8.990840862537253\n",
            "Epoch [70/500], evaluation loss: 9.064773921308847\n",
            "Epoch [71/500], batch 0, batch loss: 8.992798805236816\n",
            "Epoch [71/500], batch 100, batch loss: 8.983933448791504\n",
            "Epoch [71/500], epoch mean loss: 8.989869545245993\n",
            "Epoch [71/500], evaluation loss: 9.064648200725687\n",
            "Epoch [72/500], batch 0, batch loss: 8.978285789489746\n",
            "Epoch [72/500], batch 100, batch loss: 8.985668182373047\n",
            "Epoch [72/500], epoch mean loss: 8.988870719383502\n",
            "Epoch [72/500], evaluation loss: 9.064858041960617\n",
            "Epoch [73/500], batch 0, batch loss: 8.996789932250977\n",
            "Epoch [73/500], batch 100, batch loss: 9.00357437133789\n",
            "Epoch [73/500], epoch mean loss: 8.9878849078869\n",
            "Epoch [73/500], evaluation loss: 9.065069626117575\n",
            "Epoch [74/500], batch 0, batch loss: 8.979025840759277\n",
            "Epoch [74/500], batch 100, batch loss: 8.983129501342773\n",
            "Epoch [74/500], epoch mean loss: 8.986941970627884\n",
            "Epoch [74/500], evaluation loss: 9.064912500052616\n",
            "Epoch [75/500], batch 0, batch loss: 8.99751091003418\n",
            "Epoch [75/500], batch 100, batch loss: 8.961681365966797\n",
            "Epoch [75/500], epoch mean loss: 8.986008142602854\n",
            "Epoch [75/500], evaluation loss: 9.065545312289533\n",
            "Epoch [76/500], batch 0, batch loss: 8.984432220458984\n",
            "Epoch [76/500], batch 100, batch loss: 8.98602294921875\n",
            "Epoch [76/500], epoch mean loss: 8.985122475130805\n",
            "Epoch [76/500], evaluation loss: 9.065662022294669\n",
            "Epoch [77/500], batch 0, batch loss: 8.976998329162598\n",
            "Epoch [77/500], batch 100, batch loss: 8.973407745361328\n",
            "Epoch [77/500], epoch mean loss: 8.984036379847034\n",
            "Epoch [77/500], evaluation loss: 9.06515486487027\n",
            "Epoch [78/500], batch 0, batch loss: 9.003371238708496\n",
            "Epoch [78/500], batch 100, batch loss: 8.970327377319336\n",
            "Epoch [78/500], epoch mean loss: 8.983040201252905\n",
            "Epoch [78/500], evaluation loss: 9.065371184513486\n",
            "Epoch [79/500], batch 0, batch loss: 8.990397453308105\n",
            "Epoch [79/500], batch 100, batch loss: 8.986348152160645\n",
            "Epoch [79/500], epoch mean loss: 8.98227754954634\n",
            "Epoch [79/500], evaluation loss: 9.065353525095972\n",
            "Epoch [80/500], batch 0, batch loss: 8.965481758117676\n",
            "Epoch [80/500], batch 100, batch loss: 8.993877410888672\n",
            "Epoch [80/500], epoch mean loss: 8.981264418569104\n",
            "Epoch [80/500], evaluation loss: 9.065796983653101\n",
            "Epoch [81/500], batch 0, batch loss: 8.978047370910645\n",
            "Epoch [81/500], batch 100, batch loss: 8.991808891296387\n",
            "Epoch [81/500], epoch mean loss: 8.980276658617218\n",
            "Epoch [81/500], evaluation loss: 9.065580927092453\n",
            "Epoch [82/500], batch 0, batch loss: 9.00057315826416\n",
            "Epoch [82/500], batch 100, batch loss: 8.973106384277344\n",
            "Epoch [82/500], epoch mean loss: 8.979362701547556\n",
            "Epoch [82/500], evaluation loss: 9.066043919530408\n",
            "Epoch [83/500], batch 0, batch loss: 8.98250675201416\n",
            "Epoch [83/500], batch 100, batch loss: 8.983809471130371\n",
            "Epoch [83/500], epoch mean loss: 8.978291306002387\n",
            "Epoch [83/500], evaluation loss: 9.065709410042599\n",
            "Epoch [84/500], batch 0, batch loss: 8.97216510772705\n",
            "Epoch [84/500], batch 100, batch loss: 8.969157218933105\n",
            "Epoch [84/500], epoch mean loss: 8.977244056504349\n",
            "Epoch [84/500], evaluation loss: 9.065515485303155\n",
            "Epoch [85/500], batch 0, batch loss: 8.984675407409668\n",
            "Epoch [85/500], batch 100, batch loss: 8.981694221496582\n",
            "Epoch [85/500], epoch mean loss: 8.976234098960614\n",
            "Epoch [85/500], evaluation loss: 9.066058257530475\n",
            "Epoch [86/500], batch 0, batch loss: 8.975642204284668\n",
            "Epoch [86/500], batch 100, batch loss: 8.988036155700684\n",
            "Epoch [86/500], epoch mean loss: 8.975200283116308\n",
            "Epoch [86/500], evaluation loss: 9.065803297634783\n",
            "Epoch [87/500], batch 0, batch loss: 8.978022575378418\n",
            "Epoch [87/500], batch 100, batch loss: 8.970281600952148\n",
            "Epoch [87/500], epoch mean loss: 8.974199977414361\n",
            "Epoch [87/500], evaluation loss: 9.065634464395457\n",
            "Epoch [88/500], batch 0, batch loss: 8.97332763671875\n",
            "Epoch [88/500], batch 100, batch loss: 8.955876350402832\n",
            "Epoch [88/500], epoch mean loss: 8.973372574510245\n",
            "Epoch [88/500], evaluation loss: 9.065984627296185\n",
            "Epoch [89/500], batch 0, batch loss: 8.9893159866333\n",
            "Epoch [89/500], batch 100, batch loss: 8.982057571411133\n",
            "Epoch [89/500], epoch mean loss: 8.97263951959281\n",
            "Epoch [89/500], evaluation loss: 9.066193777939368\n",
            "Epoch [90/500], batch 0, batch loss: 8.953001022338867\n",
            "Epoch [90/500], batch 100, batch loss: 8.983053207397461\n",
            "Epoch [90/500], epoch mean loss: 8.971689964162893\n",
            "Epoch [90/500], evaluation loss: 9.065723254762847\n",
            "Epoch [91/500], batch 0, batch loss: 8.995505332946777\n",
            "Epoch [91/500], batch 100, batch loss: 8.970829963684082\n",
            "Epoch [91/500], epoch mean loss: 8.970585140688666\n",
            "Epoch [91/500], evaluation loss: 9.066238765058847\n",
            "Epoch [92/500], batch 0, batch loss: 8.973367691040039\n",
            "Epoch [92/500], batch 100, batch loss: 8.982145309448242\n",
            "Epoch [92/500], epoch mean loss: 8.969218319859998\n",
            "Epoch [92/500], evaluation loss: 9.066198579196271\n",
            "Epoch [93/500], batch 0, batch loss: 8.972110748291016\n",
            "Epoch [93/500], batch 100, batch loss: 8.951811790466309\n",
            "Epoch [93/500], epoch mean loss: 8.968330745039315\n",
            "Epoch [93/500], evaluation loss: 9.066672851299417\n",
            "Epoch [94/500], batch 0, batch loss: 8.975698471069336\n",
            "Epoch [94/500], batch 100, batch loss: 8.986257553100586\n",
            "Epoch [94/500], epoch mean loss: 8.967354264752618\n",
            "Epoch [94/500], evaluation loss: 9.066720666556522\n",
            "Epoch [95/500], batch 0, batch loss: 8.972005844116211\n",
            "Epoch [95/500], batch 100, batch loss: 8.949953079223633\n",
            "Epoch [95/500], epoch mean loss: 8.966451480470855\n",
            "Epoch [95/500], evaluation loss: 9.066436307183627\n",
            "Epoch [96/500], batch 0, batch loss: 8.950667381286621\n",
            "Epoch [96/500], batch 100, batch loss: 8.978257179260254\n",
            "Epoch [96/500], epoch mean loss: 8.965462964156579\n",
            "Epoch [96/500], evaluation loss: 9.066236035577182\n",
            "Epoch [97/500], batch 0, batch loss: 8.952006340026855\n",
            "Epoch [97/500], batch 100, batch loss: 8.95344352722168\n",
            "Epoch [97/500], epoch mean loss: 8.964414514344314\n",
            "Epoch [97/500], evaluation loss: 9.066203610650424\n",
            "Epoch [98/500], batch 0, batch loss: 8.97946834564209\n",
            "Epoch [98/500], batch 100, batch loss: 8.96463394165039\n",
            "Epoch [98/500], epoch mean loss: 8.963462961131128\n",
            "Epoch [98/500], evaluation loss: 9.066185293526486\n",
            "Epoch [99/500], batch 0, batch loss: 8.95190715789795\n",
            "Epoch [99/500], batch 100, batch loss: 8.959311485290527\n",
            "Epoch [99/500], epoch mean loss: 8.962359757258975\n",
            "Epoch [99/500], evaluation loss: 9.066665386331492\n",
            "Epoch [100/500], batch 0, batch loss: 8.976171493530273\n",
            "Epoch [100/500], batch 100, batch loss: 8.96755313873291\n",
            "Epoch [100/500], epoch mean loss: 8.961255649040485\n",
            "Epoch [100/500], evaluation loss: 9.066478597706762\n",
            "Epoch [101/500], batch 0, batch loss: 8.954829216003418\n",
            "Epoch [101/500], batch 100, batch loss: 8.974516868591309\n",
            "Epoch [101/500], epoch mean loss: 8.960163905702789\n",
            "Epoch [101/500], evaluation loss: 9.067124136563006\n",
            "Epoch [102/500], batch 0, batch loss: 8.951377868652344\n",
            "Epoch [102/500], batch 100, batch loss: 8.957743644714355\n",
            "Epoch [102/500], epoch mean loss: 8.959324721632333\n",
            "Epoch [102/500], evaluation loss: 9.067090494879361\n",
            "Epoch [103/500], batch 0, batch loss: 8.956832885742188\n",
            "Epoch [103/500], batch 100, batch loss: 8.96648120880127\n",
            "Epoch [103/500], epoch mean loss: 8.958440517557078\n",
            "Epoch [103/500], evaluation loss: 9.066769402602624\n",
            "Epoch [104/500], batch 0, batch loss: 8.936062812805176\n",
            "Epoch [104/500], batch 100, batch loss: 8.954832077026367\n",
            "Epoch [104/500], epoch mean loss: 8.957564806116038\n",
            "Epoch [104/500], evaluation loss: 9.066810048859695\n",
            "Epoch [105/500], batch 0, batch loss: 8.961596488952637\n",
            "Epoch [105/500], batch 100, batch loss: 8.969215393066406\n",
            "Epoch [105/500], epoch mean loss: 8.956746997504398\n",
            "Epoch [105/500], evaluation loss: 9.066921102589575\n",
            "Epoch [106/500], batch 0, batch loss: 8.981684684753418\n",
            "Epoch [106/500], batch 100, batch loss: 8.956801414489746\n",
            "Epoch [106/500], epoch mean loss: 8.955771807966562\n",
            "Epoch [106/500], evaluation loss: 9.067081089677481\n",
            "Epoch [107/500], batch 0, batch loss: 8.957619667053223\n",
            "Epoch [107/500], batch 100, batch loss: 8.97209358215332\n",
            "Epoch [107/500], epoch mean loss: 8.954826338537808\n",
            "Epoch [107/500], evaluation loss: 9.067255316109494\n",
            "Epoch [108/500], batch 0, batch loss: 8.951178550720215\n",
            "Epoch [108/500], batch 100, batch loss: 8.953533172607422\n",
            "Epoch [108/500], epoch mean loss: 8.953866514666327\n",
            "Epoch [108/500], evaluation loss: 9.067278434490335\n",
            "Epoch [109/500], batch 0, batch loss: 8.944494247436523\n",
            "Epoch [109/500], batch 100, batch loss: 8.969249725341797\n",
            "Epoch [109/500], epoch mean loss: 8.952983198494747\n",
            "Epoch [109/500], evaluation loss: 9.066868288763638\n",
            "Epoch [110/500], batch 0, batch loss: 8.937214851379395\n",
            "Epoch [110/500], batch 100, batch loss: 8.955930709838867\n",
            "Epoch [110/500], epoch mean loss: 8.952119342212018\n",
            "Epoch [110/500], evaluation loss: 9.066996344204608\n",
            "Epoch [111/500], batch 0, batch loss: 8.955802917480469\n",
            "Epoch [111/500], batch 100, batch loss: 8.959588050842285\n",
            "Epoch [111/500], epoch mean loss: 8.951074838638306\n",
            "Epoch [111/500], evaluation loss: 9.066910677942737\n",
            "Epoch [112/500], batch 0, batch loss: 8.950980186462402\n",
            "Epoch [112/500], batch 100, batch loss: 8.950928688049316\n",
            "Epoch [112/500], epoch mean loss: 8.950156104975733\n",
            "Epoch [112/500], evaluation loss: 9.067247522288355\n",
            "Epoch [113/500], batch 0, batch loss: 8.957510948181152\n",
            "Epoch [113/500], batch 100, batch loss: 8.949698448181152\n",
            "Epoch [113/500], epoch mean loss: 8.949337318025787\n",
            "Epoch [113/500], evaluation loss: 9.067211184008368\n",
            "Epoch [114/500], batch 0, batch loss: 8.946972846984863\n",
            "Epoch [114/500], batch 100, batch loss: 8.958724975585938\n",
            "Epoch [114/500], epoch mean loss: 8.948262411972571\n",
            "Epoch [114/500], evaluation loss: 9.067360943761365\n",
            "Epoch [115/500], batch 0, batch loss: 8.933642387390137\n",
            "Epoch [115/500], batch 100, batch loss: 8.941999435424805\n",
            "Epoch [115/500], epoch mean loss: 8.947354185170141\n",
            "Epoch [115/500], evaluation loss: 9.067506329766635\n",
            "Epoch [116/500], batch 0, batch loss: 8.935956001281738\n",
            "Epoch [116/500], batch 100, batch loss: 8.953634262084961\n",
            "Epoch [116/500], epoch mean loss: 8.94633046511946\n",
            "Epoch [116/500], evaluation loss: 9.067426977486447\n",
            "Epoch [117/500], batch 0, batch loss: 8.929978370666504\n",
            "Epoch [117/500], batch 100, batch loss: 8.95863151550293\n",
            "Epoch [117/500], epoch mean loss: 8.945369416269763\n",
            "Epoch [117/500], evaluation loss: 9.067324934334591\n",
            "Epoch [118/500], batch 0, batch loss: 8.9371976852417\n",
            "Epoch [118/500], batch 100, batch loss: 8.924565315246582\n",
            "Epoch [118/500], epoch mean loss: 8.944554444017081\n",
            "Epoch [118/500], evaluation loss: 9.067072671035241\n",
            "Epoch [119/500], batch 0, batch loss: 8.93919563293457\n",
            "Epoch [119/500], batch 100, batch loss: 8.939018249511719\n",
            "Epoch [119/500], epoch mean loss: 8.943714166509695\n",
            "Epoch [119/500], evaluation loss: 9.067338877710803\n",
            "Epoch [120/500], batch 0, batch loss: 8.946025848388672\n",
            "Epoch [120/500], batch 100, batch loss: 8.938111305236816\n",
            "Epoch [120/500], epoch mean loss: 8.942944921296219\n",
            "Epoch [120/500], evaluation loss: 9.06702600676438\n",
            "Epoch [121/500], batch 0, batch loss: 8.929259300231934\n",
            "Epoch [121/500], batch 100, batch loss: 8.951457023620605\n",
            "Epoch [121/500], epoch mean loss: 8.942165596731778\n",
            "Epoch [121/500], evaluation loss: 9.067019890094626\n",
            "Epoch [122/500], batch 0, batch loss: 8.937280654907227\n",
            "Epoch [122/500], batch 100, batch loss: 8.944745063781738\n",
            "Epoch [122/500], epoch mean loss: 8.941082650217517\n",
            "Epoch [122/500], evaluation loss: 9.067378372981631\n",
            "Epoch [123/500], batch 0, batch loss: 8.94655704498291\n",
            "Epoch [123/500], batch 100, batch loss: 8.935909271240234\n",
            "Epoch [123/500], epoch mean loss: 8.94030839821388\n",
            "Epoch [123/500], evaluation loss: 9.067622875345164\n",
            "Epoch [124/500], batch 0, batch loss: 8.952215194702148\n",
            "Epoch [124/500], batch 100, batch loss: 8.937238693237305\n",
            "Epoch [124/500], epoch mean loss: 8.93927891501065\n",
            "Epoch [124/500], evaluation loss: 9.067602782413877\n",
            "Epoch [125/500], batch 0, batch loss: 8.94202995300293\n",
            "Epoch [125/500], batch 100, batch loss: 8.94856071472168\n",
            "Epoch [125/500], epoch mean loss: 8.938289403915405\n",
            "Epoch [125/500], evaluation loss: 9.067478081275677\n",
            "Epoch [126/500], batch 0, batch loss: 8.935491561889648\n",
            "Epoch [126/500], batch 100, batch loss: 8.908937454223633\n",
            "Epoch [126/500], epoch mean loss: 8.937359020627778\n",
            "Epoch [126/500], evaluation loss: 9.067081254104089\n",
            "Epoch [127/500], batch 0, batch loss: 8.926492691040039\n",
            "Epoch [127/500], batch 100, batch loss: 8.931303024291992\n",
            "Epoch [127/500], epoch mean loss: 8.936632353683997\n",
            "Epoch [127/500], evaluation loss: 9.06693826872727\n",
            "Epoch [128/500], batch 0, batch loss: 8.928211212158203\n",
            "Epoch [128/500], batch 100, batch loss: 8.931052207946777\n",
            "Epoch [128/500], epoch mean loss: 8.935741416339216\n",
            "Epoch [128/500], evaluation loss: 9.067893751736346\n",
            "Epoch [129/500], batch 0, batch loss: 8.924300193786621\n",
            "Epoch [129/500], batch 100, batch loss: 8.930415153503418\n",
            "Epoch [129/500], epoch mean loss: 8.934872561487659\n",
            "Epoch [129/500], evaluation loss: 9.067545627725535\n",
            "Epoch [130/500], batch 0, batch loss: 8.948362350463867\n",
            "Epoch [130/500], batch 100, batch loss: 8.925093650817871\n",
            "Epoch [130/500], epoch mean loss: 8.93386274370654\n",
            "Epoch [130/500], evaluation loss: 9.067569798436658\n",
            "Epoch [131/500], batch 0, batch loss: 8.9293851852417\n",
            "Epoch [131/500], batch 100, batch loss: 8.936470985412598\n",
            "Epoch [131/500], epoch mean loss: 8.933044515807053\n",
            "Epoch [131/500], evaluation loss: 9.068150684751313\n",
            "Epoch [132/500], batch 0, batch loss: 8.922128677368164\n",
            "Epoch [132/500], batch 100, batch loss: 8.926329612731934\n",
            "Epoch [132/500], epoch mean loss: 8.932271316133697\n",
            "Epoch [132/500], evaluation loss: 9.06793397048424\n",
            "Epoch [133/500], batch 0, batch loss: 8.928375244140625\n",
            "Epoch [133/500], batch 100, batch loss: 8.955432891845703\n",
            "Epoch [133/500], epoch mean loss: 8.9313391241534\n",
            "Epoch [133/500], evaluation loss: 9.067784999978953\n",
            "Epoch [134/500], batch 0, batch loss: 8.92695426940918\n",
            "Epoch [134/500], batch 100, batch loss: 8.924450874328613\n",
            "Epoch [134/500], epoch mean loss: 8.930506730901785\n",
            "Epoch [134/500], evaluation loss: 9.06763218189108\n",
            "Epoch [135/500], batch 0, batch loss: 8.90833854675293\n",
            "Epoch [135/500], batch 100, batch loss: 8.900402069091797\n",
            "Epoch [135/500], epoch mean loss: 8.929597698408982\n",
            "Epoch [135/500], evaluation loss: 9.067593738950531\n",
            "Epoch [136/500], batch 0, batch loss: 8.930366516113281\n",
            "Epoch [136/500], batch 100, batch loss: 8.941071510314941\n",
            "Epoch [136/500], epoch mean loss: 8.928628346015667\n",
            "Epoch [136/500], evaluation loss: 9.067716927363955\n",
            "Epoch [137/500], batch 0, batch loss: 8.894134521484375\n",
            "Epoch [137/500], batch 100, batch loss: 8.912811279296875\n",
            "Epoch [137/500], epoch mean loss: 8.92776134918476\n",
            "Epoch [137/500], evaluation loss: 9.06737442674308\n",
            "Epoch [138/500], batch 0, batch loss: 8.915918350219727\n",
            "Epoch [138/500], batch 100, batch loss: 8.920697212219238\n",
            "Epoch [138/500], epoch mean loss: 8.92693176762811\n",
            "Epoch [138/500], evaluation loss: 9.067718933368552\n",
            "Epoch [139/500], batch 0, batch loss: 8.930386543273926\n",
            "Epoch [139/500], batch 100, batch loss: 8.928339958190918\n",
            "Epoch [139/500], epoch mean loss: 8.926050819199661\n",
            "Epoch [139/500], evaluation loss: 9.067734521010827\n",
            "Epoch [140/500], batch 0, batch loss: 8.937165260314941\n",
            "Epoch [140/500], batch 100, batch loss: 8.941108703613281\n",
            "Epoch [140/500], epoch mean loss: 8.925115100268659\n",
            "Epoch [140/500], evaluation loss: 9.067920750585095\n",
            "Epoch [141/500], batch 0, batch loss: 8.919328689575195\n",
            "Epoch [141/500], batch 100, batch loss: 8.892744064331055\n",
            "Epoch [141/500], epoch mean loss: 8.92434235276847\n",
            "Epoch [141/500], evaluation loss: 9.067560590546707\n",
            "Epoch [142/500], batch 0, batch loss: 8.924569129943848\n",
            "Epoch [142/500], batch 100, batch loss: 8.916584968566895\n",
            "Epoch [142/500], epoch mean loss: 8.923695712253965\n",
            "Epoch [142/500], evaluation loss: 9.067499719817063\n",
            "Epoch [143/500], batch 0, batch loss: 8.908842086791992\n",
            "Epoch [143/500], batch 100, batch loss: 8.903968811035156\n",
            "Epoch [143/500], epoch mean loss: 8.92285443174428\n",
            "Epoch [143/500], evaluation loss: 9.067994249278101\n",
            "Epoch [144/500], batch 0, batch loss: 8.906167030334473\n",
            "Epoch [144/500], batch 100, batch loss: 8.92908763885498\n",
            "Epoch [144/500], epoch mean loss: 8.921843569854211\n",
            "Epoch [144/500], evaluation loss: 9.06783100654339\n",
            "Epoch [145/500], batch 0, batch loss: 8.9111967086792\n",
            "Epoch [145/500], batch 100, batch loss: 8.93366527557373\n",
            "Epoch [145/500], epoch mean loss: 8.920963879289298\n",
            "Epoch [145/500], evaluation loss: 9.067936403998013\n",
            "Epoch [146/500], batch 0, batch loss: 8.917594909667969\n",
            "Epoch [146/500], batch 100, batch loss: 8.905950546264648\n",
            "Epoch [146/500], epoch mean loss: 8.92025247113458\n",
            "Epoch [146/500], evaluation loss: 9.068051403966443\n",
            "Epoch [147/500], batch 0, batch loss: 8.907733917236328\n",
            "Epoch [147/500], batch 100, batch loss: 8.932455062866211\n",
            "Epoch [147/500], epoch mean loss: 8.919416674252215\n",
            "Epoch [147/500], evaluation loss: 9.067990894975333\n",
            "Epoch [148/500], batch 0, batch loss: 8.8999662399292\n",
            "Epoch [148/500], batch 100, batch loss: 8.934383392333984\n",
            "Epoch [148/500], epoch mean loss: 8.918629818949206\n",
            "Epoch [148/500], evaluation loss: 9.06798977687441\n",
            "Epoch [149/500], batch 0, batch loss: 8.876575469970703\n",
            "Epoch [149/500], batch 100, batch loss: 8.927826881408691\n",
            "Epoch [149/500], epoch mean loss: 8.91762875688487\n",
            "Epoch [149/500], evaluation loss: 9.06813855006777\n",
            "Epoch [150/500], batch 0, batch loss: 8.931151390075684\n",
            "Epoch [150/500], batch 100, batch loss: 8.907875061035156\n",
            "Epoch [150/500], epoch mean loss: 8.91683684546372\n",
            "Epoch [150/500], evaluation loss: 9.06862916617558\n",
            "Epoch [151/500], batch 0, batch loss: 8.913749694824219\n",
            "Epoch [151/500], batch 100, batch loss: 8.887434005737305\n",
            "Epoch [151/500], epoch mean loss: 8.91608371405766\n",
            "Epoch [151/500], evaluation loss: 9.068503018083243\n",
            "Epoch [152/500], batch 0, batch loss: 8.912924766540527\n",
            "Epoch [152/500], batch 100, batch loss: 8.928932189941406\n",
            "Epoch [152/500], epoch mean loss: 8.915317782040301\n",
            "Epoch [152/500], evaluation loss: 9.06833714452283\n",
            "Epoch [153/500], batch 0, batch loss: 8.892160415649414\n",
            "Epoch [153/500], batch 100, batch loss: 8.908967971801758\n",
            "Epoch [153/500], epoch mean loss: 8.914539986643298\n",
            "Epoch [153/500], evaluation loss: 9.06824072476091\n",
            "Epoch [154/500], batch 0, batch loss: 8.896230697631836\n",
            "Epoch [154/500], batch 100, batch loss: 8.883636474609375\n",
            "Epoch [154/500], epoch mean loss: 8.913698952773522\n",
            "Epoch [154/500], evaluation loss: 9.068441160793963\n",
            "Epoch [155/500], batch 0, batch loss: 8.87767505645752\n",
            "Epoch [155/500], batch 100, batch loss: 8.909896850585938\n",
            "Epoch [155/500], epoch mean loss: 8.912889275057562\n",
            "Epoch [155/500], evaluation loss: 9.068358191128436\n",
            "Epoch [156/500], batch 0, batch loss: 8.893274307250977\n",
            "Epoch [156/500], batch 100, batch loss: 8.925158500671387\n",
            "Epoch [156/500], epoch mean loss: 8.911965378399554\n",
            "Epoch [156/500], evaluation loss: 9.068350068454084\n",
            "Epoch [157/500], batch 0, batch loss: 8.930295944213867\n",
            "Epoch [157/500], batch 100, batch loss: 8.926403999328613\n",
            "Epoch [157/500], epoch mean loss: 8.911225614876583\n",
            "Epoch [157/500], evaluation loss: 9.06868944496944\n",
            "Epoch [158/500], batch 0, batch loss: 8.892497062683105\n",
            "Epoch [158/500], batch 100, batch loss: 8.933728218078613\n",
            "Epoch [158/500], epoch mean loss: 8.910309561367693\n",
            "Epoch [158/500], evaluation loss: 9.06833609219255\n",
            "Epoch [159/500], batch 0, batch loss: 8.90404224395752\n",
            "Epoch [159/500], batch 100, batch loss: 8.923596382141113\n",
            "Epoch [159/500], epoch mean loss: 8.90938110187136\n",
            "Epoch [159/500], evaluation loss: 9.068601509620404\n",
            "Epoch [160/500], batch 0, batch loss: 8.912715911865234\n",
            "Epoch [160/500], batch 100, batch loss: 8.900091171264648\n",
            "Epoch [160/500], epoch mean loss: 8.908571045974206\n",
            "Epoch [160/500], evaluation loss: 9.068596642592858\n",
            "Epoch [161/500], batch 0, batch loss: 8.891107559204102\n",
            "Epoch [161/500], batch 100, batch loss: 8.92814826965332\n",
            "Epoch [161/500], epoch mean loss: 8.907904427627038\n",
            "Epoch [161/500], evaluation loss: 9.06865718446929\n",
            "Epoch [162/500], batch 0, batch loss: 8.92920207977295\n",
            "Epoch [162/500], batch 100, batch loss: 8.91574478149414\n",
            "Epoch [162/500], epoch mean loss: 8.90719068461451\n",
            "Epoch [162/500], evaluation loss: 9.06895190271838\n",
            "Epoch [163/500], batch 0, batch loss: 8.909858703613281\n",
            "Epoch [163/500], batch 100, batch loss: 8.896602630615234\n",
            "Epoch [163/500], epoch mean loss: 8.906341758267633\n",
            "Epoch [163/500], evaluation loss: 9.068944931030273\n",
            "Epoch [164/500], batch 0, batch loss: 8.916428565979004\n",
            "Epoch [164/500], batch 100, batch loss: 8.904675483703613\n",
            "Epoch [164/500], epoch mean loss: 8.905579057233087\n",
            "Epoch [164/500], evaluation loss: 9.068892281630944\n",
            "Epoch [165/500], batch 0, batch loss: 8.900142669677734\n",
            "Epoch [165/500], batch 100, batch loss: 8.902589797973633\n",
            "Epoch [165/500], epoch mean loss: 8.904599633710138\n",
            "Epoch [165/500], evaluation loss: 9.069256256366598\n",
            "Epoch [166/500], batch 0, batch loss: 8.915668487548828\n",
            "Epoch [166/500], batch 100, batch loss: 8.894698143005371\n",
            "Epoch [166/500], epoch mean loss: 8.903719112790863\n",
            "Epoch [166/500], evaluation loss: 9.06933123489906\n",
            "Epoch [167/500], batch 0, batch loss: 8.926457405090332\n",
            "Epoch [167/500], batch 100, batch loss: 8.918787002563477\n",
            "Epoch [167/500], epoch mean loss: 8.902873770944003\n",
            "Epoch [167/500], evaluation loss: 9.069150858911975\n",
            "Epoch [168/500], batch 0, batch loss: 8.904191017150879\n",
            "Epoch [168/500], batch 100, batch loss: 8.90644359588623\n",
            "Epoch [168/500], epoch mean loss: 8.902217264833121\n",
            "Epoch [168/500], evaluation loss: 9.069784065772748\n",
            "Epoch [169/500], batch 0, batch loss: 8.899004936218262\n",
            "Epoch [169/500], batch 100, batch loss: 8.886034965515137\n",
            "Epoch [169/500], epoch mean loss: 8.901344537734985\n",
            "Epoch [169/500], evaluation loss: 9.069583235115841\n",
            "Epoch [170/500], batch 0, batch loss: 8.885644912719727\n",
            "Epoch [170/500], batch 100, batch loss: 8.906050682067871\n",
            "Epoch [170/500], epoch mean loss: 8.90045325509433\n",
            "Epoch [170/500], evaluation loss: 9.069093572682348\n",
            "Epoch [171/500], batch 0, batch loss: 8.935518264770508\n",
            "Epoch [171/500], batch 100, batch loss: 8.931295394897461\n",
            "Epoch [171/500], epoch mean loss: 8.899573375438822\n",
            "Epoch [171/500], evaluation loss: 9.06945116766568\n",
            "Epoch [172/500], batch 0, batch loss: 8.887236595153809\n",
            "Epoch [172/500], batch 100, batch loss: 8.899139404296875\n",
            "Epoch [172/500], epoch mean loss: 8.898781562673635\n",
            "Epoch [172/500], evaluation loss: 9.069733093524802\n",
            "Epoch [173/500], batch 0, batch loss: 8.895234107971191\n",
            "Epoch [173/500], batch 100, batch loss: 8.902688026428223\n",
            "Epoch [173/500], epoch mean loss: 8.897921578637485\n",
            "Epoch [173/500], evaluation loss: 9.06967179528598\n",
            "Epoch [174/500], batch 0, batch loss: 8.92061996459961\n",
            "Epoch [174/500], batch 100, batch loss: 8.88135814666748\n",
            "Epoch [174/500], epoch mean loss: 8.896780581309878\n",
            "Epoch [174/500], evaluation loss: 9.069477245725434\n",
            "Epoch [175/500], batch 0, batch loss: 8.88154411315918\n",
            "Epoch [175/500], batch 100, batch loss: 8.892928123474121\n",
            "Epoch [175/500], epoch mean loss: 8.896085237634592\n",
            "Epoch [175/500], evaluation loss: 9.069957174103836\n",
            "Epoch [176/500], batch 0, batch loss: 8.89223861694336\n",
            "Epoch [176/500], batch 100, batch loss: 8.910782814025879\n",
            "Epoch [176/500], epoch mean loss: 8.89536793478604\n",
            "Epoch [176/500], evaluation loss: 9.0698488169703\n",
            "Epoch [177/500], batch 0, batch loss: 8.912813186645508\n",
            "Epoch [177/500], batch 100, batch loss: 8.887043952941895\n",
            "Epoch [177/500], epoch mean loss: 8.89439396200509\n",
            "Epoch [177/500], evaluation loss: 9.069452877702384\n",
            "Epoch [178/500], batch 0, batch loss: 8.880560874938965\n",
            "Epoch [178/500], batch 100, batch loss: 8.907931327819824\n",
            "Epoch [178/500], epoch mean loss: 8.893453112963972\n",
            "Epoch [178/500], evaluation loss: 9.069748122116614\n",
            "Epoch [179/500], batch 0, batch loss: 8.89804458618164\n",
            "Epoch [179/500], batch 100, batch loss: 8.892277717590332\n",
            "Epoch [179/500], epoch mean loss: 8.892722269584393\n",
            "Epoch [179/500], evaluation loss: 9.070198979871027\n",
            "Epoch [180/500], batch 0, batch loss: 8.910508155822754\n",
            "Epoch [180/500], batch 100, batch loss: 8.885420799255371\n",
            "Epoch [180/500], epoch mean loss: 8.891736606071735\n",
            "Epoch [180/500], evaluation loss: 9.070064314480486\n",
            "Epoch [181/500], batch 0, batch loss: 8.905129432678223\n",
            "Epoch [181/500], batch 100, batch loss: 8.89429759979248\n",
            "Epoch [181/500], epoch mean loss: 8.890936695296189\n",
            "Epoch [181/500], evaluation loss: 9.069847139818915\n",
            "Epoch [182/500], batch 0, batch loss: 8.897726058959961\n",
            "Epoch [182/500], batch 100, batch loss: 8.882708549499512\n",
            "Epoch [182/500], epoch mean loss: 8.890011918955835\n",
            "Epoch [182/500], evaluation loss: 9.069845100928998\n",
            "Epoch [183/500], batch 0, batch loss: 8.914756774902344\n",
            "Epoch [183/500], batch 100, batch loss: 8.890307426452637\n",
            "Epoch [183/500], epoch mean loss: 8.88917952570422\n",
            "Epoch [183/500], evaluation loss: 9.069878907039248\n",
            "Epoch [184/500], batch 0, batch loss: 8.903056144714355\n",
            "Epoch [184/500], batch 100, batch loss: 8.881275177001953\n",
            "Epoch [184/500], epoch mean loss: 8.888458523257025\n",
            "Epoch [184/500], evaluation loss: 9.070120120870657\n",
            "Epoch [185/500], batch 0, batch loss: 8.883091926574707\n",
            "Epoch [185/500], batch 100, batch loss: 8.89916706085205\n",
            "Epoch [185/500], epoch mean loss: 8.887557194150727\n",
            "Epoch [185/500], evaluation loss: 9.069562385822165\n",
            "Epoch [186/500], batch 0, batch loss: 8.892004013061523\n",
            "Epoch [186/500], batch 100, batch loss: 8.896288871765137\n",
            "Epoch [186/500], epoch mean loss: 8.886522424632105\n",
            "Epoch [186/500], evaluation loss: 9.070115352499075\n",
            "Epoch [187/500], batch 0, batch loss: 8.85483169555664\n",
            "Epoch [187/500], batch 100, batch loss: 8.891264915466309\n",
            "Epoch [187/500], epoch mean loss: 8.885763858926707\n",
            "Epoch [187/500], evaluation loss: 9.070270735642005\n",
            "Epoch [188/500], batch 0, batch loss: 8.891105651855469\n",
            "Epoch [188/500], batch 100, batch loss: 8.861937522888184\n",
            "Epoch [188/500], epoch mean loss: 8.884888821634753\n",
            "Epoch [188/500], evaluation loss: 9.069685870203479\n",
            "Epoch [189/500], batch 0, batch loss: 8.91671085357666\n",
            "Epoch [189/500], batch 100, batch loss: 8.898959159851074\n",
            "Epoch [189/500], epoch mean loss: 8.88415186158542\n",
            "Epoch [189/500], evaluation loss: 9.070246367618955\n",
            "Epoch [190/500], batch 0, batch loss: 8.872790336608887\n",
            "Epoch [190/500], batch 100, batch loss: 8.900104522705078\n",
            "Epoch [190/500], epoch mean loss: 8.883177379081989\n",
            "Epoch [190/500], evaluation loss: 9.069959410305682\n",
            "Epoch [191/500], batch 0, batch loss: 8.885536193847656\n",
            "Epoch [191/500], batch 100, batch loss: 8.866680145263672\n",
            "Epoch [191/500], epoch mean loss: 8.882510670300189\n",
            "Epoch [191/500], evaluation loss: 9.070088287879681\n",
            "Epoch [192/500], batch 0, batch loss: 8.885490417480469\n",
            "Epoch [192/500], batch 100, batch loss: 8.909934043884277\n",
            "Epoch [192/500], epoch mean loss: 8.881612350200784\n",
            "Epoch [192/500], evaluation loss: 9.069844213025323\n",
            "Epoch [193/500], batch 0, batch loss: 8.87177562713623\n",
            "Epoch [193/500], batch 100, batch loss: 8.916726112365723\n",
            "Epoch [193/500], epoch mean loss: 8.880892474075843\n",
            "Epoch [193/500], evaluation loss: 9.070534245721225\n",
            "Epoch [194/500], batch 0, batch loss: 8.850363731384277\n",
            "Epoch [194/500], batch 100, batch loss: 8.891639709472656\n",
            "Epoch [194/500], epoch mean loss: 8.879987560469528\n",
            "Epoch [194/500], evaluation loss: 9.070762667162665\n",
            "Epoch [195/500], batch 0, batch loss: 8.86497688293457\n",
            "Epoch [195/500], batch 100, batch loss: 8.8981351852417\n",
            "Epoch [195/500], epoch mean loss: 8.879053362484637\n",
            "Epoch [195/500], evaluation loss: 9.069940336819354\n",
            "Epoch [196/500], batch 0, batch loss: 8.877623558044434\n",
            "Epoch [196/500], batch 100, batch loss: 8.8678617477417\n",
            "Epoch [196/500], epoch mean loss: 8.878353834152222\n",
            "Epoch [196/500], evaluation loss: 9.070292472839355\n",
            "Epoch [197/500], batch 0, batch loss: 8.895249366760254\n",
            "Epoch [197/500], batch 100, batch loss: 8.878636360168457\n",
            "Epoch [197/500], epoch mean loss: 8.877528593457978\n",
            "Epoch [197/500], evaluation loss: 9.070435589757459\n",
            "Epoch [198/500], batch 0, batch loss: 8.883382797241211\n",
            "Epoch [198/500], batch 100, batch loss: 8.876715660095215\n",
            "Epoch [198/500], epoch mean loss: 8.876753691969247\n",
            "Epoch [198/500], evaluation loss: 9.07018911427465\n",
            "Epoch [199/500], batch 0, batch loss: 8.859282493591309\n",
            "Epoch [199/500], batch 100, batch loss: 8.841453552246094\n",
            "Epoch [199/500], epoch mean loss: 8.875714474710925\n",
            "Epoch [199/500], evaluation loss: 9.07079446726832\n",
            "Epoch [200/500], batch 0, batch loss: 8.858391761779785\n",
            "Epoch [200/500], batch 100, batch loss: 8.861943244934082\n",
            "Epoch [200/500], epoch mean loss: 8.87501647554595\n",
            "Epoch [200/500], evaluation loss: 9.07039237844533\n",
            "Epoch [201/500], batch 0, batch loss: 8.86786937713623\n",
            "Epoch [201/500], batch 100, batch loss: 8.870840072631836\n",
            "Epoch [201/500], epoch mean loss: 8.874197252865496\n",
            "Epoch [201/500], evaluation loss: 9.070635795593262\n",
            "Epoch [202/500], batch 0, batch loss: 8.88046932220459\n",
            "Epoch [202/500], batch 100, batch loss: 8.862870216369629\n",
            "Epoch [202/500], epoch mean loss: 8.873455993060407\n",
            "Epoch [202/500], evaluation loss: 9.070817158139985\n",
            "Epoch [203/500], batch 0, batch loss: 8.863953590393066\n",
            "Epoch [203/500], batch 100, batch loss: 8.871790885925293\n",
            "Epoch [203/500], epoch mean loss: 8.872482538223267\n",
            "Epoch [203/500], evaluation loss: 9.070625765570279\n",
            "Epoch [204/500], batch 0, batch loss: 8.86989688873291\n",
            "Epoch [204/500], batch 100, batch loss: 8.895166397094727\n",
            "Epoch [204/500], epoch mean loss: 8.871685710446588\n",
            "Epoch [204/500], evaluation loss: 9.070783845309553\n",
            "Epoch [205/500], batch 0, batch loss: 8.869349479675293\n",
            "Epoch [205/500], batch 100, batch loss: 8.8699312210083\n",
            "Epoch [205/500], epoch mean loss: 8.870995661308026\n",
            "Epoch [205/500], evaluation loss: 9.070937123791925\n",
            "Epoch [206/500], batch 0, batch loss: 8.88354778289795\n",
            "Epoch [206/500], batch 100, batch loss: 8.891118049621582\n",
            "Epoch [206/500], epoch mean loss: 8.870113652327966\n",
            "Epoch [206/500], evaluation loss: 9.07068209812559\n",
            "Epoch [207/500], batch 0, batch loss: 8.88222599029541\n",
            "Epoch [207/500], batch 100, batch loss: 8.87783432006836\n",
            "Epoch [207/500], epoch mean loss: 8.869319356721023\n",
            "Epoch [207/500], evaluation loss: 9.071140618159854\n",
            "Epoch [208/500], batch 0, batch loss: 8.878491401672363\n",
            "Epoch [208/500], batch 100, batch loss: 8.844483375549316\n",
            "Epoch [208/500], epoch mean loss: 8.868488155562302\n",
            "Epoch [208/500], evaluation loss: 9.07075309753418\n",
            "Epoch [209/500], batch 0, batch loss: 8.885459899902344\n",
            "Epoch [209/500], batch 100, batch loss: 8.869821548461914\n",
            "Epoch [209/500], epoch mean loss: 8.867606072590268\n",
            "Epoch [209/500], evaluation loss: 9.0705880461068\n",
            "Epoch [210/500], batch 0, batch loss: 8.875801086425781\n",
            "Epoch [210/500], batch 100, batch loss: 8.85912799835205\n",
            "Epoch [210/500], epoch mean loss: 8.867036326178189\n",
            "Epoch [210/500], evaluation loss: 9.070678119001718\n",
            "Epoch [211/500], batch 0, batch loss: 8.88511848449707\n",
            "Epoch [211/500], batch 100, batch loss: 8.85407543182373\n",
            "Epoch [211/500], epoch mean loss: 8.866178142613379\n",
            "Epoch [211/500], evaluation loss: 9.070561441881903\n",
            "Epoch [212/500], batch 0, batch loss: 8.897286415100098\n",
            "Epoch [212/500], batch 100, batch loss: 8.871500968933105\n",
            "Epoch [212/500], epoch mean loss: 8.865482782495432\n",
            "Epoch [212/500], evaluation loss: 9.071259958990689\n",
            "Epoch [213/500], batch 0, batch loss: 8.8522367477417\n",
            "Epoch [213/500], batch 100, batch loss: 8.886676788330078\n",
            "Epoch [213/500], epoch mean loss: 8.864664077758789\n",
            "Epoch [213/500], evaluation loss: 9.071190505192197\n",
            "Epoch [214/500], batch 0, batch loss: 8.87940502166748\n",
            "Epoch [214/500], batch 100, batch loss: 8.85425853729248\n",
            "Epoch [214/500], epoch mean loss: 8.864014378909406\n",
            "Epoch [214/500], evaluation loss: 9.071179324182971\n",
            "Epoch [215/500], batch 0, batch loss: 8.86577320098877\n",
            "Epoch [215/500], batch 100, batch loss: 8.857390403747559\n",
            "Epoch [215/500], epoch mean loss: 8.863144159317017\n",
            "Epoch [215/500], evaluation loss: 9.071050249297043\n",
            "Epoch [216/500], batch 0, batch loss: 8.86706256866455\n",
            "Epoch [216/500], batch 100, batch loss: 8.841547966003418\n",
            "Epoch [216/500], epoch mean loss: 8.862284594568713\n",
            "Epoch [216/500], evaluation loss: 9.071027985934553\n",
            "Epoch [217/500], batch 0, batch loss: 8.86405086517334\n",
            "Epoch [217/500], batch 100, batch loss: 8.8529052734375\n",
            "Epoch [217/500], epoch mean loss: 8.861455826923764\n",
            "Epoch [217/500], evaluation loss: 9.071565759593042\n",
            "Epoch [218/500], batch 0, batch loss: 8.836852073669434\n",
            "Epoch [218/500], batch 100, batch loss: 8.834661483764648\n",
            "Epoch [218/500], epoch mean loss: 8.860654197890183\n",
            "Epoch [218/500], evaluation loss: 9.071588088726175\n",
            "Epoch [219/500], batch 0, batch loss: 8.869829177856445\n",
            "Epoch [219/500], batch 100, batch loss: 8.840864181518555\n",
            "Epoch [219/500], epoch mean loss: 8.859994066172632\n",
            "Epoch [219/500], evaluation loss: 9.071137230971765\n",
            "Epoch [220/500], batch 0, batch loss: 8.865970611572266\n",
            "Epoch [220/500], batch 100, batch loss: 8.881598472595215\n",
            "Epoch [220/500], epoch mean loss: 8.859117376393286\n",
            "Epoch [220/500], evaluation loss: 9.07127936133023\n",
            "Epoch [221/500], batch 0, batch loss: 8.872937202453613\n",
            "Epoch [221/500], batch 100, batch loss: 8.881918907165527\n",
            "Epoch [221/500], epoch mean loss: 8.858479064086389\n",
            "Epoch [221/500], evaluation loss: 9.07145565953748\n",
            "Epoch [222/500], batch 0, batch loss: 8.858832359313965\n",
            "Epoch [222/500], batch 100, batch loss: 8.854022026062012\n",
            "Epoch [222/500], epoch mean loss: 8.857669090402537\n",
            "Epoch [222/500], evaluation loss: 9.071578551983011\n",
            "Epoch [223/500], batch 0, batch loss: 8.867998123168945\n",
            "Epoch [223/500], batch 100, batch loss: 8.853565216064453\n",
            "Epoch [223/500], epoch mean loss: 8.85681779631253\n",
            "Epoch [223/500], evaluation loss: 9.072056967636634\n",
            "Epoch [224/500], batch 0, batch loss: 8.83858585357666\n",
            "Epoch [224/500], batch 100, batch loss: 8.878335952758789\n",
            "Epoch [224/500], epoch mean loss: 8.856202092663995\n",
            "Epoch [224/500], evaluation loss: 9.071712592552448\n",
            "Epoch [225/500], batch 0, batch loss: 8.853891372680664\n",
            "Epoch [225/500], batch 100, batch loss: 8.848990440368652\n",
            "Epoch [225/500], epoch mean loss: 8.85533201283422\n",
            "Epoch [225/500], evaluation loss: 9.07230729070203\n",
            "Epoch [226/500], batch 0, batch loss: 8.8396577835083\n",
            "Epoch [226/500], batch 100, batch loss: 8.88339614868164\n",
            "Epoch [226/500], epoch mean loss: 8.854383871473114\n",
            "Epoch [226/500], evaluation loss: 9.071933055746145\n",
            "Epoch [227/500], batch 0, batch loss: 8.825016975402832\n",
            "Epoch [227/500], batch 100, batch loss: 8.880431175231934\n",
            "Epoch [227/500], epoch mean loss: 8.853651178294214\n",
            "Epoch [227/500], evaluation loss: 9.072233792009024\n",
            "Epoch [228/500], batch 0, batch loss: 8.838458061218262\n",
            "Epoch [228/500], batch 100, batch loss: 8.841665267944336\n",
            "Epoch [228/500], epoch mean loss: 8.852836452681442\n",
            "Epoch [228/500], evaluation loss: 9.072186437146417\n",
            "Epoch [229/500], batch 0, batch loss: 8.859794616699219\n",
            "Epoch [229/500], batch 100, batch loss: 8.858138084411621\n",
            "Epoch [229/500], epoch mean loss: 8.851907960299787\n",
            "Epoch [229/500], evaluation loss: 9.072097021957923\n",
            "Epoch [230/500], batch 0, batch loss: 8.870415687561035\n",
            "Epoch [230/500], batch 100, batch loss: 8.84795093536377\n",
            "Epoch [230/500], epoch mean loss: 8.851141880298483\n",
            "Epoch [230/500], evaluation loss: 9.071969459796774\n",
            "Epoch [231/500], batch 0, batch loss: 8.848260879516602\n",
            "Epoch [231/500], batch 100, batch loss: 8.830784797668457\n",
            "Epoch [231/500], epoch mean loss: 8.85018565736968\n",
            "Epoch [231/500], evaluation loss: 9.072155985338934\n",
            "Epoch [232/500], batch 0, batch loss: 8.837645530700684\n",
            "Epoch [232/500], batch 100, batch loss: 8.86202621459961\n",
            "Epoch [232/500], epoch mean loss: 8.849399772183649\n",
            "Epoch [232/500], evaluation loss: 9.072115898132324\n",
            "Epoch [233/500], batch 0, batch loss: 8.84446907043457\n",
            "Epoch [233/500], batch 100, batch loss: 8.841426849365234\n",
            "Epoch [233/500], epoch mean loss: 8.848558253255383\n",
            "Epoch [233/500], evaluation loss: 9.07284088792472\n",
            "Epoch [234/500], batch 0, batch loss: 8.841304779052734\n",
            "Epoch [234/500], batch 100, batch loss: 8.830779075622559\n",
            "Epoch [234/500], epoch mean loss: 8.847911489420923\n",
            "Epoch [234/500], evaluation loss: 9.072446428496262\n",
            "Epoch [235/500], batch 0, batch loss: 8.846104621887207\n",
            "Epoch [235/500], batch 100, batch loss: 8.839195251464844\n",
            "Epoch [235/500], epoch mean loss: 8.847114472553647\n",
            "Epoch [235/500], evaluation loss: 9.072798104121768\n",
            "Epoch [236/500], batch 0, batch loss: 8.841064453125\n",
            "Epoch [236/500], batch 100, batch loss: 8.870924949645996\n",
            "Epoch [236/500], epoch mean loss: 8.84633024807634\n",
            "Epoch [236/500], evaluation loss: 9.072647094726562\n",
            "Epoch [237/500], batch 0, batch loss: 8.844481468200684\n",
            "Epoch [237/500], batch 100, batch loss: 8.856429100036621\n",
            "Epoch [237/500], epoch mean loss: 8.845732187402659\n",
            "Epoch [237/500], evaluation loss: 9.072612400712638\n",
            "Epoch [238/500], batch 0, batch loss: 8.84415054321289\n",
            "Epoch [238/500], batch 100, batch loss: 8.856158256530762\n",
            "Epoch [238/500], epoch mean loss: 8.844883910540876\n",
            "Epoch [238/500], evaluation loss: 9.072697738121295\n",
            "Epoch [239/500], batch 0, batch loss: 8.83862018585205\n",
            "Epoch [239/500], batch 100, batch loss: 8.838719367980957\n",
            "Epoch [239/500], epoch mean loss: 8.84411749346503\n",
            "Epoch [239/500], evaluation loss: 9.07285341723212\n",
            "Epoch [240/500], batch 0, batch loss: 8.828235626220703\n",
            "Epoch [240/500], batch 100, batch loss: 8.83071231842041\n",
            "Epoch [240/500], epoch mean loss: 8.843336828823748\n",
            "Epoch [240/500], evaluation loss: 9.072477636666134\n",
            "Epoch [241/500], batch 0, batch loss: 8.833645820617676\n",
            "Epoch [241/500], batch 100, batch loss: 8.831742286682129\n",
            "Epoch [241/500], epoch mean loss: 8.84235954284668\n",
            "Epoch [241/500], evaluation loss: 9.073143531536234\n",
            "Epoch [242/500], batch 0, batch loss: 8.872956275939941\n",
            "Epoch [242/500], batch 100, batch loss: 8.840705871582031\n",
            "Epoch [242/500], epoch mean loss: 8.841571372130822\n",
            "Epoch [242/500], evaluation loss: 9.072823656016382\n",
            "Epoch [243/500], batch 0, batch loss: 8.844027519226074\n",
            "Epoch [243/500], batch 100, batch loss: 8.835683822631836\n",
            "Epoch [243/500], epoch mean loss: 8.840911931005017\n",
            "Epoch [243/500], evaluation loss: 9.072635190240268\n",
            "Epoch [244/500], batch 0, batch loss: 8.851251602172852\n",
            "Epoch [244/500], batch 100, batch loss: 8.82395076751709\n",
            "Epoch [244/500], epoch mean loss: 8.839983496172675\n",
            "Epoch [244/500], evaluation loss: 9.072325673596612\n",
            "Epoch [245/500], batch 0, batch loss: 8.8487548828125\n",
            "Epoch [245/500], batch 100, batch loss: 8.83007526397705\n",
            "Epoch [245/500], epoch mean loss: 8.8394207214487\n",
            "Epoch [245/500], evaluation loss: 9.073221798600821\n",
            "Epoch [246/500], batch 0, batch loss: 8.819064140319824\n",
            "Epoch [246/500], batch 100, batch loss: 8.856934547424316\n",
            "Epoch [246/500], epoch mean loss: 8.838626582047034\n",
            "Epoch [246/500], evaluation loss: 9.072842630846747\n",
            "Epoch [247/500], batch 0, batch loss: 8.800493240356445\n",
            "Epoch [247/500], batch 100, batch loss: 8.824801445007324\n",
            "Epoch [247/500], epoch mean loss: 8.837826942575388\n",
            "Epoch [247/500], evaluation loss: 9.072896595658927\n",
            "Epoch [248/500], batch 0, batch loss: 8.850305557250977\n",
            "Epoch [248/500], batch 100, batch loss: 8.849398612976074\n",
            "Epoch [248/500], epoch mean loss: 8.837048357930676\n",
            "Epoch [248/500], evaluation loss: 9.072918760365454\n",
            "Epoch [249/500], batch 0, batch loss: 8.81574821472168\n",
            "Epoch [249/500], batch 100, batch loss: 8.850811004638672\n",
            "Epoch [249/500], epoch mean loss: 8.83638724787482\n",
            "Epoch [249/500], evaluation loss: 9.072942898191254\n",
            "Epoch [250/500], batch 0, batch loss: 8.829739570617676\n",
            "Epoch [250/500], batch 100, batch loss: 8.845394134521484\n",
            "Epoch [250/500], epoch mean loss: 8.835692866095181\n",
            "Epoch [250/500], evaluation loss: 9.072840032906369\n",
            "Epoch [251/500], batch 0, batch loss: 8.835429191589355\n",
            "Epoch [251/500], batch 100, batch loss: 8.826909065246582\n",
            "Epoch [251/500], epoch mean loss: 8.834865487855057\n",
            "Epoch [251/500], evaluation loss: 9.072948094072013\n",
            "Epoch [252/500], batch 0, batch loss: 8.851293563842773\n",
            "Epoch [252/500], batch 100, batch loss: 8.83080005645752\n",
            "Epoch [252/500], epoch mean loss: 8.83421932417771\n",
            "Epoch [252/500], evaluation loss: 9.07321962816962\n",
            "Epoch [253/500], batch 0, batch loss: 8.818939208984375\n",
            "Epoch [253/500], batch 100, batch loss: 8.83873176574707\n",
            "Epoch [253/500], epoch mean loss: 8.833421600276026\n",
            "Epoch [253/500], evaluation loss: 9.07299518585205\n",
            "Epoch [254/500], batch 0, batch loss: 8.832294464111328\n",
            "Epoch [254/500], batch 100, batch loss: 8.82475471496582\n",
            "Epoch [254/500], epoch mean loss: 8.832546661640036\n",
            "Epoch [254/500], evaluation loss: 9.07351776649212\n",
            "Epoch [255/500], batch 0, batch loss: 8.829812049865723\n",
            "Epoch [255/500], batch 100, batch loss: 8.845104217529297\n",
            "Epoch [255/500], epoch mean loss: 8.83181044151043\n",
            "Epoch [255/500], evaluation loss: 9.073383561496076\n",
            "Epoch [256/500], batch 0, batch loss: 8.830794334411621\n",
            "Epoch [256/500], batch 100, batch loss: 8.81024169921875\n",
            "Epoch [256/500], epoch mean loss: 8.831143576523353\n",
            "Epoch [256/500], evaluation loss: 9.073196772871347\n",
            "Epoch [257/500], batch 0, batch loss: 8.811357498168945\n",
            "Epoch [257/500], batch 100, batch loss: 8.814180374145508\n",
            "Epoch [257/500], epoch mean loss: 8.830451356953589\n",
            "Epoch [257/500], evaluation loss: 9.073678674369022\n",
            "Epoch [258/500], batch 0, batch loss: 8.837646484375\n",
            "Epoch [258/500], batch 100, batch loss: 8.808039665222168\n",
            "Epoch [258/500], epoch mean loss: 8.82966501959439\n",
            "Epoch [258/500], evaluation loss: 9.073610371556775\n",
            "Epoch [259/500], batch 0, batch loss: 8.860993385314941\n",
            "Epoch [259/500], batch 100, batch loss: 8.803136825561523\n",
            "Epoch [259/500], epoch mean loss: 8.828889197316663\n",
            "Epoch [259/500], evaluation loss: 9.073918474131617\n",
            "Epoch [260/500], batch 0, batch loss: 8.829216003417969\n",
            "Epoch [260/500], batch 100, batch loss: 8.822909355163574\n",
            "Epoch [260/500], epoch mean loss: 8.828143777518436\n",
            "Epoch [260/500], evaluation loss: 9.073570054152917\n",
            "Epoch [261/500], batch 0, batch loss: 8.773505210876465\n",
            "Epoch [261/500], batch 100, batch loss: 8.837808609008789\n",
            "Epoch [261/500], epoch mean loss: 8.827494851474103\n",
            "Epoch [261/500], evaluation loss: 9.073692058694773\n",
            "Epoch [262/500], batch 0, batch loss: 8.805146217346191\n",
            "Epoch [262/500], batch 100, batch loss: 8.809319496154785\n",
            "Epoch [262/500], epoch mean loss: 8.826777671945505\n",
            "Epoch [262/500], evaluation loss: 9.07374040011702\n",
            "Epoch [263/500], batch 0, batch loss: 8.842592239379883\n",
            "Epoch [263/500], batch 100, batch loss: 8.830709457397461\n",
            "Epoch [263/500], epoch mean loss: 8.825956385711144\n",
            "Epoch [263/500], evaluation loss: 9.07412262620597\n",
            "Epoch [264/500], batch 0, batch loss: 8.82657241821289\n",
            "Epoch [264/500], batch 100, batch loss: 8.820088386535645\n",
            "Epoch [264/500], epoch mean loss: 8.82527704074465\n",
            "Epoch [264/500], evaluation loss: 9.074027028577081\n",
            "Epoch [265/500], batch 0, batch loss: 8.842488288879395\n",
            "Epoch [265/500], batch 100, batch loss: 8.822628021240234\n",
            "Epoch [265/500], epoch mean loss: 8.82453544386502\n",
            "Epoch [265/500], evaluation loss: 9.073880096961712\n",
            "Epoch [266/500], batch 0, batch loss: 8.833722114562988\n",
            "Epoch [266/500], batch 100, batch loss: 8.821900367736816\n",
            "Epoch [266/500], epoch mean loss: 8.823774124013967\n",
            "Epoch [266/500], evaluation loss: 9.074146928458378\n",
            "Epoch [267/500], batch 0, batch loss: 8.823539733886719\n",
            "Epoch [267/500], batch 100, batch loss: 8.816341400146484\n",
            "Epoch [267/500], epoch mean loss: 8.823089262534832\n",
            "Epoch [267/500], evaluation loss: 9.074334900954675\n",
            "Epoch [268/500], batch 0, batch loss: 8.83364200592041\n",
            "Epoch [268/500], batch 100, batch loss: 8.811535835266113\n",
            "Epoch [268/500], epoch mean loss: 8.822209728175196\n",
            "Epoch [268/500], evaluation loss: 9.0742999767435\n",
            "Epoch [269/500], batch 0, batch loss: 8.801261901855469\n",
            "Epoch [269/500], batch 100, batch loss: 8.837552070617676\n",
            "Epoch [269/500], epoch mean loss: 8.821584759087399\n",
            "Epoch [269/500], evaluation loss: 9.074444705042346\n",
            "Epoch [270/500], batch 0, batch loss: 8.80147933959961\n",
            "Epoch [270/500], batch 100, batch loss: 8.818610191345215\n",
            "Epoch [270/500], epoch mean loss: 8.82087621195563\n",
            "Epoch [270/500], evaluation loss: 9.074282185784702\n",
            "Epoch [271/500], batch 0, batch loss: 8.822734832763672\n",
            "Epoch [271/500], batch 100, batch loss: 8.826886177062988\n",
            "Epoch [271/500], epoch mean loss: 8.820209478509836\n",
            "Epoch [271/500], evaluation loss: 9.073840042640423\n",
            "Epoch [272/500], batch 0, batch loss: 8.82392692565918\n",
            "Epoch [272/500], batch 100, batch loss: 8.826030731201172\n",
            "Epoch [272/500], epoch mean loss: 8.819253025383786\n",
            "Epoch [272/500], evaluation loss: 9.07443220862027\n",
            "Epoch [273/500], batch 0, batch loss: 8.784589767456055\n",
            "Epoch [273/500], batch 100, batch loss: 8.839661598205566\n",
            "Epoch [273/500], epoch mean loss: 8.818565360431013\n",
            "Epoch [273/500], evaluation loss: 9.073995294242069\n",
            "Epoch [274/500], batch 0, batch loss: 8.833727836608887\n",
            "Epoch [274/500], batch 100, batch loss: 8.829690933227539\n",
            "Epoch [274/500], epoch mean loss: 8.81808693655606\n",
            "Epoch [274/500], evaluation loss: 9.074666746731463\n",
            "Epoch [275/500], batch 0, batch loss: 8.782816886901855\n",
            "Epoch [275/500], batch 100, batch loss: 8.820985794067383\n",
            "Epoch [275/500], epoch mean loss: 8.817311443131546\n",
            "Epoch [275/500], evaluation loss: 9.074502484551791\n",
            "Epoch [276/500], batch 0, batch loss: 8.80549430847168\n",
            "Epoch [276/500], batch 100, batch loss: 8.82638168334961\n",
            "Epoch [276/500], epoch mean loss: 8.816632015951749\n",
            "Epoch [276/500], evaluation loss: 9.074152979357489\n",
            "Epoch [277/500], batch 0, batch loss: 8.80178451538086\n",
            "Epoch [277/500], batch 100, batch loss: 8.83061695098877\n",
            "Epoch [277/500], epoch mean loss: 8.815910684651342\n",
            "Epoch [277/500], evaluation loss: 9.074298266706796\n",
            "Epoch [278/500], batch 0, batch loss: 8.800507545471191\n",
            "Epoch [278/500], batch 100, batch loss: 8.81906509399414\n",
            "Epoch [278/500], epoch mean loss: 8.815218966582727\n",
            "Epoch [278/500], evaluation loss: 9.0745048194096\n",
            "Epoch [279/500], batch 0, batch loss: 8.816115379333496\n",
            "Epoch [279/500], batch 100, batch loss: 8.811973571777344\n",
            "Epoch [279/500], epoch mean loss: 8.814546132909841\n",
            "Epoch [279/500], evaluation loss: 9.074372686188797\n",
            "Epoch [280/500], batch 0, batch loss: 8.798558235168457\n",
            "Epoch [280/500], batch 100, batch loss: 8.812376976013184\n",
            "Epoch [280/500], epoch mean loss: 8.813910278780707\n",
            "Epoch [280/500], evaluation loss: 9.074554246047448\n",
            "Epoch [281/500], batch 0, batch loss: 8.8306245803833\n",
            "Epoch [281/500], batch 100, batch loss: 8.810338020324707\n",
            "Epoch [281/500], epoch mean loss: 8.812989341801611\n",
            "Epoch [281/500], evaluation loss: 9.07456766325852\n",
            "Epoch [282/500], batch 0, batch loss: 8.835349082946777\n",
            "Epoch [282/500], batch 100, batch loss: 8.8239164352417\n",
            "Epoch [282/500], epoch mean loss: 8.812276782660648\n",
            "Epoch [282/500], evaluation loss: 9.074547274359341\n",
            "Epoch [283/500], batch 0, batch loss: 8.802467346191406\n",
            "Epoch [283/500], batch 100, batch loss: 8.808549880981445\n",
            "Epoch [283/500], epoch mean loss: 8.81154518291868\n",
            "Epoch [283/500], evaluation loss: 9.07506673089389\n",
            "Epoch [284/500], batch 0, batch loss: 8.80815601348877\n",
            "Epoch [284/500], batch 100, batch loss: 8.801284790039062\n",
            "Epoch [284/500], epoch mean loss: 8.810856202553058\n",
            "Epoch [284/500], evaluation loss: 9.07515992789433\n",
            "Epoch [285/500], batch 0, batch loss: 8.835655212402344\n",
            "Epoch [285/500], batch 100, batch loss: 8.825963020324707\n",
            "Epoch [285/500], epoch mean loss: 8.809927841712689\n",
            "Epoch [285/500], evaluation loss: 9.074951730925461\n",
            "Epoch [286/500], batch 0, batch loss: 8.806303024291992\n",
            "Epoch [286/500], batch 100, batch loss: 8.821602821350098\n",
            "Epoch [286/500], epoch mean loss: 8.809235326175031\n",
            "Epoch [286/500], evaluation loss: 9.074781253420074\n",
            "Epoch [287/500], batch 0, batch loss: 8.790529251098633\n",
            "Epoch [287/500], batch 100, batch loss: 8.799269676208496\n",
            "Epoch [287/500], epoch mean loss: 8.808484373421505\n",
            "Epoch [287/500], evaluation loss: 9.075248586720434\n",
            "Epoch [288/500], batch 0, batch loss: 8.789353370666504\n",
            "Epoch [288/500], batch 100, batch loss: 8.83366870880127\n",
            "Epoch [288/500], epoch mean loss: 8.807822416568625\n",
            "Epoch [288/500], evaluation loss: 9.075142465788742\n",
            "Epoch [289/500], batch 0, batch loss: 8.768280029296875\n",
            "Epoch [289/500], batch 100, batch loss: 8.805405616760254\n",
            "Epoch [289/500], epoch mean loss: 8.807177790280047\n",
            "Epoch [289/500], evaluation loss: 9.075055089490167\n",
            "Epoch [290/500], batch 0, batch loss: 8.76994514465332\n",
            "Epoch [290/500], batch 100, batch loss: 8.822945594787598\n",
            "Epoch [290/500], epoch mean loss: 8.806331823612082\n",
            "Epoch [290/500], evaluation loss: 9.075066632237927\n",
            "Epoch [291/500], batch 0, batch loss: 8.80344009399414\n",
            "Epoch [291/500], batch 100, batch loss: 8.808195114135742\n",
            "Epoch [291/500], epoch mean loss: 8.805618064156894\n",
            "Epoch [291/500], evaluation loss: 9.07497553989805\n",
            "Epoch [292/500], batch 0, batch loss: 8.799247741699219\n",
            "Epoch [292/500], batch 100, batch loss: 8.794997215270996\n",
            "Epoch [292/500], epoch mean loss: 8.805088520050049\n",
            "Epoch [292/500], evaluation loss: 9.075297618734426\n",
            "Epoch [293/500], batch 0, batch loss: 8.790895462036133\n",
            "Epoch [293/500], batch 100, batch loss: 8.805419921875\n",
            "Epoch [293/500], epoch mean loss: 8.804242216307541\n",
            "Epoch [293/500], evaluation loss: 9.07518120469718\n",
            "Epoch [294/500], batch 0, batch loss: 8.816143989562988\n",
            "Epoch [294/500], batch 100, batch loss: 8.79578685760498\n",
            "Epoch [294/500], epoch mean loss: 8.803621670295453\n",
            "Epoch [294/500], evaluation loss: 9.075364244395288\n",
            "Epoch [295/500], batch 0, batch loss: 8.790654182434082\n",
            "Epoch [295/500], batch 100, batch loss: 8.79655933380127\n",
            "Epoch [295/500], epoch mean loss: 8.802770959919897\n",
            "Epoch [295/500], evaluation loss: 9.075938849613584\n",
            "Epoch [296/500], batch 0, batch loss: 8.802526473999023\n",
            "Epoch [296/500], batch 100, batch loss: 8.781728744506836\n",
            "Epoch [296/500], epoch mean loss: 8.801999264749988\n",
            "Epoch [296/500], evaluation loss: 9.075757947461359\n",
            "Epoch [297/500], batch 0, batch loss: 8.810264587402344\n",
            "Epoch [297/500], batch 100, batch loss: 8.796760559082031\n",
            "Epoch [297/500], epoch mean loss: 8.801161955142843\n",
            "Epoch [297/500], evaluation loss: 9.075933818159433\n",
            "Epoch [298/500], batch 0, batch loss: 8.78685188293457\n",
            "Epoch [298/500], batch 100, batch loss: 8.812984466552734\n",
            "Epoch [298/500], epoch mean loss: 8.800520543394418\n",
            "Epoch [298/500], evaluation loss: 9.075627622933224\n",
            "Epoch [299/500], batch 0, batch loss: 8.8092622756958\n",
            "Epoch [299/500], batch 100, batch loss: 8.791473388671875\n",
            "Epoch [299/500], epoch mean loss: 8.799827452363639\n",
            "Epoch [299/500], evaluation loss: 9.075861799305883\n",
            "Epoch [300/500], batch 0, batch loss: 8.80408000946045\n",
            "Epoch [300/500], batch 100, batch loss: 8.787836074829102\n",
            "Epoch [300/500], epoch mean loss: 8.798997763929696\n",
            "Epoch [300/500], evaluation loss: 9.075947860191608\n",
            "Epoch [301/500], batch 0, batch loss: 8.780984878540039\n",
            "Epoch [301/500], batch 100, batch loss: 8.79177474975586\n",
            "Epoch [301/500], epoch mean loss: 8.798197614735571\n",
            "Epoch [301/500], evaluation loss: 9.076380170624832\n",
            "Epoch [302/500], batch 0, batch loss: 8.786514282226562\n",
            "Epoch [302/500], batch 100, batch loss: 8.81534481048584\n",
            "Epoch [302/500], epoch mean loss: 8.797664403915405\n",
            "Epoch [302/500], evaluation loss: 9.076182233876196\n",
            "Epoch [303/500], batch 0, batch loss: 8.791597366333008\n",
            "Epoch [303/500], batch 100, batch loss: 8.803336143493652\n",
            "Epoch [303/500], epoch mean loss: 8.796828853672949\n",
            "Epoch [303/500], evaluation loss: 9.076709155378671\n",
            "Epoch [304/500], batch 0, batch loss: 8.82419204711914\n",
            "Epoch [304/500], batch 100, batch loss: 8.793710708618164\n",
            "Epoch [304/500], epoch mean loss: 8.796128092140988\n",
            "Epoch [304/500], evaluation loss: 9.076306902129074\n",
            "Epoch [305/500], batch 0, batch loss: 8.77318000793457\n",
            "Epoch [305/500], batch 100, batch loss: 8.755220413208008\n",
            "Epoch [305/500], epoch mean loss: 8.79530798155686\n",
            "Epoch [305/500], evaluation loss: 9.076607704162598\n",
            "Epoch [306/500], batch 0, batch loss: 8.806511878967285\n",
            "Epoch [306/500], batch 100, batch loss: 8.806026458740234\n",
            "Epoch [306/500], epoch mean loss: 8.794638411752109\n",
            "Epoch [306/500], evaluation loss: 9.076668476236277\n",
            "Epoch [307/500], batch 0, batch loss: 8.769222259521484\n",
            "Epoch [307/500], batch 100, batch loss: 8.749870300292969\n",
            "Epoch [307/500], epoch mean loss: 8.793942772108933\n",
            "Epoch [307/500], evaluation loss: 9.076318609303442\n",
            "Epoch [308/500], batch 0, batch loss: 8.795631408691406\n",
            "Epoch [308/500], batch 100, batch loss: 8.805718421936035\n",
            "Epoch [308/500], epoch mean loss: 8.793418053922982\n",
            "Epoch [308/500], evaluation loss: 9.076660616644498\n",
            "Epoch [309/500], batch 0, batch loss: 8.802600860595703\n",
            "Epoch [309/500], batch 100, batch loss: 8.826874732971191\n",
            "Epoch [309/500], epoch mean loss: 8.792656396997385\n",
            "Epoch [309/500], evaluation loss: 9.076726058433795\n",
            "Epoch [310/500], batch 0, batch loss: 8.766318321228027\n",
            "Epoch [310/500], batch 100, batch loss: 8.821998596191406\n",
            "Epoch [310/500], epoch mean loss: 8.79197017077742\n",
            "Epoch [310/500], evaluation loss: 9.076711292924552\n",
            "Epoch [311/500], batch 0, batch loss: 8.781716346740723\n",
            "Epoch [311/500], batch 100, batch loss: 8.781577110290527\n",
            "Epoch [311/500], epoch mean loss: 8.791335023682693\n",
            "Epoch [311/500], evaluation loss: 9.07685296288852\n",
            "Epoch [312/500], batch 0, batch loss: 8.784937858581543\n",
            "Epoch [312/500], batch 100, batch loss: 8.785754203796387\n",
            "Epoch [312/500], epoch mean loss: 8.790948382739362\n",
            "Epoch [312/500], evaluation loss: 9.076393916689117\n",
            "Epoch [313/500], batch 0, batch loss: 8.770393371582031\n",
            "Epoch [313/500], batch 100, batch loss: 8.827838897705078\n",
            "Epoch [313/500], epoch mean loss: 8.79015827178955\n",
            "Epoch [313/500], evaluation loss: 9.076946949136667\n",
            "Epoch [314/500], batch 0, batch loss: 8.79366683959961\n",
            "Epoch [314/500], batch 100, batch loss: 8.770061492919922\n",
            "Epoch [314/500], epoch mean loss: 8.789370627238833\n",
            "Epoch [314/500], evaluation loss: 9.076492638423526\n",
            "Epoch [315/500], batch 0, batch loss: 8.814912796020508\n",
            "Epoch [315/500], batch 100, batch loss: 8.793140411376953\n",
            "Epoch [315/500], epoch mean loss: 8.78865856959902\n",
            "Epoch [315/500], evaluation loss: 9.076780680952401\n",
            "Epoch [316/500], batch 0, batch loss: 8.81998062133789\n",
            "Epoch [316/500], batch 100, batch loss: 8.799581527709961\n",
            "Epoch [316/500], epoch mean loss: 8.788048587996384\n",
            "Epoch [316/500], evaluation loss: 9.077165077472555\n",
            "Epoch [317/500], batch 0, batch loss: 8.801473617553711\n",
            "Epoch [317/500], batch 100, batch loss: 8.80247688293457\n",
            "Epoch [317/500], epoch mean loss: 8.787399908591961\n",
            "Epoch [317/500], evaluation loss: 9.077238115771063\n",
            "Epoch [318/500], batch 0, batch loss: 8.78984260559082\n",
            "Epoch [318/500], batch 100, batch loss: 8.800447463989258\n",
            "Epoch [318/500], epoch mean loss: 8.786440282032407\n",
            "Epoch [318/500], evaluation loss: 9.077412934138858\n",
            "Epoch [319/500], batch 0, batch loss: 8.778053283691406\n",
            "Epoch [319/500], batch 100, batch loss: 8.797378540039062\n",
            "Epoch [319/500], epoch mean loss: 8.785915761158384\n",
            "Epoch [319/500], evaluation loss: 9.077338317344928\n",
            "Epoch [320/500], batch 0, batch loss: 8.78494644165039\n",
            "Epoch [320/500], batch 100, batch loss: 8.791711807250977\n",
            "Epoch [320/500], epoch mean loss: 8.785213774648206\n",
            "Epoch [320/500], evaluation loss: 9.077466471441861\n",
            "Epoch [321/500], batch 0, batch loss: 8.786846160888672\n",
            "Epoch [321/500], batch 100, batch loss: 8.74966812133789\n",
            "Epoch [321/500], epoch mean loss: 8.784456433921024\n",
            "Epoch [321/500], evaluation loss: 9.077488603263065\n",
            "Epoch [322/500], batch 0, batch loss: 8.779980659484863\n",
            "Epoch [322/500], batch 100, batch loss: 8.77727222442627\n",
            "Epoch [322/500], epoch mean loss: 8.783898041166108\n",
            "Epoch [322/500], evaluation loss: 9.07753220919905\n",
            "Epoch [323/500], batch 0, batch loss: 8.792692184448242\n",
            "Epoch [323/500], batch 100, batch loss: 8.757540702819824\n",
            "Epoch [323/500], epoch mean loss: 8.783055749432794\n",
            "Epoch [323/500], evaluation loss: 9.077805584874646\n",
            "Epoch [324/500], batch 0, batch loss: 8.791472434997559\n",
            "Epoch [324/500], batch 100, batch loss: 8.817768096923828\n",
            "Epoch [324/500], epoch mean loss: 8.782491223565463\n",
            "Epoch [324/500], evaluation loss: 9.077479132290545\n",
            "Epoch [325/500], batch 0, batch loss: 8.780965805053711\n",
            "Epoch [325/500], batch 100, batch loss: 8.775652885437012\n",
            "Epoch [325/500], epoch mean loss: 8.781783917854572\n",
            "Epoch [325/500], evaluation loss: 9.077971787288272\n",
            "Epoch [326/500], batch 0, batch loss: 8.794646263122559\n",
            "Epoch [326/500], batch 100, batch loss: 8.76992416381836\n",
            "Epoch [326/500], epoch mean loss: 8.781274466679013\n",
            "Epoch [326/500], evaluation loss: 9.078107241926523\n",
            "Epoch [327/500], batch 0, batch loss: 8.801487922668457\n",
            "Epoch [327/500], batch 100, batch loss: 8.7603178024292\n",
            "Epoch [327/500], epoch mean loss: 8.780354795784787\n",
            "Epoch [327/500], evaluation loss: 9.078047061788626\n",
            "Epoch [328/500], batch 0, batch loss: 8.780986785888672\n",
            "Epoch [328/500], batch 100, batch loss: 8.783136367797852\n",
            "Epoch [328/500], epoch mean loss: 8.779779713729333\n",
            "Epoch [328/500], evaluation loss: 9.077727548007307\n",
            "Epoch [329/500], batch 0, batch loss: 8.789743423461914\n",
            "Epoch [329/500], batch 100, batch loss: 8.788134574890137\n",
            "Epoch [329/500], epoch mean loss: 8.779045039209826\n",
            "Epoch [329/500], evaluation loss: 9.078110497573327\n",
            "Epoch [330/500], batch 0, batch loss: 8.76688003540039\n",
            "Epoch [330/500], batch 100, batch loss: 8.745210647583008\n",
            "Epoch [330/500], epoch mean loss: 8.778482527568423\n",
            "Epoch [330/500], evaluation loss: 9.07794084220097\n",
            "Epoch [331/500], batch 0, batch loss: 8.782369613647461\n",
            "Epoch [331/500], batch 100, batch loss: 8.760356903076172\n",
            "Epoch [331/500], epoch mean loss: 8.777810787332468\n",
            "Epoch [331/500], evaluation loss: 9.07823187729408\n",
            "Epoch [332/500], batch 0, batch loss: 8.764374732971191\n",
            "Epoch [332/500], batch 100, batch loss: 8.78088665008545\n",
            "Epoch [332/500], epoch mean loss: 8.777261503811541\n",
            "Epoch [332/500], evaluation loss: 9.078143711747794\n",
            "Epoch [333/500], batch 0, batch loss: 8.778371810913086\n",
            "Epoch [333/500], batch 100, batch loss: 8.761429786682129\n",
            "Epoch [333/500], epoch mean loss: 8.776557437304792\n",
            "Epoch [333/500], evaluation loss: 9.078175840706662\n",
            "Epoch [334/500], batch 0, batch loss: 8.755592346191406\n",
            "Epoch [334/500], batch 100, batch loss: 8.776107788085938\n",
            "Epoch [334/500], epoch mean loss: 8.77575842265425\n",
            "Epoch [334/500], evaluation loss: 9.077983593118601\n",
            "Epoch [335/500], batch 0, batch loss: 8.761443138122559\n",
            "Epoch [335/500], batch 100, batch loss: 8.793676376342773\n",
            "Epoch [335/500], epoch mean loss: 8.775114437629437\n",
            "Epoch [335/500], evaluation loss: 9.078426361083984\n",
            "Epoch [336/500], batch 0, batch loss: 8.775069236755371\n",
            "Epoch [336/500], batch 100, batch loss: 8.780961036682129\n",
            "Epoch [336/500], epoch mean loss: 8.774447112247861\n",
            "Epoch [336/500], evaluation loss: 9.078529061942264\n",
            "Epoch [337/500], batch 0, batch loss: 8.782876014709473\n",
            "Epoch [337/500], batch 100, batch loss: 8.7839994430542\n",
            "Epoch [337/500], epoch mean loss: 8.773694728982859\n",
            "Epoch [337/500], evaluation loss: 9.078768236883755\n",
            "Epoch [338/500], batch 0, batch loss: 8.763404846191406\n",
            "Epoch [338/500], batch 100, batch loss: 8.76993179321289\n",
            "Epoch [338/500], epoch mean loss: 8.772977187715728\n",
            "Epoch [338/500], evaluation loss: 9.078594733928812\n",
            "Epoch [339/500], batch 0, batch loss: 8.782303810119629\n",
            "Epoch [339/500], batch 100, batch loss: 8.767345428466797\n",
            "Epoch [339/500], epoch mean loss: 8.772442497056106\n",
            "Epoch [339/500], evaluation loss: 9.078859822503452\n",
            "Epoch [340/500], batch 0, batch loss: 8.74516487121582\n",
            "Epoch [340/500], batch 100, batch loss: 8.804356575012207\n",
            "Epoch [340/500], epoch mean loss: 8.771719496825646\n",
            "Epoch [340/500], evaluation loss: 9.078417186079355\n",
            "Epoch [341/500], batch 0, batch loss: 8.742475509643555\n",
            "Epoch [341/500], batch 100, batch loss: 8.771684646606445\n",
            "Epoch [341/500], epoch mean loss: 8.771187009482547\n",
            "Epoch [341/500], evaluation loss: 9.07840712317105\n",
            "Epoch [342/500], batch 0, batch loss: 8.746782302856445\n",
            "Epoch [342/500], batch 100, batch loss: 8.776712417602539\n",
            "Epoch [342/500], epoch mean loss: 8.770490745018268\n",
            "Epoch [342/500], evaluation loss: 9.078609466552734\n",
            "Epoch [343/500], batch 0, batch loss: 8.792654991149902\n",
            "Epoch [343/500], batch 100, batch loss: 8.754622459411621\n",
            "Epoch [343/500], epoch mean loss: 8.769864402968308\n",
            "Epoch [343/500], evaluation loss: 9.07865228324101\n",
            "Epoch [344/500], batch 0, batch loss: 8.817745208740234\n",
            "Epoch [344/500], batch 100, batch loss: 8.757551193237305\n",
            "Epoch [344/500], epoch mean loss: 8.769325239904996\n",
            "Epoch [344/500], evaluation loss: 9.079063875921841\n",
            "Epoch [345/500], batch 0, batch loss: 8.777474403381348\n",
            "Epoch [345/500], batch 100, batch loss: 8.79172134399414\n",
            "Epoch [345/500], epoch mean loss: 8.768603809948626\n",
            "Epoch [345/500], evaluation loss: 9.07942456212537\n",
            "Epoch [346/500], batch 0, batch loss: 8.77022647857666\n",
            "Epoch [346/500], batch 100, batch loss: 8.766960144042969\n",
            "Epoch [346/500], epoch mean loss: 8.768050341770566\n",
            "Epoch [346/500], evaluation loss: 9.078939569407495\n",
            "Epoch [347/500], batch 0, batch loss: 8.740873336791992\n",
            "Epoch [347/500], batch 100, batch loss: 8.779340744018555\n",
            "Epoch [347/500], epoch mean loss: 8.767490666488122\n",
            "Epoch [347/500], evaluation loss: 9.079485663052264\n",
            "Epoch [348/500], batch 0, batch loss: 8.800318717956543\n",
            "Epoch [348/500], batch 100, batch loss: 8.757545471191406\n",
            "Epoch [348/500], epoch mean loss: 8.766900037897043\n",
            "Epoch [348/500], evaluation loss: 9.079318934473498\n",
            "Epoch [349/500], batch 0, batch loss: 8.726190567016602\n",
            "Epoch [349/500], batch 100, batch loss: 8.756526947021484\n",
            "Epoch [349/500], epoch mean loss: 8.766284580888419\n",
            "Epoch [349/500], evaluation loss: 9.079516180630389\n",
            "Epoch [350/500], batch 0, batch loss: 8.769075393676758\n",
            "Epoch [350/500], batch 100, batch loss: 8.74845027923584\n",
            "Epoch [350/500], epoch mean loss: 8.765729164255076\n",
            "Epoch [350/500], evaluation loss: 9.079227513280408\n",
            "Epoch [351/500], batch 0, batch loss: 8.75384521484375\n",
            "Epoch [351/500], batch 100, batch loss: 8.776093482971191\n",
            "Epoch [351/500], epoch mean loss: 8.765135510214444\n",
            "Epoch [351/500], evaluation loss: 9.079637856319033\n",
            "Epoch [352/500], batch 0, batch loss: 8.761767387390137\n",
            "Epoch [352/500], batch 100, batch loss: 8.738846778869629\n",
            "Epoch [352/500], epoch mean loss: 8.764593625890798\n",
            "Epoch [352/500], evaluation loss: 9.079740195438779\n",
            "Epoch [353/500], batch 0, batch loss: 8.775106430053711\n",
            "Epoch [353/500], batch 100, batch loss: 8.73995304107666\n",
            "Epoch [353/500], epoch mean loss: 8.764100855794446\n",
            "Epoch [353/500], evaluation loss: 9.07994559715534\n",
            "Epoch [354/500], batch 0, batch loss: 8.73214340209961\n",
            "Epoch [354/500], batch 100, batch loss: 8.77602481842041\n",
            "Epoch [354/500], epoch mean loss: 8.763501940102413\n",
            "Epoch [354/500], evaluation loss: 9.080053954288877\n",
            "Epoch [355/500], batch 0, batch loss: 8.77412223815918\n",
            "Epoch [355/500], batch 100, batch loss: 8.739314079284668\n",
            "Epoch [355/500], epoch mean loss: 8.762870385729034\n",
            "Epoch [355/500], evaluation loss: 9.079897979210163\n",
            "Epoch [356/500], batch 0, batch loss: 8.76035213470459\n",
            "Epoch [356/500], batch 100, batch loss: 8.748543739318848\n",
            "Epoch [356/500], epoch mean loss: 8.762252314337369\n",
            "Epoch [356/500], evaluation loss: 9.079513648460651\n",
            "Epoch [357/500], batch 0, batch loss: 8.768270492553711\n",
            "Epoch [357/500], batch 100, batch loss: 8.746728897094727\n",
            "Epoch [357/500], epoch mean loss: 8.761523189215824\n",
            "Epoch [357/500], evaluation loss: 9.080321706574539\n",
            "Epoch [358/500], batch 0, batch loss: 8.747772216796875\n",
            "Epoch [358/500], batch 100, batch loss: 8.770484924316406\n",
            "Epoch [358/500], epoch mean loss: 8.761102585956968\n",
            "Epoch [358/500], evaluation loss: 9.07979570586106\n",
            "Epoch [359/500], batch 0, batch loss: 8.758458137512207\n",
            "Epoch [359/500], batch 100, batch loss: 8.771761894226074\n",
            "Epoch [359/500], epoch mean loss: 8.760359427024579\n",
            "Epoch [359/500], evaluation loss: 9.079974733549973\n",
            "Epoch [360/500], batch 0, batch loss: 8.774138450622559\n",
            "Epoch [360/500], batch 100, batch loss: 8.730195999145508\n",
            "Epoch [360/500], epoch mean loss: 8.759799891504748\n",
            "Epoch [360/500], evaluation loss: 9.080112358619427\n",
            "Epoch [361/500], batch 0, batch loss: 8.763595581054688\n",
            "Epoch [361/500], batch 100, batch loss: 8.769157409667969\n",
            "Epoch [361/500], epoch mean loss: 8.75915995959578\n",
            "Epoch [361/500], evaluation loss: 9.08032173945986\n",
            "Epoch [362/500], batch 0, batch loss: 8.752728462219238\n",
            "Epoch [362/500], batch 100, batch loss: 8.729840278625488\n",
            "Epoch [362/500], epoch mean loss: 8.758604041461286\n",
            "Epoch [362/500], evaluation loss: 9.080068259403623\n",
            "Epoch [363/500], batch 0, batch loss: 8.762655258178711\n",
            "Epoch [363/500], batch 100, batch loss: 8.759413719177246\n",
            "Epoch [363/500], epoch mean loss: 8.758055736278665\n",
            "Epoch [363/500], evaluation loss: 9.080418060565817\n",
            "Epoch [364/500], batch 0, batch loss: 8.747764587402344\n",
            "Epoch [364/500], batch 100, batch loss: 8.74813461303711\n",
            "Epoch [364/500], epoch mean loss: 8.757439358481045\n",
            "Epoch [364/500], evaluation loss: 9.080635892933813\n",
            "Epoch [365/500], batch 0, batch loss: 8.75594711303711\n",
            "Epoch [365/500], batch 100, batch loss: 8.765332221984863\n",
            "Epoch [365/500], epoch mean loss: 8.75689513929959\n",
            "Epoch [365/500], evaluation loss: 9.08056482775458\n",
            "Epoch [366/500], batch 0, batch loss: 8.776995658874512\n",
            "Epoch [366/500], batch 100, batch loss: 8.76037883758545\n",
            "Epoch [366/500], epoch mean loss: 8.756339147173126\n",
            "Epoch [366/500], evaluation loss: 9.080451373396249\n",
            "Epoch [367/500], batch 0, batch loss: 8.745407104492188\n",
            "Epoch [367/500], batch 100, batch loss: 8.742812156677246\n",
            "Epoch [367/500], epoch mean loss: 8.755512163556855\n",
            "Epoch [367/500], evaluation loss: 9.081055410977068\n",
            "Epoch [368/500], batch 0, batch loss: 8.796436309814453\n",
            "Epoch [368/500], batch 100, batch loss: 8.73753547668457\n",
            "Epoch [368/500], epoch mean loss: 8.754683691879798\n",
            "Epoch [368/500], evaluation loss: 9.080900488228634\n",
            "Epoch [369/500], batch 0, batch loss: 8.75652027130127\n",
            "Epoch [369/500], batch 100, batch loss: 8.76346492767334\n",
            "Epoch [369/500], epoch mean loss: 8.754190888898126\n",
            "Epoch [369/500], evaluation loss: 9.081260516725738\n",
            "Epoch [370/500], batch 0, batch loss: 8.767827987670898\n",
            "Epoch [370/500], batch 100, batch loss: 8.740937232971191\n",
            "Epoch [370/500], epoch mean loss: 8.753535706421424\n",
            "Epoch [370/500], evaluation loss: 9.081020815619107\n",
            "Epoch [371/500], batch 0, batch loss: 8.781218528747559\n",
            "Epoch [371/500], batch 100, batch loss: 8.734010696411133\n",
            "Epoch [371/500], epoch mean loss: 8.75295851148408\n",
            "Epoch [371/500], evaluation loss: 9.081428166093497\n",
            "Epoch [372/500], batch 0, batch loss: 8.770584106445312\n",
            "Epoch [372/500], batch 100, batch loss: 8.764036178588867\n",
            "Epoch [372/500], epoch mean loss: 8.752291457406406\n",
            "Epoch [372/500], evaluation loss: 9.081830024719238\n",
            "Epoch [373/500], batch 0, batch loss: 8.763957977294922\n",
            "Epoch [373/500], batch 100, batch loss: 8.752665519714355\n",
            "Epoch [373/500], epoch mean loss: 8.751450382429978\n",
            "Epoch [373/500], evaluation loss: 9.08124903974862\n",
            "Epoch [374/500], batch 0, batch loss: 8.782522201538086\n",
            "Epoch [374/500], batch 100, batch loss: 8.760428428649902\n",
            "Epoch [374/500], epoch mean loss: 8.75100619217445\n",
            "Epoch [374/500], evaluation loss: 9.081271237340466\n",
            "Epoch [375/500], batch 0, batch loss: 8.753868103027344\n",
            "Epoch [375/500], batch 100, batch loss: 8.726937294006348\n",
            "Epoch [375/500], epoch mean loss: 8.75038428142153\n",
            "Epoch [375/500], evaluation loss: 9.081516200098498\n",
            "Epoch [376/500], batch 0, batch loss: 8.743577003479004\n",
            "Epoch [376/500], batch 100, batch loss: 8.729208946228027\n",
            "Epoch [376/500], epoch mean loss: 8.749781123523054\n",
            "Epoch [376/500], evaluation loss: 9.082024080999966\n",
            "Epoch [377/500], batch 0, batch loss: 8.741646766662598\n",
            "Epoch [377/500], batch 100, batch loss: 8.728219985961914\n",
            "Epoch [377/500], epoch mean loss: 8.749128317010813\n",
            "Epoch [377/500], evaluation loss: 9.081883562022242\n",
            "Epoch [378/500], batch 0, batch loss: 8.747771263122559\n",
            "Epoch [378/500], batch 100, batch loss: 8.759471893310547\n",
            "Epoch [378/500], epoch mean loss: 8.7483805952401\n",
            "Epoch [378/500], evaluation loss: 9.082072586848819\n",
            "Epoch [379/500], batch 0, batch loss: 8.75363540649414\n",
            "Epoch [379/500], batch 100, batch loss: 8.775116920471191\n",
            "Epoch [379/500], epoch mean loss: 8.747774346121426\n",
            "Epoch [379/500], evaluation loss: 9.082023028669687\n",
            "Epoch [380/500], batch 0, batch loss: 8.753558158874512\n",
            "Epoch [380/500], batch 100, batch loss: 8.750722885131836\n",
            "Epoch [380/500], epoch mean loss: 8.747454100641711\n",
            "Epoch [380/500], evaluation loss: 9.08253416521796\n",
            "Epoch [381/500], batch 0, batch loss: 8.766023635864258\n",
            "Epoch [381/500], batch 100, batch loss: 8.753484725952148\n",
            "Epoch [381/500], epoch mean loss: 8.746812212056128\n",
            "Epoch [381/500], evaluation loss: 9.082514203827957\n",
            "Epoch [382/500], batch 0, batch loss: 8.764559745788574\n",
            "Epoch [382/500], batch 100, batch loss: 8.746795654296875\n",
            "Epoch [382/500], epoch mean loss: 8.746333311344015\n",
            "Epoch [382/500], evaluation loss: 9.082407096336627\n",
            "Epoch [383/500], batch 0, batch loss: 8.745759010314941\n",
            "Epoch [383/500], batch 100, batch loss: 8.742892265319824\n",
            "Epoch [383/500], epoch mean loss: 8.745492614548782\n",
            "Epoch [383/500], evaluation loss: 9.082506607318747\n",
            "Epoch [384/500], batch 0, batch loss: 8.762216567993164\n",
            "Epoch [384/500], batch 100, batch loss: 8.716526985168457\n",
            "Epoch [384/500], epoch mean loss: 8.744868475815345\n",
            "Epoch [384/500], evaluation loss: 9.08295832009151\n",
            "Epoch [385/500], batch 0, batch loss: 8.747766494750977\n",
            "Epoch [385/500], batch 100, batch loss: 8.759011268615723\n",
            "Epoch [385/500], epoch mean loss: 8.744340304670663\n",
            "Epoch [385/500], evaluation loss: 9.083178783285208\n",
            "Epoch [386/500], batch 0, batch loss: 8.729878425598145\n",
            "Epoch [386/500], batch 100, batch loss: 8.759503364562988\n",
            "Epoch [386/500], epoch mean loss: 8.743703579080515\n",
            "Epoch [386/500], evaluation loss: 9.082240795267039\n",
            "Epoch [387/500], batch 0, batch loss: 8.737144470214844\n",
            "Epoch [387/500], batch 100, batch loss: 8.783899307250977\n",
            "Epoch [387/500], epoch mean loss: 8.743294962521258\n",
            "Epoch [387/500], evaluation loss: 9.082612892677044\n",
            "Epoch [388/500], batch 0, batch loss: 8.719388961791992\n",
            "Epoch [388/500], batch 100, batch loss: 8.740214347839355\n",
            "Epoch [388/500], epoch mean loss: 8.742622178176354\n",
            "Epoch [388/500], evaluation loss: 9.082977590889767\n",
            "Epoch [389/500], batch 0, batch loss: 8.738980293273926\n",
            "Epoch [389/500], batch 100, batch loss: 8.753630638122559\n",
            "Epoch [389/500], epoch mean loss: 8.742097583310358\n",
            "Epoch [389/500], evaluation loss: 9.082822536600046\n",
            "Epoch [390/500], batch 0, batch loss: 8.756909370422363\n",
            "Epoch [390/500], batch 100, batch loss: 8.716446876525879\n",
            "Epoch [390/500], epoch mean loss: 8.741651732346106\n",
            "Epoch [390/500], evaluation loss: 9.082618055672482\n",
            "Epoch [391/500], batch 0, batch loss: 8.744779586791992\n",
            "Epoch [391/500], batch 100, batch loss: 8.753539085388184\n",
            "Epoch [391/500], epoch mean loss: 8.741082125696643\n",
            "Epoch [391/500], evaluation loss: 9.08300149851832\n",
            "Epoch [392/500], batch 0, batch loss: 8.745433807373047\n",
            "Epoch [392/500], batch 100, batch loss: 8.725476264953613\n",
            "Epoch [392/500], epoch mean loss: 8.740551529259518\n",
            "Epoch [392/500], evaluation loss: 9.08342095079093\n",
            "Epoch [393/500], batch 0, batch loss: 8.749726295471191\n",
            "Epoch [393/500], batch 100, batch loss: 8.735204696655273\n",
            "Epoch [393/500], epoch mean loss: 8.739955655459699\n",
            "Epoch [393/500], evaluation loss: 9.083065164500269\n",
            "Epoch [394/500], batch 0, batch loss: 8.720361709594727\n",
            "Epoch [394/500], batch 100, batch loss: 8.720418930053711\n",
            "Epoch [394/500], epoch mean loss: 8.739176240460626\n",
            "Epoch [394/500], evaluation loss: 9.083453441488333\n",
            "Epoch [395/500], batch 0, batch loss: 8.743996620178223\n",
            "Epoch [395/500], batch 100, batch loss: 8.733142852783203\n",
            "Epoch [395/500], epoch mean loss: 8.738682418033994\n",
            "Epoch [395/500], evaluation loss: 9.083263134134226\n",
            "Epoch [396/500], batch 0, batch loss: 8.750580787658691\n",
            "Epoch [396/500], batch 100, batch loss: 8.734048843383789\n",
            "Epoch [396/500], epoch mean loss: 8.737959532902158\n",
            "Epoch [396/500], evaluation loss: 9.083241232510272\n",
            "Epoch [397/500], batch 0, batch loss: 8.752041816711426\n",
            "Epoch [397/500], batch 100, batch loss: 8.714282035827637\n",
            "Epoch [397/500], epoch mean loss: 8.73739583738919\n",
            "Epoch [397/500], evaluation loss: 9.083316441239981\n",
            "Epoch [398/500], batch 0, batch loss: 8.74462604522705\n",
            "Epoch [398/500], batch 100, batch loss: 8.729216575622559\n",
            "Epoch [398/500], epoch mean loss: 8.736802750620349\n",
            "Epoch [398/500], evaluation loss: 9.083321735776703\n",
            "Epoch [399/500], batch 0, batch loss: 8.759492874145508\n",
            "Epoch [399/500], batch 100, batch loss: 8.763405799865723\n",
            "Epoch [399/500], epoch mean loss: 8.736198844580814\n",
            "Epoch [399/500], evaluation loss: 9.084032913734173\n",
            "Epoch [400/500], batch 0, batch loss: 8.730890274047852\n",
            "Epoch [400/500], batch 100, batch loss: 8.725765228271484\n",
            "Epoch [400/500], epoch mean loss: 8.735627552558636\n",
            "Epoch [400/500], evaluation loss: 9.083941854279617\n",
            "Epoch [401/500], batch 0, batch loss: 8.71945858001709\n",
            "Epoch [401/500], batch 100, batch loss: 8.737892150878906\n",
            "Epoch [401/500], epoch mean loss: 8.73503797629784\n",
            "Epoch [401/500], evaluation loss: 9.083727902379529\n",
            "Epoch [402/500], batch 0, batch loss: 8.718816757202148\n",
            "Epoch [402/500], batch 100, batch loss: 8.741496086120605\n",
            "Epoch [402/500], epoch mean loss: 8.734601415436844\n",
            "Epoch [402/500], evaluation loss: 9.084029493660763\n",
            "Epoch [403/500], batch 0, batch loss: 8.742897033691406\n",
            "Epoch [403/500], batch 100, batch loss: 8.728864669799805\n",
            "Epoch [403/500], epoch mean loss: 8.733892144828006\n",
            "Epoch [403/500], evaluation loss: 9.083762070228314\n",
            "Epoch [404/500], batch 0, batch loss: 8.706435203552246\n",
            "Epoch [404/500], batch 100, batch loss: 8.745806694030762\n",
            "Epoch [404/500], epoch mean loss: 8.733469872639096\n",
            "Epoch [404/500], evaluation loss: 9.08400348137165\n",
            "Epoch [405/500], batch 0, batch loss: 8.738897323608398\n",
            "Epoch [405/500], batch 100, batch loss: 8.713492393493652\n",
            "Epoch [405/500], epoch mean loss: 8.732915524778695\n",
            "Epoch [405/500], evaluation loss: 9.084036202266299\n",
            "Epoch [406/500], batch 0, batch loss: 8.714461326599121\n",
            "Epoch [406/500], batch 100, batch loss: 8.713850021362305\n",
            "Epoch [406/500], epoch mean loss: 8.7322998046875\n",
            "Epoch [406/500], evaluation loss: 9.083956323820969\n",
            "Epoch [407/500], batch 0, batch loss: 8.768269538879395\n",
            "Epoch [407/500], batch 100, batch loss: 8.749736785888672\n",
            "Epoch [407/500], epoch mean loss: 8.731877992893088\n",
            "Epoch [407/500], evaluation loss: 9.083622899548761\n",
            "Epoch [408/500], batch 0, batch loss: 8.73504638671875\n",
            "Epoch [408/500], batch 100, batch loss: 8.734432220458984\n",
            "Epoch [408/500], epoch mean loss: 8.731491203965811\n",
            "Epoch [408/500], evaluation loss: 9.083526677098767\n",
            "Epoch [409/500], batch 0, batch loss: 8.74040412902832\n",
            "Epoch [409/500], batch 100, batch loss: 8.746583938598633\n",
            "Epoch [409/500], epoch mean loss: 8.730803374586435\n",
            "Epoch [409/500], evaluation loss: 9.084064911151755\n",
            "Epoch [410/500], batch 0, batch loss: 8.740921974182129\n",
            "Epoch [410/500], batch 100, batch loss: 8.744766235351562\n",
            "Epoch [410/500], epoch mean loss: 8.730041331258313\n",
            "Epoch [410/500], evaluation loss: 9.083887889467437\n",
            "Epoch [411/500], batch 0, batch loss: 8.736652374267578\n",
            "Epoch [411/500], batch 100, batch loss: 8.743842124938965\n",
            "Epoch [411/500], epoch mean loss: 8.729407762659006\n",
            "Epoch [411/500], evaluation loss: 9.084495380006988\n",
            "Epoch [412/500], batch 0, batch loss: 8.72425365447998\n",
            "Epoch [412/500], batch 100, batch loss: 8.724043846130371\n",
            "Epoch [412/500], epoch mean loss: 8.728815637785813\n",
            "Epoch [412/500], evaluation loss: 9.084429214740622\n",
            "Epoch [413/500], batch 0, batch loss: 8.729303359985352\n",
            "Epoch [413/500], batch 100, batch loss: 8.755577087402344\n",
            "Epoch [413/500], epoch mean loss: 8.728164977040784\n",
            "Epoch [413/500], evaluation loss: 9.084417836419467\n",
            "Epoch [414/500], batch 0, batch loss: 8.735881805419922\n",
            "Epoch [414/500], batch 100, batch loss: 8.71156120300293\n",
            "Epoch [414/500], epoch mean loss: 8.727603575278973\n",
            "Epoch [414/500], evaluation loss: 9.08449179550697\n",
            "Epoch [415/500], batch 0, batch loss: 8.746794700622559\n",
            "Epoch [415/500], batch 100, batch loss: 8.730411529541016\n",
            "Epoch [415/500], epoch mean loss: 8.727125233617322\n",
            "Epoch [415/500], evaluation loss: 9.084974979532175\n",
            "Epoch [416/500], batch 0, batch loss: 8.699929237365723\n",
            "Epoch [416/500], batch 100, batch loss: 8.712850570678711\n",
            "Epoch [416/500], epoch mean loss: 8.7264315342081\n",
            "Epoch [416/500], evaluation loss: 9.084769314733045\n",
            "Epoch [417/500], batch 0, batch loss: 8.719420433044434\n",
            "Epoch [417/500], batch 100, batch loss: 8.735359191894531\n",
            "Epoch [417/500], epoch mean loss: 8.725845517783329\n",
            "Epoch [417/500], evaluation loss: 9.084497681979474\n",
            "Epoch [418/500], batch 0, batch loss: 8.7282075881958\n",
            "Epoch [418/500], batch 100, batch loss: 8.744558334350586\n",
            "Epoch [418/500], epoch mean loss: 8.725231910574026\n",
            "Epoch [418/500], evaluation loss: 9.084598343947839\n",
            "Epoch [419/500], batch 0, batch loss: 8.732244491577148\n",
            "Epoch [419/500], batch 100, batch loss: 8.710624694824219\n",
            "Epoch [419/500], epoch mean loss: 8.724770529516812\n",
            "Epoch [419/500], evaluation loss: 9.085018421041555\n",
            "Epoch [420/500], batch 0, batch loss: 8.741901397705078\n",
            "Epoch [420/500], batch 100, batch loss: 8.728241920471191\n",
            "Epoch [420/500], epoch mean loss: 8.724238798536103\n",
            "Epoch [420/500], evaluation loss: 9.084783784274396\n",
            "Epoch [421/500], batch 0, batch loss: 8.714560508728027\n",
            "Epoch [421/500], batch 100, batch loss: 8.708706855773926\n",
            "Epoch [421/500], epoch mean loss: 8.723665730706577\n",
            "Epoch [421/500], evaluation loss: 9.084750274132038\n",
            "Epoch [422/500], batch 0, batch loss: 8.737726211547852\n",
            "Epoch [422/500], batch 100, batch loss: 8.75219440460205\n",
            "Epoch [422/500], epoch mean loss: 8.723062622136084\n",
            "Epoch [422/500], evaluation loss: 9.085698029090619\n",
            "Epoch [423/500], batch 0, batch loss: 8.70335865020752\n",
            "Epoch [423/500], batch 100, batch loss: 8.723276138305664\n",
            "Epoch [423/500], epoch mean loss: 8.722549249385965\n",
            "Epoch [423/500], evaluation loss: 9.08487606048584\n",
            "Epoch [424/500], batch 0, batch loss: 8.715912818908691\n",
            "Epoch [424/500], batch 100, batch loss: 8.703536033630371\n",
            "Epoch [424/500], epoch mean loss: 8.721948755198511\n",
            "Epoch [424/500], evaluation loss: 9.085025326959018\n",
            "Epoch [425/500], batch 0, batch loss: 8.744891166687012\n",
            "Epoch [425/500], batch 100, batch loss: 8.718571662902832\n",
            "Epoch [425/500], epoch mean loss: 8.721098209249563\n",
            "Epoch [425/500], evaluation loss: 9.08582197386643\n",
            "Epoch [426/500], batch 0, batch loss: 8.710614204406738\n",
            "Epoch [426/500], batch 100, batch loss: 8.719417572021484\n",
            "Epoch [426/500], epoch mean loss: 8.720647006199277\n",
            "Epoch [426/500], evaluation loss: 9.08517600750101\n",
            "Epoch [427/500], batch 0, batch loss: 8.733489990234375\n",
            "Epoch [427/500], batch 100, batch loss: 8.711488723754883\n",
            "Epoch [427/500], epoch mean loss: 8.720034385549612\n",
            "Epoch [427/500], evaluation loss: 9.085297485877728\n",
            "Epoch [428/500], batch 0, batch loss: 8.725316047668457\n",
            "Epoch [428/500], batch 100, batch loss: 8.747747421264648\n",
            "Epoch [428/500], epoch mean loss: 8.719487050483966\n",
            "Epoch [428/500], evaluation loss: 9.085596479218582\n",
            "Epoch [429/500], batch 0, batch loss: 8.748739242553711\n",
            "Epoch [429/500], batch 100, batch loss: 8.720739364624023\n",
            "Epoch [429/500], epoch mean loss: 8.71882019371822\n",
            "Epoch [429/500], evaluation loss: 9.085251413542649\n",
            "Epoch [430/500], batch 0, batch loss: 8.721396446228027\n",
            "Epoch [430/500], batch 100, batch loss: 8.708320617675781\n",
            "Epoch [430/500], epoch mean loss: 8.718444133627004\n",
            "Epoch [430/500], evaluation loss: 9.085888500871329\n",
            "Epoch [431/500], batch 0, batch loss: 8.726423263549805\n",
            "Epoch [431/500], batch 100, batch loss: 8.737714767456055\n",
            "Epoch [431/500], epoch mean loss: 8.717906351747184\n",
            "Epoch [431/500], evaluation loss: 9.0858955712154\n",
            "Epoch [432/500], batch 0, batch loss: 8.733121871948242\n",
            "Epoch [432/500], batch 100, batch loss: 8.693960189819336\n",
            "Epoch [432/500], epoch mean loss: 8.717086882426822\n",
            "Epoch [432/500], evaluation loss: 9.08614392116152\n",
            "Epoch [433/500], batch 0, batch loss: 8.712467193603516\n",
            "Epoch [433/500], batch 100, batch loss: 8.709705352783203\n",
            "Epoch [433/500], epoch mean loss: 8.716660943524591\n",
            "Epoch [433/500], evaluation loss: 9.08542304203428\n",
            "Epoch [434/500], batch 0, batch loss: 8.72335147857666\n",
            "Epoch [434/500], batch 100, batch loss: 8.716340065002441\n",
            "Epoch [434/500], epoch mean loss: 8.71590884800615\n",
            "Epoch [434/500], evaluation loss: 9.085935198027512\n",
            "Epoch [435/500], batch 0, batch loss: 8.73110294342041\n",
            "Epoch [435/500], batch 100, batch loss: 8.710654258728027\n",
            "Epoch [435/500], epoch mean loss: 8.715412871590976\n",
            "Epoch [435/500], evaluation loss: 9.085846802283978\n",
            "Epoch [436/500], batch 0, batch loss: 8.720220565795898\n",
            "Epoch [436/500], batch 100, batch loss: 8.713837623596191\n",
            "Epoch [436/500], epoch mean loss: 8.714709717651893\n",
            "Epoch [436/500], evaluation loss: 9.085688558118097\n",
            "Epoch [437/500], batch 0, batch loss: 8.708706855773926\n",
            "Epoch [437/500], batch 100, batch loss: 8.713275909423828\n",
            "Epoch [437/500], epoch mean loss: 8.714360343998877\n",
            "Epoch [437/500], evaluation loss: 9.086096664954876\n",
            "Epoch [438/500], batch 0, batch loss: 8.714556694030762\n",
            "Epoch [438/500], batch 100, batch loss: 8.711642265319824\n",
            "Epoch [438/500], epoch mean loss: 8.71391672101514\n",
            "Epoch [438/500], evaluation loss: 9.08599639761037\n",
            "Epoch [439/500], batch 0, batch loss: 8.748162269592285\n",
            "Epoch [439/500], batch 100, batch loss: 8.72432804107666\n",
            "Epoch [439/500], epoch mean loss: 8.71331917006394\n",
            "Epoch [439/500], evaluation loss: 9.085997318399363\n",
            "Epoch [440/500], batch 0, batch loss: 8.710650444030762\n",
            "Epoch [440/500], batch 100, batch loss: 8.669514656066895\n",
            "Epoch [440/500], epoch mean loss: 8.712629885509097\n",
            "Epoch [440/500], evaluation loss: 9.086053946922565\n",
            "Epoch [441/500], batch 0, batch loss: 8.71791934967041\n",
            "Epoch [441/500], batch 100, batch loss: 8.711308479309082\n",
            "Epoch [441/500], epoch mean loss: 8.712140338174228\n",
            "Epoch [441/500], evaluation loss: 9.086189467331458\n",
            "Epoch [442/500], batch 0, batch loss: 8.719099998474121\n",
            "Epoch [442/500], batch 100, batch loss: 8.697663307189941\n",
            "Epoch [442/500], epoch mean loss: 8.711543494257434\n",
            "Epoch [442/500], evaluation loss: 9.086103965496195\n",
            "Epoch [443/500], batch 0, batch loss: 8.696990013122559\n",
            "Epoch [443/500], batch 100, batch loss: 8.68956184387207\n",
            "Epoch [443/500], epoch mean loss: 8.71099542749339\n",
            "Epoch [443/500], evaluation loss: 9.08633879957528\n",
            "Epoch [444/500], batch 0, batch loss: 8.702856063842773\n",
            "Epoch [444/500], batch 100, batch loss: 8.703788757324219\n",
            "Epoch [444/500], epoch mean loss: 8.710538864135742\n",
            "Epoch [444/500], evaluation loss: 9.086601454636146\n",
            "Epoch [445/500], batch 0, batch loss: 8.716499328613281\n",
            "Epoch [445/500], batch 100, batch loss: 8.71712589263916\n",
            "Epoch [445/500], epoch mean loss: 8.709984614931304\n",
            "Epoch [445/500], evaluation loss: 9.086656406007965\n",
            "Epoch [446/500], batch 0, batch loss: 8.705933570861816\n",
            "Epoch [446/500], batch 100, batch loss: 8.711466789245605\n",
            "Epoch [446/500], epoch mean loss: 8.709483968800512\n",
            "Epoch [446/500], evaluation loss: 9.086561400314856\n",
            "Epoch [447/500], batch 0, batch loss: 8.726285934448242\n",
            "Epoch [447/500], batch 100, batch loss: 8.700959205627441\n",
            "Epoch [447/500], epoch mean loss: 8.708730187909357\n",
            "Epoch [447/500], evaluation loss: 9.086314563093515\n",
            "Epoch [448/500], batch 0, batch loss: 8.67354679107666\n",
            "Epoch [448/500], batch 100, batch loss: 8.701456069946289\n",
            "Epoch [448/500], epoch mean loss: 8.708297688385535\n",
            "Epoch [448/500], evaluation loss: 9.086538512131263\n",
            "Epoch [449/500], batch 0, batch loss: 8.696989059448242\n",
            "Epoch [449/500], batch 100, batch loss: 8.711620330810547\n",
            "Epoch [449/500], epoch mean loss: 8.70768379342967\n",
            "Epoch [449/500], evaluation loss: 9.086527166695431\n",
            "Epoch [450/500], batch 0, batch loss: 8.718446731567383\n",
            "Epoch [450/500], batch 100, batch loss: 8.70090389251709\n",
            "Epoch [450/500], epoch mean loss: 8.707246204902386\n",
            "Epoch [450/500], evaluation loss: 9.08697536073882\n",
            "Epoch [451/500], batch 0, batch loss: 8.705361366271973\n",
            "Epoch [451/500], batch 100, batch loss: 8.693077087402344\n",
            "Epoch [451/500], epoch mean loss: 8.706709985075326\n",
            "Epoch [451/500], evaluation loss: 9.087087894308157\n",
            "Epoch [452/500], batch 0, batch loss: 8.71030330657959\n",
            "Epoch [452/500], batch 100, batch loss: 8.712545394897461\n",
            "Epoch [452/500], epoch mean loss: 8.706204134842444\n",
            "Epoch [452/500], evaluation loss: 9.087518034310177\n",
            "Epoch [453/500], batch 0, batch loss: 8.715850830078125\n",
            "Epoch [453/500], batch 100, batch loss: 8.723419189453125\n",
            "Epoch [453/500], epoch mean loss: 8.705560832188047\n",
            "Epoch [453/500], evaluation loss: 9.08684595699968\n",
            "Epoch [454/500], batch 0, batch loss: 8.708695411682129\n",
            "Epoch [454/500], batch 100, batch loss: 8.694624900817871\n",
            "Epoch [454/500], epoch mean loss: 8.704924295688498\n",
            "Epoch [454/500], evaluation loss: 9.087215686666555\n",
            "Epoch [455/500], batch 0, batch loss: 8.722367286682129\n",
            "Epoch [455/500], batch 100, batch loss: 8.74580192565918\n",
            "Epoch [455/500], epoch mean loss: 8.70450730159365\n",
            "Epoch [455/500], evaluation loss: 9.086852731375858\n",
            "Epoch [456/500], batch 0, batch loss: 8.718317031860352\n",
            "Epoch [456/500], batch 100, batch loss: 8.697966575622559\n",
            "Epoch [456/500], epoch mean loss: 8.703933715820312\n",
            "Epoch [456/500], evaluation loss: 9.08689965872929\n",
            "Epoch [457/500], batch 0, batch loss: 8.694052696228027\n",
            "Epoch [457/500], batch 100, batch loss: 8.707721710205078\n",
            "Epoch [457/500], epoch mean loss: 8.70341130782818\n",
            "Epoch [457/500], evaluation loss: 9.08784165875665\n",
            "Epoch [458/500], batch 0, batch loss: 8.715499877929688\n",
            "Epoch [458/500], batch 100, batch loss: 8.675501823425293\n",
            "Epoch [458/500], epoch mean loss: 8.702918529510498\n",
            "Epoch [458/500], evaluation loss: 9.087637769764868\n",
            "Epoch [459/500], batch 0, batch loss: 8.708526611328125\n",
            "Epoch [459/500], batch 100, batch loss: 8.732102394104004\n",
            "Epoch [459/500], epoch mean loss: 8.702275588594635\n",
            "Epoch [459/500], evaluation loss: 9.087580023140744\n",
            "Epoch [460/500], batch 0, batch loss: 8.70189094543457\n",
            "Epoch [460/500], batch 100, batch loss: 8.703866958618164\n",
            "Epoch [460/500], epoch mean loss: 8.701858076555975\n",
            "Epoch [460/500], evaluation loss: 9.087708177237674\n",
            "Epoch [461/500], batch 0, batch loss: 8.661642074584961\n",
            "Epoch [461/500], batch 100, batch loss: 8.713470458984375\n",
            "Epoch [461/500], epoch mean loss: 8.701113750194681\n",
            "Epoch [461/500], evaluation loss: 9.087636684549265\n",
            "Epoch [462/500], batch 0, batch loss: 8.716506958007812\n",
            "Epoch [462/500], batch 100, batch loss: 8.68234634399414\n",
            "Epoch [462/500], epoch mean loss: 8.700517687304266\n",
            "Epoch [462/500], evaluation loss: 9.087695812356882\n",
            "Epoch [463/500], batch 0, batch loss: 8.689504623413086\n",
            "Epoch [463/500], batch 100, batch loss: 8.698944091796875\n",
            "Epoch [463/500], epoch mean loss: 8.700037134104761\n",
            "Epoch [463/500], evaluation loss: 9.088143907744309\n",
            "Epoch [464/500], batch 0, batch loss: 8.69894027709961\n",
            "Epoch [464/500], batch 100, batch loss: 8.713586807250977\n",
            "Epoch [464/500], epoch mean loss: 8.699428632341583\n",
            "Epoch [464/500], evaluation loss: 9.088001547188595\n",
            "Epoch [465/500], batch 0, batch loss: 8.711631774902344\n",
            "Epoch [465/500], batch 100, batch loss: 8.697735786437988\n",
            "Epoch [465/500], epoch mean loss: 8.698769890028855\n",
            "Epoch [465/500], evaluation loss: 9.087676508673306\n",
            "Epoch [466/500], batch 0, batch loss: 8.684272766113281\n",
            "Epoch [466/500], batch 100, batch loss: 8.718494415283203\n",
            "Epoch [466/500], epoch mean loss: 8.698225070690286\n",
            "Epoch [466/500], evaluation loss: 9.08794985146358\n",
            "Epoch [467/500], batch 0, batch loss: 8.682217597961426\n",
            "Epoch [467/500], batch 100, batch loss: 8.663496971130371\n",
            "Epoch [467/500], epoch mean loss: 8.69778954571691\n",
            "Epoch [467/500], evaluation loss: 9.088224213698815\n",
            "Epoch [468/500], batch 0, batch loss: 8.684767723083496\n",
            "Epoch [468/500], batch 100, batch loss: 8.713604927062988\n",
            "Epoch [468/500], epoch mean loss: 8.697122179228684\n",
            "Epoch [468/500], evaluation loss: 9.088574705452755\n",
            "Epoch [469/500], batch 0, batch loss: 8.689186096191406\n",
            "Epoch [469/500], batch 100, batch loss: 8.69809341430664\n",
            "Epoch [469/500], epoch mean loss: 8.696693387524835\n",
            "Epoch [469/500], evaluation loss: 9.08932929203428\n",
            "Epoch [470/500], batch 0, batch loss: 8.710334777832031\n",
            "Epoch [470/500], batch 100, batch loss: 8.6968355178833\n",
            "Epoch [470/500], epoch mean loss: 8.69613319429858\n",
            "Epoch [470/500], evaluation loss: 9.088701346824909\n",
            "Epoch [471/500], batch 0, batch loss: 8.674560546875\n",
            "Epoch [471/500], batch 100, batch loss: 8.685256958007812\n",
            "Epoch [471/500], epoch mean loss: 8.695573017514985\n",
            "Epoch [471/500], evaluation loss: 9.088786651348245\n",
            "Epoch [472/500], batch 0, batch loss: 8.698938369750977\n",
            "Epoch [472/500], batch 100, batch loss: 8.70875358581543\n",
            "Epoch [472/500], epoch mean loss: 8.695092209454241\n",
            "Epoch [472/500], evaluation loss: 9.088596179567535\n",
            "Epoch [473/500], batch 0, batch loss: 8.712597846984863\n",
            "Epoch [473/500], batch 100, batch loss: 8.71595573425293\n",
            "Epoch [473/500], epoch mean loss: 8.694557041957461\n",
            "Epoch [473/500], evaluation loss: 9.08906390749175\n",
            "Epoch [474/500], batch 0, batch loss: 8.668509483337402\n",
            "Epoch [474/500], batch 100, batch loss: 8.67418384552002\n",
            "Epoch [474/500], epoch mean loss: 8.694115170117083\n",
            "Epoch [474/500], evaluation loss: 9.08892404622045\n",
            "Epoch [475/500], batch 0, batch loss: 8.67953872680664\n",
            "Epoch [475/500], batch 100, batch loss: 8.729208946228027\n",
            "Epoch [475/500], epoch mean loss: 8.693517183435373\n",
            "Epoch [475/500], evaluation loss: 9.088609826975855\n",
            "Epoch [476/500], batch 0, batch loss: 8.676816940307617\n",
            "Epoch [476/500], batch 100, batch loss: 8.68226146697998\n",
            "Epoch [476/500], epoch mean loss: 8.693008932574042\n",
            "Epoch [476/500], evaluation loss: 9.08853031026906\n",
            "Epoch [477/500], batch 0, batch loss: 8.707497596740723\n",
            "Epoch [477/500], batch 100, batch loss: 8.696660041809082\n",
            "Epoch [477/500], epoch mean loss: 8.692291522848196\n",
            "Epoch [477/500], evaluation loss: 9.088601901613433\n",
            "Epoch [478/500], batch 0, batch loss: 8.687223434448242\n",
            "Epoch [478/500], batch 100, batch loss: 8.716509819030762\n",
            "Epoch [478/500], epoch mean loss: 8.691987284298602\n",
            "Epoch [478/500], evaluation loss: 9.088717033123148\n",
            "Epoch [479/500], batch 0, batch loss: 8.740904808044434\n",
            "Epoch [479/500], batch 100, batch loss: 8.671600341796875\n",
            "Epoch [479/500], epoch mean loss: 8.691455947941748\n",
            "Epoch [479/500], evaluation loss: 9.088416987452014\n",
            "Epoch [480/500], batch 0, batch loss: 8.7125883102417\n",
            "Epoch [480/500], batch 100, batch loss: 8.722674369812012\n",
            "Epoch [480/500], epoch mean loss: 8.691027871493635\n",
            "Epoch [480/500], evaluation loss: 9.088631103778708\n",
            "Epoch [481/500], batch 0, batch loss: 8.672513961791992\n",
            "Epoch [481/500], batch 100, batch loss: 8.685308456420898\n",
            "Epoch [481/500], epoch mean loss: 8.690545624700086\n",
            "Epoch [481/500], evaluation loss: 9.089245039841224\n",
            "Epoch [482/500], batch 0, batch loss: 8.687170028686523\n",
            "Epoch [482/500], batch 100, batch loss: 8.662769317626953\n",
            "Epoch [482/500], epoch mean loss: 8.690102092150983\n",
            "Epoch [482/500], evaluation loss: 9.088837196087015\n",
            "Epoch [483/500], batch 0, batch loss: 8.672355651855469\n",
            "Epoch [483/500], batch 100, batch loss: 8.695408821105957\n",
            "Epoch [483/500], epoch mean loss: 8.689785686032526\n",
            "Epoch [483/500], evaluation loss: 9.088483909080768\n",
            "Epoch [484/500], batch 0, batch loss: 8.706742286682129\n",
            "Epoch [484/500], batch 100, batch loss: 8.67427921295166\n",
            "Epoch [484/500], epoch mean loss: 8.689209913385325\n",
            "Epoch [484/500], evaluation loss: 9.089307850804822\n",
            "Epoch [485/500], batch 0, batch loss: 8.661827087402344\n",
            "Epoch [485/500], batch 100, batch loss: 8.697518348693848\n",
            "Epoch [485/500], epoch mean loss: 8.688444778837006\n",
            "Epoch [485/500], evaluation loss: 9.089429362066861\n",
            "Epoch [486/500], batch 0, batch loss: 8.691604614257812\n",
            "Epoch [486/500], batch 100, batch loss: 8.672436714172363\n",
            "Epoch [486/500], epoch mean loss: 8.688086361720645\n",
            "Epoch [486/500], evaluation loss: 9.089267763598212\n",
            "Epoch [487/500], batch 0, batch loss: 8.701817512512207\n",
            "Epoch [487/500], batch 100, batch loss: 8.701519012451172\n",
            "Epoch [487/500], epoch mean loss: 8.687560385671155\n",
            "Epoch [487/500], evaluation loss: 9.08909455661116\n",
            "Epoch [488/500], batch 0, batch loss: 8.6559476852417\n",
            "Epoch [488/500], batch 100, batch loss: 8.68200969696045\n",
            "Epoch [488/500], epoch mean loss: 8.687286697585007\n",
            "Epoch [488/500], evaluation loss: 9.08925697721284\n",
            "Epoch [489/500], batch 0, batch loss: 8.69405460357666\n",
            "Epoch [489/500], batch 100, batch loss: 8.686243057250977\n",
            "Epoch [489/500], epoch mean loss: 8.686565711580474\n",
            "Epoch [489/500], evaluation loss: 9.089168285501414\n",
            "Epoch [490/500], batch 0, batch loss: 8.688375473022461\n",
            "Epoch [490/500], batch 100, batch loss: 8.690143585205078\n",
            "Epoch [490/500], epoch mean loss: 8.685992561537644\n",
            "Epoch [490/500], evaluation loss: 9.089199460785965\n",
            "Epoch [491/500], batch 0, batch loss: 8.648807525634766\n",
            "Epoch [491/500], batch 100, batch loss: 8.6510648727417\n",
            "Epoch [491/500], epoch mean loss: 8.68556335876728\n",
            "Epoch [491/500], evaluation loss: 9.08955268202157\n",
            "Epoch [492/500], batch 0, batch loss: 8.682538032531738\n",
            "Epoch [492/500], batch 100, batch loss: 8.663419723510742\n",
            "Epoch [492/500], epoch mean loss: 8.685079245731748\n",
            "Epoch [492/500], evaluation loss: 9.089782320219895\n",
            "Epoch [493/500], batch 0, batch loss: 8.689116477966309\n",
            "Epoch [493/500], batch 100, batch loss: 8.693049430847168\n",
            "Epoch [493/500], epoch mean loss: 8.684584938246628\n",
            "Epoch [493/500], evaluation loss: 9.089898175206677\n",
            "Epoch [494/500], batch 0, batch loss: 8.695320129394531\n",
            "Epoch [494/500], batch 100, batch loss: 8.701909065246582\n",
            "Epoch [494/500], epoch mean loss: 8.684034339312849\n",
            "Epoch [494/500], evaluation loss: 9.089795868972253\n",
            "Epoch [495/500], batch 0, batch loss: 8.675443649291992\n",
            "Epoch [495/500], batch 100, batch loss: 8.692704200744629\n",
            "Epoch [495/500], epoch mean loss: 8.683663771070282\n",
            "Epoch [495/500], evaluation loss: 9.089791429453882\n",
            "Epoch [496/500], batch 0, batch loss: 8.677315711975098\n",
            "Epoch [496/500], batch 100, batch loss: 8.675002098083496\n",
            "Epoch [496/500], epoch mean loss: 8.683191842046277\n",
            "Epoch [496/500], evaluation loss: 9.090580611393369\n",
            "Epoch [497/500], batch 0, batch loss: 8.691678047180176\n",
            "Epoch [497/500], batch 100, batch loss: 8.673543930053711\n",
            "Epoch [497/500], epoch mean loss: 8.682774272458307\n",
            "Epoch [497/500], evaluation loss: 9.089958717083109\n",
            "Epoch [498/500], batch 0, batch loss: 8.681325912475586\n",
            "Epoch [498/500], batch 100, batch loss: 8.672540664672852\n",
            "Epoch [498/500], epoch mean loss: 8.68215327427305\n",
            "Epoch [498/500], evaluation loss: 9.0899061005691\n",
            "Epoch [499/500], batch 0, batch loss: 8.658912658691406\n",
            "Epoch [499/500], batch 100, batch loss: 8.695172309875488\n",
            "Epoch [499/500], epoch mean loss: 8.681765646770083\n",
            "Epoch [499/500], evaluation loss: 9.089360434433509\n",
            "Epoch [500/500], batch 0, batch loss: 8.696823120117188\n",
            "Epoch [500/500], batch 100, batch loss: 8.684269905090332\n",
            "Epoch [500/500], epoch mean loss: 8.681360178980334\n",
            "Epoch [500/500], evaluation loss: 9.089586027737322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot losses"
      ],
      "metadata": {
        "id": "2-QjOD6XZs8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.train_losses)\n",
        "plt.plot(model.eval_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e9Q6YXhoZPwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "07bb89f6-dc53-47a5-a3b0-5f11d8e1754e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save and load model"
      ],
      "metadata": {
        "id": "uw6FUPF5Zg0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/datasets/Brown_Corpus/nplm_model.pt')"
      ],
      "metadata": {
        "id": "GCxMpGqKX_i5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the embeddings to compute similarities between words"
      ],
      "metadata": {
        "id": "fUlX1UruKel6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = {('socialist', 'republic'), ('cat', 'dog'), ('dog', 'republic'), ('socialist', 'cat')}\n",
        "\n",
        "cos = nn.CosineSimilarity(dim=0)\n",
        "\n",
        "lm_similarities = {}\n",
        "for word_pairs in words:\n",
        "    w1 = word_pairs[0]\n",
        "    w2 = word_pairs[1]\n",
        "    words_tensor = torch.LongTensor(np.array([encoder.transform([w1]), encoder.transform([w2])]))\n",
        "    words_tensor = words_tensor.to(device)\n",
        "    # get word embeddings from the best model\n",
        "    words_embeds = model.embedding(words_tensor)\n",
        "    # calculate cosine similarity between word vectors\n",
        "    sim = cos(words_embeds[0][0], words_embeds[1][0])\n",
        "    lm_similarities[word_pairs] = sim.item()\n",
        "\n",
        "print(lm_similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IezeSaz0Kk0J",
        "outputId": "b0156482-6866-4515-8ebb-92e6e305038f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('socialist', 'cat'): 0.0028149187564849854, ('dog', 'republic'): -0.014645600691437721, ('socialist', 'republic'): -0.11175817251205444, ('cat', 'dog'): -0.048882946372032166}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-25ba1d808e12>:9: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  words_tensor = torch.LongTensor([encoder.transform([w1]), encoder.transform([w2])])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "AEN8nG9Rt6UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 9571\n",
        "embedding_dim = 256\n",
        "hidden_dim = 1024\n",
        "context_size = n_grams_len - 1\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 500\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = NPLM(vocab_size, embedding_dim, hidden_dim, context_size)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "model = model.to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/datasets/Brown_Corpus/nplm_model.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p69vyV-Lt5ra",
        "outputId": "14197a93-238a-4470-e2e7-4ac9cba2cf62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkiyCpjKvBE5",
        "outputId": "2623b29f-f70d-4025-c851-d055203b88f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9571, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project words into a 2D space to visualize them"
      ],
      "metadata": {
        "id": "Z1QxPcloLS47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import Isomap, TSNE\n",
        "\n",
        "embeddings = model.embedding.weight\n",
        "\n",
        "# dimensionality reduction\n",
        "isomap = Isomap(n_components=2)\n",
        "# tsne = TSNE(n_components=2)\n",
        "embeddings_2d = isomap.fit_transform(embeddings.detach().cpu().numpy())\n",
        "# embeddings_2d = tsne.fit_transform(embeddings.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "vkrAODNwLbQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5O-txfb4bGVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec data preparation and model building and training"
      ],
      "metadata": {
        "id": "w199uTOqzDxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# if the word is not in the vocabulary build using the training set it is replaced with <UNK>\n",
        "def replace_unknown_word(word, vocabulary):\n",
        "    if word in vocabulary:\n",
        "        return word\n",
        "    else:\n",
        "        return '<UNK>'\n",
        "\n",
        "# return the ids for each word in the n-gram\n",
        "def get_ngram_ids(ngram, encoder):\n",
        "    return encoder.transform(ngram)\n",
        "\n",
        "\n",
        "context_len = 11  # n-gram length\n",
        "min_len = context_len  # minimum sentence length\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "word_ids = encoder.fit_transform(list(vocabulary))  # encode words into ids\n",
        "print(word_ids)\n",
        "\n",
        "context_train = []\n",
        "context_test = []\n",
        "for i, sentence in enumerate(shuffled_docs):\n",
        "    # skip sentences with less words than min_len\n",
        "    if len(sentence) < min_len:\n",
        "        continue\n",
        "    # iterate through the sentence and build n-grams (the last word is the word to predict)\n",
        "    for j, word in enumerate(sentence):\n",
        "        if j < len(sentence) - (context_len-1):\n",
        "            if i <= num_train:\n",
        "                context_train.append([replace_unknown_word(sentence[j+k], vocabulary) for k in range(context_len) if k < context_len])\n",
        "            else:\n",
        "                context_test.append([replace_unknown_word(sentence[j+k], vocabulary) for k in range(context_len) if k < context_len])\n",
        "\n",
        "# numpy array conversion\n",
        "context_train = np.array(context_train)\n",
        "context_test = np.array(context_test)\n",
        "\n",
        "# replace words with ids\n",
        "for i in range(context_len):\n",
        "    context_train[:, i] = encoder.transform(context_train[:, i])\n",
        "    context_test[:, i] = encoder.transform(context_test[:, i])\n",
        "\n",
        "print(context_train.shape)\n",
        "print(context_test.shape)"
      ],
      "metadata": {
        "id": "3xNDVpw1zKhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77984975-394a-467e-9921-497fa1fee3f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7059 4999  851 ... 3335 1690 4061]\n",
            "(99587, 11)\n",
            "(24434, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split X and y for CBOW and Skip-gram"
      ],
      "metadata": {
        "id": "d7KqK5cT3H-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "# Use slicing to take all elements except the 5th element (which has index 4)\n",
        "result = np.concatenate([arr[:4], arr[5:]])\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6vODHBKvYnD",
        "outputId": "a0aa4998-becb-4b01-f7ca-df3c39462b17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  3  4  6  7  8  9 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_train = np.array(context_train, dtype=int)\n",
        "context_test = np.array(context_test, dtype=int)\n",
        "\n",
        "# CBOW splitting (usually the context length is an odd number)\n",
        "X_train = context_train[:, 0:context_len-1]\n",
        "y_train = context_train[:, -1]\n",
        "X_test = context_test[:, 0:context_len-1]\n",
        "y_test = context_test[:, -1]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "a-XPBsNL3HE6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}